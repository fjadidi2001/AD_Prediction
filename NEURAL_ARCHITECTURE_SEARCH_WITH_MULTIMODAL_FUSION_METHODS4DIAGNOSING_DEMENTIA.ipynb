{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPmVbdksr+HFAyTSlW/urlh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7bf06daf7ef343fa8c2b375431b7af36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b530f1b74054a8fa35bc2ac517fe3fb",
              "IPY_MODEL_d3df08063e094052b1f5f47c22772e8f",
              "IPY_MODEL_f0e990dd85344c68966eeef2b5d7cf87"
            ],
            "layout": "IPY_MODEL_b10f7f1d33bb44c6af55445d5eebfa9b"
          }
        },
        "9b530f1b74054a8fa35bc2ac517fe3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9bacee7f786439bbdcbeb8e1f54b1a2",
            "placeholder": "​",
            "style": "IPY_MODEL_4168ef5d074941dba8fe2e54ec58fe2a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d3df08063e094052b1f5f47c22772e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c60c110815304064bb2666e3f99adb79",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18fefffee8a64763b4a607c855cf31cd",
            "value": 48
          }
        },
        "f0e990dd85344c68966eeef2b5d7cf87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ecec58d85be4c8a85b68eb8e3306b2e",
            "placeholder": "​",
            "style": "IPY_MODEL_c30ecbf53c3c4ac486701a557e57110f",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.50kB/s]"
          }
        },
        "b10f7f1d33bb44c6af55445d5eebfa9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9bacee7f786439bbdcbeb8e1f54b1a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4168ef5d074941dba8fe2e54ec58fe2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c60c110815304064bb2666e3f99adb79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18fefffee8a64763b4a607c855cf31cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ecec58d85be4c8a85b68eb8e3306b2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c30ecbf53c3c4ac486701a557e57110f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83aa8a6596e244a3abb864fc6ad754f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c167186174d47d78cf1e5ed9f3de24f",
              "IPY_MODEL_759200fcf6c349cda87bd7af2495d5ae",
              "IPY_MODEL_cb894524e6884943b59bc3785856c4e6"
            ],
            "layout": "IPY_MODEL_5459ae5e6ba348d396f50d58854db8ab"
          }
        },
        "8c167186174d47d78cf1e5ed9f3de24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c3c1297cbb74ab59f00ba2061d4bcd1",
            "placeholder": "​",
            "style": "IPY_MODEL_63d9755a4afb4c8c8fa979a2af20ef0e",
            "value": "vocab.txt: 100%"
          }
        },
        "759200fcf6c349cda87bd7af2495d5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea9cce16349a41e38ce186fb619564b1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fe5c9d35a44424db31afec4617819e3",
            "value": 231508
          }
        },
        "cb894524e6884943b59bc3785856c4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f0f9b5734c4350b446f8701ca9a950",
            "placeholder": "​",
            "style": "IPY_MODEL_3fd9245e09614e738da9b8a23f87e45f",
            "value": " 232k/232k [00:00&lt;00:00, 3.14MB/s]"
          }
        },
        "5459ae5e6ba348d396f50d58854db8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3c1297cbb74ab59f00ba2061d4bcd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63d9755a4afb4c8c8fa979a2af20ef0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea9cce16349a41e38ce186fb619564b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fe5c9d35a44424db31afec4617819e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6f0f9b5734c4350b446f8701ca9a950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fd9245e09614e738da9b8a23f87e45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd37c3f7ea09403f80d22ce18342b081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_120830e90b684f0ba009538fd1484dc5",
              "IPY_MODEL_c16fea3ee442475e943e8344e4fc12b4",
              "IPY_MODEL_211d60e410a04d2aac64f8f9dc7a8720"
            ],
            "layout": "IPY_MODEL_1cab200c311c4f669221ee0417a3d9ab"
          }
        },
        "120830e90b684f0ba009538fd1484dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce161a6fd364bf193572322e7f551d9",
            "placeholder": "​",
            "style": "IPY_MODEL_5684f080ea23494cb048c7ab26c21b94",
            "value": "tokenizer.json: 100%"
          }
        },
        "c16fea3ee442475e943e8344e4fc12b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbb7e6ebdad3440aabadca01d0901c5a",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22cef289a4e44b54ba32fc4fa99f52e3",
            "value": 466062
          }
        },
        "211d60e410a04d2aac64f8f9dc7a8720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a8de18c03734dc48e1056e870fea32e",
            "placeholder": "​",
            "style": "IPY_MODEL_7ed222a9238a4d41bca5d8012bcf69e9",
            "value": " 466k/466k [00:00&lt;00:00, 1.44MB/s]"
          }
        },
        "1cab200c311c4f669221ee0417a3d9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce161a6fd364bf193572322e7f551d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5684f080ea23494cb048c7ab26c21b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbb7e6ebdad3440aabadca01d0901c5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22cef289a4e44b54ba32fc4fa99f52e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a8de18c03734dc48e1056e870fea32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed222a9238a4d41bca5d8012bcf69e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "087fb7b4b0e5423188d3a88f68deae5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_965648fa43f044169b95c11f4f95afb8",
              "IPY_MODEL_6802598135ae484d85b2434cd23e3d3a",
              "IPY_MODEL_dbe8184cf37a4a9b9c2312bb5e639115"
            ],
            "layout": "IPY_MODEL_23d17f19a7bb40f8887d6bfa69944cc2"
          }
        },
        "965648fa43f044169b95c11f4f95afb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04ffc5a1c406499a9d49070578a584c0",
            "placeholder": "​",
            "style": "IPY_MODEL_5afc1676a8324843b909a51eb4e98b6f",
            "value": "config.json: 100%"
          }
        },
        "6802598135ae484d85b2434cd23e3d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5574e1731db247a9ba1f24aef9eaf73d",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a9de8952b294ad99b6758263aa046c8",
            "value": 570
          }
        },
        "dbe8184cf37a4a9b9c2312bb5e639115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a31c8c724bf44578defc5b61297ecef",
            "placeholder": "​",
            "style": "IPY_MODEL_b66976d5e779456a84a378fb6efa22bf",
            "value": " 570/570 [00:00&lt;00:00, 14.0kB/s]"
          }
        },
        "23d17f19a7bb40f8887d6bfa69944cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04ffc5a1c406499a9d49070578a584c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5afc1676a8324843b909a51eb4e98b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5574e1731db247a9ba1f24aef9eaf73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9de8952b294ad99b6758263aa046c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a31c8c724bf44578defc5b61297ecef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b66976d5e779456a84a378fb6efa22bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8fb59d637e34960a7fa06b743b23a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3a9526f2c734d79beb72b7a8c0d8cfa",
              "IPY_MODEL_03a46c1d36294f689cd929c0a26ac322",
              "IPY_MODEL_3a99e6f19901430e9ed69254515eab2d"
            ],
            "layout": "IPY_MODEL_474386d1004f4d7a90a047f60bef4505"
          }
        },
        "d3a9526f2c734d79beb72b7a8c0d8cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d5d9c486520445285788c3f2f20c3c9",
            "placeholder": "​",
            "style": "IPY_MODEL_ab262d42ec32455283e6a985115e09dc",
            "value": "model.safetensors: 100%"
          }
        },
        "03a46c1d36294f689cd929c0a26ac322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83dc802c05dd4cb4b9b61b23e754e545",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e14d0945463f4b1285d3c17261ec55ee",
            "value": 440449768
          }
        },
        "3a99e6f19901430e9ed69254515eab2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11d17caaeed84714842faf6f3f625044",
            "placeholder": "​",
            "style": "IPY_MODEL_38a9401f685942009f34e6b3e66e09da",
            "value": " 440M/440M [00:02&lt;00:00, 187MB/s]"
          }
        },
        "474386d1004f4d7a90a047f60bef4505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5d9c486520445285788c3f2f20c3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab262d42ec32455283e6a985115e09dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83dc802c05dd4cb4b9b61b23e754e545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e14d0945463f4b1285d3c17261ec55ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11d17caaeed84714842faf6f3f625044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a9401f685942009f34e6b3e66e09da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/NEURAL_ARCHITECTURE_SEARCH_WITH_MULTIMODAL_FUSION_METHODS4DIAGNOSING_DEMENTIA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDCDHbYzNp2n",
        "outputId": "32958fcc-71c2-47a5-eaa3-7f42deadb156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workflow Overview\n",
        "\n",
        "- Setup and Dependencies Installation\n",
        "- Dataset Extraction and Exploration\n",
        "- Audio Preprocessing and Feature Extraction\n",
        "- Text Generation (ASR) and Linguistic Feature Extraction\n",
        "- DARTS Neural Architecture Search Implementation\n",
        "- BERT Text Processing\n",
        "- Multimodal Fusion Implementation\n",
        "- Model Training and Evaluation\n",
        "- Testing and Validation"
      ],
      "metadata": {
        "id": "Hz8BP_SsPwy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AD Detection Starter Script for Google Colab\n",
        "# Run this first to test dataset loading and basic setup\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install transformers torch torchaudio librosa speechrecognition pydub scikit-learn\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Step 1: Check and extract datasets\n",
        "def setup_datasets():\n",
        "    base_path = \"/content/drive/MyDrive/Voice/\"\n",
        "\n",
        "    # Check if files exist\n",
        "    files_to_check = [\n",
        "        \"ADReSSo21-diagnosis-train.tgz\",\n",
        "        \"ADReSSo21-progression-test.tgz\",\n",
        "        \"ADReSSo21-progression-train.tgz\"\n",
        "    ]\n",
        "\n",
        "    print(\"Checking dataset files...\")\n",
        "    for file in files_to_check:\n",
        "        full_path = os.path.join(base_path, file)\n",
        "        if os.path.exists(full_path):\n",
        "            print(f\"✓ Found: {file}\")\n",
        "        else:\n",
        "            print(f\"✗ Missing: {file}\")\n",
        "\n",
        "    # Extract datasets\n",
        "    print(\"\\nExtracting datasets...\")\n",
        "    for file in files_to_check:\n",
        "        archive_path = os.path.join(base_path, file)\n",
        "        extract_path = os.path.join(base_path, file.replace('.tgz', ''))\n",
        "\n",
        "        if os.path.exists(archive_path) and not os.path.exists(extract_path):\n",
        "            print(f\"Extracting {file}...\")\n",
        "            try:\n",
        "                with tarfile.open(archive_path, 'r:gz') as tar:\n",
        "                    tar.extractall(extract_path)\n",
        "                print(f\"✓ Extracted to {extract_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"✗ Error extracting {file}: {e}\")\n",
        "        elif os.path.exists(extract_path):\n",
        "            print(f\"✓ Already extracted: {file}\")\n",
        "\n",
        "# Step 2: Explore dataset structure\n",
        "def explore_dataset_structure():\n",
        "    base_path = \"/content/drive/MyDrive/Voice/\"\n",
        "\n",
        "    print(\"Dataset structure:\")\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        level = root.replace(base_path, '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files[:5]:  # Show first 5 files only\n",
        "            print(f\"{subindent}{file}\")\n",
        "        if len(files) > 5:\n",
        "            print(f\"{subindent}... and {len(files) - 5} more files\")\n",
        "\n",
        "# Step 3: Find and analyze audio files\n",
        "def find_audio_files():\n",
        "    base_path = \"/content/drive/MyDrive/Voice/\"\n",
        "    audio_extensions = ['.wav', '.mp3', '.flac', '.m4a']\n",
        "\n",
        "    audio_files = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if any(file.lower().endswith(ext) for ext in audio_extensions):\n",
        "                audio_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"\\nFound {len(audio_files)} audio files\")\n",
        "\n",
        "    if audio_files:\n",
        "        print(\"\\nSample audio files:\")\n",
        "        for i, file in enumerate(audio_files[:5]):\n",
        "            print(f\"{i+1}. {file}\")\n",
        "\n",
        "        # Analyze first audio file\n",
        "        if len(audio_files) > 0:\n",
        "            print(f\"\\nAnalyzing first audio file: {audio_files[0]}\")\n",
        "            try:\n",
        "                y, sr = librosa.load(audio_files[0], duration=10)  # Load first 10 seconds\n",
        "                print(f\"Sample rate: {sr} Hz\")\n",
        "                print(f\"Duration: {len(y)/sr:.2f} seconds\")\n",
        "                print(f\"Audio shape: {y.shape}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading audio: {e}\")\n",
        "\n",
        "    return audio_files\n",
        "\n",
        "# Step 4: Check for label information\n",
        "def check_labels():\n",
        "    base_path = \"/content/drive/MyDrive/Voice/\"\n",
        "\n",
        "    # Look for CSV files or text files that might contain labels\n",
        "    label_files = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.csv', '.txt', '.tsv', '.json')):\n",
        "                label_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"\\nFound {len(label_files)} potential label files:\")\n",
        "    for file in label_files:\n",
        "        print(f\"- {file}\")\n",
        "\n",
        "    # Try to read label files\n",
        "    for file in label_files[:3]:  # Check first 3 files\n",
        "        try:\n",
        "            if file.endswith('.csv'):\n",
        "                df = pd.read_csv(file)\n",
        "                print(f\"\\n{file} (CSV):\")\n",
        "                print(f\"Shape: {df.shape}\")\n",
        "                print(f\"Columns: {list(df.columns)}\")\n",
        "                print(df.head())\n",
        "            elif file.endswith('.txt'):\n",
        "                with open(file, 'r') as f:\n",
        "                    content = f.read()[:500]  # First 500 characters\n",
        "                print(f\"\\n{file} (TXT):\")\n",
        "                print(content)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file}: {e}\")\n",
        "\n",
        "# Step 5: Basic audio feature extraction test\n",
        "def test_audio_processing():\n",
        "    print(\"\\nTesting audio processing...\")\n",
        "\n",
        "    # Find an audio file to test\n",
        "    audio_files = find_audio_files()\n",
        "    if not audio_files:\n",
        "        print(\"No audio files found for testing\")\n",
        "        return\n",
        "\n",
        "    test_file = audio_files[0]\n",
        "    print(f\"Testing with: {test_file}\")\n",
        "\n",
        "    try:\n",
        "        # Load audio\n",
        "        y, sr = librosa.load(test_file, sr=16000, duration=30)  # 30 seconds max\n",
        "\n",
        "        # Extract basic features\n",
        "        print(\"Extracting features...\")\n",
        "\n",
        "        # MFCCs\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "        print(f\"MFCCs shape: {mfccs.shape}\")\n",
        "\n",
        "        # Spectral features\n",
        "        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "        print(f\"Spectral centroids shape: {spectral_centroids.shape}\")\n",
        "\n",
        "        # Zero crossing rate\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        print(f\"Zero crossing rate shape: {zcr.shape}\")\n",
        "\n",
        "        print(\"✓ Audio processing test successful!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Audio processing test failed: {e}\")\n",
        "\n",
        "# Main execution\n",
        "def run_startup_checks():\n",
        "    print(\"=== AD Detection Model Setup ===\\n\")\n",
        "\n",
        "    # Run all checks\n",
        "    setup_datasets()\n",
        "    explore_dataset_structure()\n",
        "    audio_files = find_audio_files()\n",
        "    check_labels()\n",
        "    test_audio_processing()\n",
        "\n",
        "    print(\"\\n=== Setup Complete ===\")\n",
        "    print(f\"Ready to proceed with model implementation!\")\n",
        "    print(f\"Found {len(audio_files) if 'audio_files' in locals() else 0} audio files to work with\")\n",
        "\n",
        "# Run the startup checks\n",
        "if __name__ == \"__main__\":\n",
        "    run_startup_checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSwjsVS-Qbg6",
        "outputId": "68e58532-9fa4-4fc0-a527-8db7d0d20d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Collecting speechrecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m857.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, speechrecognition, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydub-0.25.1 speechrecognition-3.14.3\n",
            "=== AD Detection Model Setup ===\n",
            "\n",
            "Checking dataset files...\n",
            "✓ Found: ADReSSo21-diagnosis-train.tgz\n",
            "✓ Found: ADReSSo21-progression-test.tgz\n",
            "✓ Found: ADReSSo21-progression-train.tgz\n",
            "\n",
            "Extracting datasets...\n",
            "Extracting ADReSSo21-diagnosis-train.tgz...\n",
            "✓ Extracted to /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train\n",
            "Extracting ADReSSo21-progression-test.tgz...\n",
            "✓ Extracted to /content/drive/MyDrive/Voice/ADReSSo21-progression-test\n",
            "Extracting ADReSSo21-progression-train.tgz...\n",
            "✓ Extracted to /content/drive/MyDrive/Voice/ADReSSo21-progression-train\n",
            "Dataset structure:\n",
            "/\n",
            "  ADReSSo21-diagnosis-train.tgz\n",
            "  ADReSSo21-progression-test.tgz\n",
            "  ADReSSo21-progression-train.tgz\n",
            "  task1.csv\n",
            "  task2.csv\n",
            "  ... and 8 more files\n",
            "Extracted_dataset/\n",
            "  diagnosis_train/\n",
            "    ADReSSo21/\n",
            "      diagnosis/\n",
            "        README.md\n",
            "        train/\n",
            "          adresso-train-mmse-scores.csv\n",
            "          segmentation/\n",
            "            cn/\n",
            "              adrso186.csv\n",
            "              adrso278.csv\n",
            "              adrso267.csv\n",
            "              adrso261.csv\n",
            "              adrso280.csv\n",
            "              ... and 74 more files\n",
            "            ad/\n",
            "              adrso031.csv\n",
            "              adrso035.csv\n",
            "              adrso054.csv\n",
            "              adrso028.csv\n",
            "              adrso049.csv\n",
            "              ... and 82 more files\n",
            "          audio/\n",
            "            cn/\n",
            "              adrso014.wav\n",
            "              adrso015.wav\n",
            "              adrso003.wav\n",
            "              adrso008.wav\n",
            "              adrso012.wav\n",
            "              ... and 74 more files\n",
            "            ad/\n",
            "              adrso036.wav\n",
            "              adrso043.wav\n",
            "              adrso024.wav\n",
            "              adrso045.wav\n",
            "              adrso049.wav\n",
            "              ... and 82 more files\n",
            "  progression_test/\n",
            "    ADReSSo21/\n",
            "      progression/\n",
            "        test-dist/\n",
            "          README\n",
            "          test_results_task3.csv\n",
            "          segmentation/\n",
            "            adrspt24.csv\n",
            "            adrspt12.csv\n",
            "            adrspt26.csv\n",
            "            adrspt11.csv\n",
            "            adrspt21.csv\n",
            "            ... and 10 more files\n",
            "          audio/\n",
            "            adrspt26.wav\n",
            "            adrspt5.wav\n",
            "            adrspt20.wav\n",
            "            adrspt22.wav\n",
            "            adrspt32.wav\n",
            "            ... and 27 more files\n",
            "  progression_train/\n",
            "    ADReSSo21/\n",
            "      progression/\n",
            "        README.md\n",
            "        train/\n",
            "          segmentation/\n",
            "            no_decline/\n",
            "              adrsp039.csv\n",
            "              adrsp207.csv\n",
            "              adrsp030.csv\n",
            "              adrsp001.csv\n",
            "              adrsp136.csv\n",
            "              ... and 32 more files\n",
            "            decline/\n",
            "              adrsp101.csv\n",
            "              adrsp051.csv\n",
            "              adrsp266.csv\n",
            "              adrsp127.csv\n",
            "              adrsp313.csv\n",
            "              ... and 5 more files\n",
            "          audio/\n",
            "            no_decline/\n",
            "              adrsp196.wav\n",
            "              adrsp137.wav\n",
            "              adrsp130.wav\n",
            "              adrsp349.wav\n",
            "              adrsp198.wav\n",
            "              ... and 53 more files\n",
            "            decline/\n",
            "              adrsp055.wav\n",
            "              adrsp003.wav\n",
            "              adrsp300.wav\n",
            "              adrsp266.wav\n",
            "              adrsp320.wav\n",
            "              ... and 10 more files\n",
            "Persian_Translated_Dataset/\n",
            "  translation_template.json\n",
            "  translation_template.csv\n",
            "  translation_guidelines.txt\n",
            "  diagnosis_train/\n",
            "    ADReSSo21/\n",
            "      diagnosis/\n",
            "        train/\n",
            "          segmentation/\n",
            "            cn/\n",
            "            ad/\n",
            "          audio/\n",
            "            cn/\n",
            "            ad/\n",
            "  progression_test/\n",
            "    ADReSSo21/\n",
            "      progression/\n",
            "        test-dist/\n",
            "          segmentation/\n",
            "          audio/\n",
            "  progression_train/\n",
            "    ADReSSo21/\n",
            "      progression/\n",
            "        train/\n",
            "          segmentation/\n",
            "            no_decline/\n",
            "            decline/\n",
            "          audio/\n",
            "            no_decline/\n",
            "            decline/\n",
            "ADReSSo21-diagnosis-train/\n",
            "  ADReSSo21/\n",
            "    diagnosis/\n",
            "      README.md\n",
            "      train/\n",
            "        adresso-train-mmse-scores.csv\n",
            "        segmentation/\n",
            "          cn/\n",
            "            adrso281.csv\n",
            "            adrso308.csv\n",
            "            adrso270.csv\n",
            "            adrso022.csv\n",
            "            adrso298.csv\n",
            "            ... and 74 more files\n",
            "          ad/\n",
            "            adrso229.csv\n",
            "            adrso106.csv\n",
            "            adrso144.csv\n",
            "            adrso049.csv\n",
            "            adrso078.csv\n",
            "            ... and 82 more files\n",
            "        audio/\n",
            "          cn/\n",
            "            adrso173.wav\n",
            "            adrso015.wav\n",
            "            adrso307.wav\n",
            "            adrso283.wav\n",
            "            adrso167.wav\n",
            "            ... and 74 more files\n",
            "          ad/\n",
            "            adrso047.wav\n",
            "            adrso128.wav\n",
            "            adrso045.wav\n",
            "            adrso110.wav\n",
            "            adrso036.wav\n",
            "            ... and 82 more files\n",
            "ADReSSo21-progression-test/\n",
            "  ADReSSo21/\n",
            "    progression/\n",
            "      test-dist/\n",
            "        test_results_task3.csv\n",
            "        README\n",
            "        segmentation/\n",
            "          adrspt24.csv\n",
            "          adrspt15.csv\n",
            "          adrspt12.csv\n",
            "          adrspt2.csv\n",
            "          adrspt9.csv\n",
            "          ... and 10 more files\n",
            "        audio/\n",
            "          adrspt20.wav\n",
            "          adrspt15.wav\n",
            "          adrspt4.wav\n",
            "          adrspt28.wav\n",
            "          adrspt16.wav\n",
            "          ... and 27 more files\n",
            "ADReSSo21-progression-train/\n",
            "  ADReSSo21/\n",
            "    progression/\n",
            "      README.md\n",
            "      train/\n",
            "        segmentation/\n",
            "          no_decline/\n",
            "            adrsp195.csv\n",
            "            adrsp041.csv\n",
            "            adrsp030.csv\n",
            "            adrsp052.csv\n",
            "            adrsp349.csv\n",
            "            ... and 32 more files\n",
            "          decline/\n",
            "            adrsp051.csv\n",
            "            adrsp313.csv\n",
            "            adrsp101.csv\n",
            "            adrsp055.csv\n",
            "            adrsp179.csv\n",
            "            ... and 5 more files\n",
            "        audio/\n",
            "          no_decline/\n",
            "            adrsp196.wav\n",
            "            adrsp137.wav\n",
            "            adrsp130.wav\n",
            "            adrsp349.wav\n",
            "            adrsp198.wav\n",
            "            ... and 53 more files\n",
            "          decline/\n",
            "            adrsp055.wav\n",
            "            adrsp003.wav\n",
            "            adrsp266.wav\n",
            "            adrsp300.wav\n",
            "            adrsp320.wav\n",
            "            ... and 10 more files\n",
            "\n",
            "Found 542 audio files\n",
            "\n",
            "Sample audio files:\n",
            "1. /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso014.wav\n",
            "2. /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso015.wav\n",
            "3. /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso003.wav\n",
            "4. /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso008.wav\n",
            "5. /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso012.wav\n",
            "\n",
            "Analyzing first audio file: /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso014.wav\n",
            "Sample rate: 22050 Hz\n",
            "Duration: 10.00 seconds\n",
            "Audio shape: (220500,)\n",
            "\n",
            "Found 473 potential label files:\n",
            "- /content/drive/MyDrive/Voice/task1.csv\n",
            "- /content/drive/MyDrive/Voice/task2.csv\n",
            "- /content/drive/MyDrive/Voice/task3.csv\n",
            "- /content/drive/MyDrive/Voice/unmatched_audio_ids.csv\n",
            "- /content/drive/MyDrive/Voice/unmatched_task1_ids.csv\n",
            "- /content/drive/MyDrive/Voice/missing_audio_ids.csv\n",
            "- /content/drive/MyDrive/Voice/task1_acoustic_features.csv\n",
            "- /content/drive/MyDrive/Voice/segmentation_ids.csv\n",
            "- /content/drive/MyDrive/Voice/skipped_files.csv\n",
            "- /content/drive/MyDrive/Voice/task1_linguistic_features.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/adresso-train-mmse-scores.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso186.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso278.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso267.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso261.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso280.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso276.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso148.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso265.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso002.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso167.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso270.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso177.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso153.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso173.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso021.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso005.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso266.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso172.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso170.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso156.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso023.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso260.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso158.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso268.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso017.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso154.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso259.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso018.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso257.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso264.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso165.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso015.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso012.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso022.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso151.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso157.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso007.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso263.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso182.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso014.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso273.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso159.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso019.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso168.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso169.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso164.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso008.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso152.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso016.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso183.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso010.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso277.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso162.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso161.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso274.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso262.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso003.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso180.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso178.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso160.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso300.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso291.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso283.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso310.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso309.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso289.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso315.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso299.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso298.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso285.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso307.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso286.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso316.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso281.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso296.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso308.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso302.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso312.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/cn/adrso292.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso031.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso035.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso054.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso028.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso049.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso045.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso036.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso032.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso027.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso047.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso024.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso043.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso053.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso039.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso033.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso025.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso046.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso197.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso234.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso098.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso122.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso134.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso192.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso249.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso200.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso128.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso223.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso222.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso142.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso077.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso072.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso218.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso093.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso237.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso236.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso071.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso246.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso144.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso215.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso247.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso248.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso209.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso232.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso060.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso092.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso089.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso187.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso229.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso206.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso070.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso205.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso220.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso211.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso130.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso106.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso063.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso190.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso228.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso059.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso078.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso188.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso253.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso141.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso125.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso233.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso075.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso189.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso224.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso123.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso068.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso202.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso212.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso138.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso245.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso216.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso198.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso126.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso109.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso116.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso110.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso074.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso055.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso112.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso056.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso090.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso244.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/segmentation/ad/adrso250.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/test_results_task3.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt24.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt12.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt26.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt11.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt21.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt17.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt29.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt13.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt1.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt23.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt18.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt10.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt15.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt2.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_test/ADReSSo21/progression/test-dist/segmentation/adrspt9.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp039.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp207.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp030.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp001.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp136.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp193.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp319.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp052.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp056.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp196.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp130.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp321.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp124.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp198.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp157.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp042.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp161.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp177.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp253.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp137.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp028.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp197.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp041.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp195.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp122.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp007.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp031.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp043.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp192.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp350.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp200.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp306.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp310.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp251.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp024.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp148.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/no_decline/adrsp349.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/decline/adrsp101.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/decline/adrsp051.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/decline/adrsp266.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/decline/adrsp127.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/decline/adrsp313.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/decline/adrsp300.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/decline/adrsp003.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/decline/adrsp055.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/decline/adrsp209.csv\n",
            "- /content/drive/MyDrive/Voice/Extracted_dataset/progression_train/ADReSSo21/progression/train/segmentation/decline/adrsp179.csv\n",
            "- /content/drive/MyDrive/Voice/Persian_Translated_Dataset/translation_template.json\n",
            "- /content/drive/MyDrive/Voice/Persian_Translated_Dataset/translation_template.csv\n",
            "- /content/drive/MyDrive/Voice/Persian_Translated_Dataset/translation_guidelines.txt\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/adresso-train-mmse-scores.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso281.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso308.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso270.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso022.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso298.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso300.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso265.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso186.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso148.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso152.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso182.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso268.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso259.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso276.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso261.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso262.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso018.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso170.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso263.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso172.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso277.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso280.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso168.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso267.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso007.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso158.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso309.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso292.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso021.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso157.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso286.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso291.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso260.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso156.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso315.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso167.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso302.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso178.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso289.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso161.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso162.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso173.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso154.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso003.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso019.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso023.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso017.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso274.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso299.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso264.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso180.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso014.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso183.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso266.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso159.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso153.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso283.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso316.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso312.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso310.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso164.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso016.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso002.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso008.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso285.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso307.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso177.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso160.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso015.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso278.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso273.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso257.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso012.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso169.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso010.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso165.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso296.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso005.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/cn/adrso151.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso229.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso106.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso144.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso049.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso078.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso209.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso247.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso092.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso077.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso198.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso031.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso090.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso116.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso036.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso206.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso128.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso110.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso032.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso224.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso142.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso126.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso054.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso187.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso028.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso222.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso212.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso053.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso189.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso244.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso200.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso098.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso192.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso033.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso218.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso027.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso246.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso130.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso056.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso190.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso245.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso070.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso215.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso220.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso232.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso075.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso035.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso055.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso188.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso109.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso047.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso063.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso089.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso248.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso138.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso072.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso228.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso093.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso134.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso216.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso046.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso249.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso068.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso237.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso060.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso202.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso223.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso233.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso059.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso234.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso123.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso025.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso253.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso045.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso043.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso250.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso071.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso074.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso122.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso197.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso141.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso236.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso125.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso211.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso024.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso112.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso205.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/segmentation/ad/adrso039.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/test_results_task3.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt24.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt15.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt12.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt2.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt9.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt10.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt29.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt11.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt17.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt18.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt1.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt13.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt26.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt21.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-test/ADReSSo21/progression/test-dist/segmentation/adrspt23.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp195.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp041.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp030.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp052.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp349.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp197.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp207.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp043.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp198.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp148.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp056.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp042.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp161.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp137.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp157.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp321.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp251.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp196.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp306.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp028.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp039.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp122.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp193.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp319.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp177.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp130.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp136.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp350.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp253.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp001.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp124.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp007.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp310.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp024.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp192.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp200.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/no_decline/adrsp031.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/decline/adrsp051.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/decline/adrsp313.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/decline/adrsp101.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/decline/adrsp055.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/decline/adrsp179.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/decline/adrsp300.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/decline/adrsp209.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/decline/adrsp127.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/decline/adrsp266.csv\n",
            "- /content/drive/MyDrive/Voice/ADReSSo21-progression-train/ADReSSo21/progression/train/segmentation/decline/adrsp003.csv\n",
            "\n",
            "/content/drive/MyDrive/Voice/task1.csv (CSV):\n",
            "Shape: (71, 2)\n",
            "Columns: ['ID', 'Dx']\n",
            "         ID       Dx\n",
            "0  adrsdt15  Control\n",
            "1  adrsdt40  Control\n",
            "2  adrsdt26  Control\n",
            "3  adrsdt67  Control\n",
            "4  adrsdt58  Control\n",
            "\n",
            "/content/drive/MyDrive/Voice/task2.csv (CSV):\n",
            "Shape: (71, 2)\n",
            "Columns: ['ID', 'MMSE']\n",
            "         ID  MMSE\n",
            "0  adrsdt15    30\n",
            "1  adrsdt40    28\n",
            "2  adrsdt26    29\n",
            "3  adrsdt67    30\n",
            "4  adrsdt58    29\n",
            "\n",
            "/content/drive/MyDrive/Voice/task3.csv (CSV):\n",
            "Shape: (32, 2)\n",
            "Columns: ['ID', 'Decline']\n",
            "         ID  Decline\n",
            "0   adrspt2    False\n",
            "1  adrspt18    False\n",
            "2   adrspt9     True\n",
            "3  adrspt21    False\n",
            "4  adrspt29    False\n",
            "\n",
            "Testing audio processing...\n",
            "\n",
            "Found 542 audio files\n",
            "\n",
            "Sample audio files:\n",
            "1. /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso014.wav\n",
            "2. /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso015.wav\n",
            "3. /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso003.wav\n",
            "4. /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso008.wav\n",
            "5. /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso012.wav\n",
            "\n",
            "Analyzing first audio file: /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso014.wav\n",
            "Sample rate: 22050 Hz\n",
            "Duration: 10.00 seconds\n",
            "Audio shape: (220500,)\n",
            "Testing with: /content/drive/MyDrive/Voice/Extracted_dataset/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso014.wav\n",
            "Extracting features...\n",
            "MFCCs shape: (13, 938)\n",
            "Spectral centroids shape: (1, 938)\n",
            "Zero crossing rate shape: (1, 938)\n",
            "✓ Audio processing test successful!\n",
            "\n",
            "=== Setup Complete ===\n",
            "Ready to proceed with model implementation!\n",
            "Found 542 audio files to work with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multimodal Alzheimer's Detection Model Implementation\n",
        "# Based on BERT + DARTS Architecture\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import speech_recognition as sr\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tarfile\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Step 1: Setup and Installation\n",
        "def install_dependencies():\n",
        "    \"\"\"Install required packages\"\"\"\n",
        "    import subprocess\n",
        "    import sys\n",
        "\n",
        "    packages = [\n",
        "        'torch torchvision torchaudio',\n",
        "        'transformers',\n",
        "        'librosa',\n",
        "        'SpeechRecognition',\n",
        "        'pydub',\n",
        "        'scikit-learn',\n",
        "        'matplotlib',\n",
        "        'seaborn',\n",
        "        'pandas',\n",
        "        'numpy',\n",
        "        'tqdm'\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
        "        except:\n",
        "            print(f\"Failed to install {package}\")\n",
        "\n",
        "# Step 2: Dataset Extraction and Loading\n",
        "class ADReSSoDatasetLoader:\n",
        "    def __init__(self, base_path=\"/content/drive/MyDrive/Voice/\"):\n",
        "        self.base_path = base_path\n",
        "        self.train_diagnosis_path = os.path.join(base_path, \"ADReSSo21-diagnosis-train.tgz\")\n",
        "        self.train_progression_path = os.path.join(base_path, \"ADReSSo21-progression-train.tgz\")\n",
        "        self.test_progression_path = os.path.join(base_path, \"ADReSSo21-progression-test.tgz\")\n",
        "\n",
        "        # Extract datasets\n",
        "        self.extract_datasets()\n",
        "\n",
        "    def extract_datasets(self):\n",
        "        \"\"\"Extract all dataset archives\"\"\"\n",
        "        datasets = [\n",
        "            (self.train_diagnosis_path, \"diagnosis_train\"),\n",
        "            (self.train_progression_path, \"progression_train\"),\n",
        "            (self.test_progression_path, \"progression_test\")\n",
        "        ]\n",
        "\n",
        "        for archive_path, folder_name in datasets:\n",
        "            if os.path.exists(archive_path):\n",
        "                extract_path = os.path.join(self.base_path, folder_name)\n",
        "                if not os.path.exists(extract_path):\n",
        "                    print(f\"Extracting {archive_path}...\")\n",
        "                    with tarfile.open(archive_path, 'r:gz') as tar:\n",
        "                        tar.extractall(extract_path)\n",
        "                    print(f\"Extracted to {extract_path}\")\n",
        "                else:\n",
        "                    print(f\"{folder_name} already extracted\")\n",
        "\n",
        "    def load_audio_files(self):\n",
        "        \"\"\"Load all audio files and their labels\"\"\"\n",
        "        audio_files = []\n",
        "        labels = []\n",
        "\n",
        "        # Load diagnosis training data\n",
        "        diagnosis_path = os.path.join(self.base_path, \"diagnosis_train\")\n",
        "        if os.path.exists(diagnosis_path):\n",
        "            # Look for audio files and corresponding labels\n",
        "            for root, dirs, files in os.walk(diagnosis_path):\n",
        "                for file in files:\n",
        "                    if file.endswith(('.wav', '.mp3', '.flac')):\n",
        "                        audio_path = os.path.join(root, file)\n",
        "                        # Extract label from filename or folder structure\n",
        "                        # Assuming AD/Control classification from folder or filename\n",
        "                        if 'ad' in file.lower() or 'ad' in root.lower():\n",
        "                            label = 1  # AD patient\n",
        "                        else:\n",
        "                            label = 0  # Control\n",
        "\n",
        "                        audio_files.append(audio_path)\n",
        "                        labels.append(label)\n",
        "\n",
        "        return audio_files, labels\n",
        "\n",
        "# Step 3: Audio Feature Extraction\n",
        "class AudioFeatureExtractor:\n",
        "    def __init__(self, sample_rate=16000):\n",
        "        self.sample_rate = sample_rate\n",
        "\n",
        "    def extract_acoustic_features(self, audio_path):\n",
        "        \"\"\"Extract comprehensive acoustic features\"\"\"\n",
        "        try:\n",
        "            # Load audio\n",
        "            y, sr = librosa.load(audio_path, sr=self.sample_rate)\n",
        "\n",
        "            # Extract various acoustic features\n",
        "            features = {}\n",
        "\n",
        "            # Spectral features\n",
        "            features['mfcc'] = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "            features['spectral_centroid'] = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "            features['spectral_rolloff'] = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "            features['spectral_bandwidth'] = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "            features['zero_crossing_rate'] = librosa.feature.zero_crossing_rate(y)\n",
        "\n",
        "            # Prosodic features\n",
        "            features['tempo'], _ = librosa.beat.beat_track(y=y, sr=sr)\n",
        "            features['chroma'] = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "            features['tonnetz'] = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr)\n",
        "\n",
        "            # Aggregate features (mean, std, etc.)\n",
        "            aggregated_features = []\n",
        "            for key, value in features.items():\n",
        "                if key == 'tempo':\n",
        "                    aggregated_features.append(value)\n",
        "                else:\n",
        "                    if value.ndim > 1:\n",
        "                        aggregated_features.extend([\n",
        "                            np.mean(value, axis=1),\n",
        "                            np.std(value, axis=1),\n",
        "                            np.max(value, axis=1),\n",
        "                            np.min(value, axis=1)\n",
        "                        ])\n",
        "                    else:\n",
        "                        aggregated_features.extend([\n",
        "                            np.mean(value),\n",
        "                            np.std(value),\n",
        "                            np.max(value),\n",
        "                            np.min(value)\n",
        "                        ])\n",
        "\n",
        "            # Flatten all features\n",
        "            feature_vector = np.concatenate([f.flatten() if hasattr(f, 'flatten') else [f]\n",
        "                                          for f in aggregated_features])\n",
        "\n",
        "            return feature_vector\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting features from {audio_path}: {e}\")\n",
        "            return np.zeros(200)  # Return zero vector if extraction fails\n",
        "\n",
        "# Step 4: Speech-to-Text and Linguistic Feature Extraction\n",
        "class SpeechToTextProcessor:\n",
        "    def __init__(self):\n",
        "        self.recognizer = sr.Recognizer()\n",
        "\n",
        "    def audio_to_text(self, audio_path):\n",
        "        \"\"\"Convert audio to text using speech recognition\"\"\"\n",
        "        try:\n",
        "            # Convert audio to wav if needed\n",
        "            audio_data, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "            # Save as temporary wav file\n",
        "            temp_path = \"/tmp/temp_audio.wav\"\n",
        "            librosa.output.write_wav(temp_path, audio_data, sr)\n",
        "\n",
        "            # Perform speech recognition\n",
        "            with sr.AudioFile(temp_path) as source:\n",
        "                audio = self.recognizer.record(source)\n",
        "                text = self.recognizer.recognize_google(audio)\n",
        "\n",
        "            # Clean up temp file\n",
        "            if os.path.exists(temp_path):\n",
        "                os.remove(temp_path)\n",
        "\n",
        "            return text\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Speech recognition failed for {audio_path}: {e}\")\n",
        "            return \"unable to transcribe audio\"\n",
        "\n",
        "    def extract_linguistic_features(self, text):\n",
        "        \"\"\"Extract linguistic features from text\"\"\"\n",
        "        if not text or len(text.strip()) == 0:\n",
        "            return {\n",
        "                'word_count': 0,\n",
        "                'sentence_count': 0,\n",
        "                'avg_word_length': 0,\n",
        "                'avg_sentence_length': 0,\n",
        "                'pause_count': 0,\n",
        "                'filler_count': 0\n",
        "            }\n",
        "\n",
        "        words = text.split()\n",
        "        sentences = text.split('.')\n",
        "\n",
        "        # Count fillers and pauses\n",
        "        fillers = ['um', 'uh', 'er', 'ah', 'hmm']\n",
        "        filler_count = sum(1 for word in words if word.lower() in fillers)\n",
        "\n",
        "        features = {\n",
        "            'word_count': len(words),\n",
        "            'sentence_count': len(sentences),\n",
        "            'avg_word_length': np.mean([len(word) for word in words]) if words else 0,\n",
        "            'avg_sentence_length': np.mean([len(sent.split()) for sent in sentences]) if sentences else 0,\n",
        "            'pause_count': text.count('...') + text.count(','),\n",
        "            'filler_count': filler_count\n",
        "        }\n",
        "\n",
        "        return features\n",
        "\n",
        "# Step 5: DARTS Implementation\n",
        "class DARTSCell(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DARTSCell, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        # Define possible operations\n",
        "        self.operations = nn.ModuleList([\n",
        "            nn.Identity(),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(input_dim, output_dim, 1),\n",
        "            nn.Conv1d(input_dim, output_dim, 3, padding=1),\n",
        "            nn.MaxPool1d(3, stride=1, padding=1),\n",
        "            nn.AvgPool1d(3, stride=1, padding=1)\n",
        "        ])\n",
        "\n",
        "        # Architecture parameters (alpha)\n",
        "        self.alpha = nn.Parameter(torch.randn(len(self.operations)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply softmax to architecture parameters\n",
        "        weights = F.softmax(self.alpha, dim=0)\n",
        "\n",
        "        # Weighted combination of all operations\n",
        "        output = sum(w * op(x) for w, op in zip(weights, self.operations))\n",
        "        return output\n",
        "\n",
        "class DARTSNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers=3):\n",
        "        super(DARTSNetwork, self).__init__()\n",
        "\n",
        "        self.input_projection = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # Stack multiple DARTS cells\n",
        "        self.cells = nn.ModuleList([\n",
        "            DARTSCell(hidden_dim, hidden_dim) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.output_projection = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, input_dim)\n",
        "        x = self.input_projection(x)\n",
        "        x = x.unsqueeze(-1)  # Add sequence dimension for conv1d\n",
        "\n",
        "        for cell in self.cells:\n",
        "            x = cell(x)\n",
        "\n",
        "        x = x.squeeze(-1)  # Remove sequence dimension\n",
        "        x = self.output_projection(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Step 6: BERT Text Processing\n",
        "class BERTProcessor:\n",
        "    def __init__(self, model_name='bert-base-uncased'):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "        self.model = BertModel.from_pretrained(model_name)\n",
        "        self.model.eval()\n",
        "\n",
        "    def encode_text(self, text, max_length=512):\n",
        "        \"\"\"Encode text using BERT\"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            text,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            # Use CLS token representation\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "\n",
        "        return cls_embedding\n",
        "\n",
        "# Step 7: Multimodal Fusion Model\n",
        "class MultimodalFusionModel(nn.Module):\n",
        "    def __init__(self, audio_dim, text_dim, hidden_dim=256, num_classes=2):\n",
        "        super(MultimodalFusionModel, self).__init__()\n",
        "\n",
        "        # Audio processing with DARTS\n",
        "        self.audio_darts = DARTSNetwork(audio_dim, hidden_dim)\n",
        "\n",
        "        # Text processing\n",
        "        self.text_projection = nn.Linear(text_dim, hidden_dim)\n",
        "\n",
        "        # Fusion methods\n",
        "        self.fusion_method = 'concatenation'  # Can be changed to other methods\n",
        "\n",
        "        if self.fusion_method == 'concatenation':\n",
        "            fusion_dim = hidden_dim * 2\n",
        "        elif self.fusion_method == 'tucker':\n",
        "            fusion_dim = hidden_dim\n",
        "        elif self.fusion_method == 'mfb':\n",
        "            fusion_dim = hidden_dim\n",
        "        elif self.fusion_method == 'block':\n",
        "            fusion_dim = hidden_dim\n",
        "        else:\n",
        "            fusion_dim = hidden_dim * 2\n",
        "\n",
        "        # Final classification layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(fusion_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, audio_features, text_features):\n",
        "        # Process audio features through DARTS\n",
        "        audio_repr = self.audio_darts(audio_features)\n",
        "\n",
        "        # Process text features\n",
        "        text_repr = self.text_projection(text_features)\n",
        "\n",
        "        # Fusion\n",
        "        if self.fusion_method == 'concatenation':\n",
        "            fused = torch.cat([audio_repr, text_repr], dim=1)\n",
        "        elif self.fusion_method == 'tucker':\n",
        "            fused = self.tucker_fusion(audio_repr, text_repr)\n",
        "        elif self.fusion_method == 'mfb':\n",
        "            fused = self.mfb_fusion(audio_repr, text_repr)\n",
        "        elif self.fusion_method == 'block':\n",
        "            fused = self.block_fusion(audio_repr, text_repr)\n",
        "        else:\n",
        "            fused = torch.cat([audio_repr, text_repr], dim=1)\n",
        "\n",
        "        # Classification\n",
        "        output = self.classifier(fused)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def tucker_fusion(self, audio, text):\n",
        "        \"\"\"Tucker decomposition fusion\"\"\"\n",
        "        # Simplified Tucker fusion\n",
        "        outer_product = torch.bmm(audio.unsqueeze(2), text.unsqueeze(1))\n",
        "        fused = torch.mean(outer_product, dim=[1, 2])\n",
        "        return fused\n",
        "\n",
        "    def mfb_fusion(self, audio, text):\n",
        "        \"\"\"Multimodal Factorized Bilinear pooling\"\"\"\n",
        "        # Simplified MFB\n",
        "        expanded_audio = audio.unsqueeze(2).expand(-1, -1, text.size(1))\n",
        "        expanded_text = text.unsqueeze(1).expand(-1, audio.size(1), -1)\n",
        "        fused = torch.sum(expanded_audio * expanded_text, dim=2)\n",
        "        return fused\n",
        "\n",
        "    def block_fusion(self, audio, text):\n",
        "        \"\"\"Block fusion\"\"\"\n",
        "        # Element-wise multiplication and addition\n",
        "        fused = audio * text + audio + text\n",
        "        return fused\n",
        "\n",
        "# Step 8: Dataset Class\n",
        "class ADReSSoDataset(Dataset):\n",
        "    def __init__(self, audio_files, labels, audio_extractor, text_processor, bert_processor):\n",
        "        self.audio_files = audio_files\n",
        "        self.labels = labels\n",
        "        self.audio_extractor = audio_extractor\n",
        "        self.text_processor = text_processor\n",
        "        self.bert_processor = bert_processor\n",
        "\n",
        "        # Pre-extract features to avoid repeated computation\n",
        "        self.audio_features = []\n",
        "        self.text_features = []\n",
        "\n",
        "        print(\"Extracting features...\")\n",
        "        for audio_file in tqdm(audio_files):\n",
        "            # Extract audio features\n",
        "            audio_feat = self.audio_extractor.extract_acoustic_features(audio_file)\n",
        "            self.audio_features.append(audio_feat)\n",
        "\n",
        "            # Convert audio to text and extract BERT features\n",
        "            text = self.text_processor.audio_to_text(audio_file)\n",
        "            text_feat = self.bert_processor.encode_text(text)\n",
        "            self.text_features.append(text_feat.squeeze(0))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_feat = torch.FloatTensor(self.audio_features[idx])\n",
        "        text_feat = self.text_features[idx]\n",
        "        label = torch.LongTensor([self.labels[idx]])\n",
        "\n",
        "        return audio_feat, text_feat, label\n",
        "\n",
        "# Step 9: Training Function\n",
        "def train_model(model, train_loader, val_loader, num_epochs=50, learning_rate=0.001):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for audio_feat, text_feat, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "            audio_feat, text_feat, labels = audio_feat.to(device), text_feat.to(device), labels.to(device)\n",
        "            labels = labels.squeeze()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(audio_feat, text_feat)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for audio_feat, text_feat, labels in val_loader:\n",
        "                audio_feat, text_feat, labels = audio_feat.to(device), text_feat.to(device), labels.to(device)\n",
        "                labels = labels.squeeze()\n",
        "\n",
        "                outputs = model(audio_feat, text_feat)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * val_correct / val_total\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return train_losses, val_accuracies\n",
        "\n",
        "# Step 10: Main Execution Function\n",
        "def main():\n",
        "    print(\"Starting Multimodal AD Detection Model Training...\")\n",
        "\n",
        "    # Initialize components\n",
        "    dataset_loader = ADReSSoDatasetLoader()\n",
        "    audio_extractor = AudioFeatureExtractor()\n",
        "    text_processor = SpeechToTextProcessor()\n",
        "    bert_processor = BERTProcessor()\n",
        "\n",
        "    # Load data\n",
        "    print(\"Loading audio files...\")\n",
        "    audio_files, labels = dataset_loader.load_audio_files()\n",
        "\n",
        "    if len(audio_files) == 0:\n",
        "        print(\"No audio files found. Please check dataset paths.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(audio_files)} audio files\")\n",
        "\n",
        "    # Split data\n",
        "    train_files, val_files, train_labels, val_labels = train_test_split(\n",
        "        audio_files, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "    )\n",
        "\n",
        "    # Create datasets\n",
        "    print(\"Creating datasets...\")\n",
        "    train_dataset = ADReSSoDataset(train_files, train_labels, audio_extractor, text_processor, bert_processor)\n",
        "    val_dataset = ADReSSoDataset(val_files, val_labels, audio_extractor, text_processor, bert_processor)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "    # Get feature dimensions\n",
        "    audio_dim = len(train_dataset.audio_features[0])\n",
        "    text_dim = train_dataset.text_features[0].shape[0]\n",
        "\n",
        "    print(f\"Audio feature dimension: {audio_dim}\")\n",
        "    print(f\"Text feature dimension: {text_dim}\")\n",
        "\n",
        "    # Initialize model\n",
        "    model = MultimodalFusionModel(audio_dim=audio_dim, text_dim=text_dim)\n",
        "\n",
        "    # Train model\n",
        "    print(\"Starting training...\")\n",
        "    train_losses, val_accuracies = train_model(model, train_loader, val_loader)\n",
        "\n",
        "    # Plot training curves\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses)\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(val_accuracies)\n",
        "    plt.title('Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/Voice/multimodal_ad_model.pth')\n",
        "    print(\"Model saved successfully!\")\n",
        "\n",
        "    return model, train_loader, val_loader\n",
        "\n",
        "# Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Install dependencies first\n",
        "    install_dependencies()\n",
        "\n",
        "    # Run main function\n",
        "    model, train_loader, val_loader = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7bf06daf7ef343fa8c2b375431b7af36",
            "9b530f1b74054a8fa35bc2ac517fe3fb",
            "d3df08063e094052b1f5f47c22772e8f",
            "f0e990dd85344c68966eeef2b5d7cf87",
            "b10f7f1d33bb44c6af55445d5eebfa9b",
            "c9bacee7f786439bbdcbeb8e1f54b1a2",
            "4168ef5d074941dba8fe2e54ec58fe2a",
            "c60c110815304064bb2666e3f99adb79",
            "18fefffee8a64763b4a607c855cf31cd",
            "3ecec58d85be4c8a85b68eb8e3306b2e",
            "c30ecbf53c3c4ac486701a557e57110f",
            "83aa8a6596e244a3abb864fc6ad754f4",
            "8c167186174d47d78cf1e5ed9f3de24f",
            "759200fcf6c349cda87bd7af2495d5ae",
            "cb894524e6884943b59bc3785856c4e6",
            "5459ae5e6ba348d396f50d58854db8ab",
            "3c3c1297cbb74ab59f00ba2061d4bcd1",
            "63d9755a4afb4c8c8fa979a2af20ef0e",
            "ea9cce16349a41e38ce186fb619564b1",
            "8fe5c9d35a44424db31afec4617819e3",
            "b6f0f9b5734c4350b446f8701ca9a950",
            "3fd9245e09614e738da9b8a23f87e45f",
            "bd37c3f7ea09403f80d22ce18342b081",
            "120830e90b684f0ba009538fd1484dc5",
            "c16fea3ee442475e943e8344e4fc12b4",
            "211d60e410a04d2aac64f8f9dc7a8720",
            "1cab200c311c4f669221ee0417a3d9ab",
            "bce161a6fd364bf193572322e7f551d9",
            "5684f080ea23494cb048c7ab26c21b94",
            "bbb7e6ebdad3440aabadca01d0901c5a",
            "22cef289a4e44b54ba32fc4fa99f52e3",
            "1a8de18c03734dc48e1056e870fea32e",
            "7ed222a9238a4d41bca5d8012bcf69e9",
            "087fb7b4b0e5423188d3a88f68deae5c",
            "965648fa43f044169b95c11f4f95afb8",
            "6802598135ae484d85b2434cd23e3d3a",
            "dbe8184cf37a4a9b9c2312bb5e639115",
            "23d17f19a7bb40f8887d6bfa69944cc2",
            "04ffc5a1c406499a9d49070578a584c0",
            "5afc1676a8324843b909a51eb4e98b6f",
            "5574e1731db247a9ba1f24aef9eaf73d",
            "6a9de8952b294ad99b6758263aa046c8",
            "4a31c8c724bf44578defc5b61297ecef",
            "b66976d5e779456a84a378fb6efa22bf",
            "d8fb59d637e34960a7fa06b743b23a87",
            "d3a9526f2c734d79beb72b7a8c0d8cfa",
            "03a46c1d36294f689cd929c0a26ac322",
            "3a99e6f19901430e9ed69254515eab2d",
            "474386d1004f4d7a90a047f60bef4505",
            "9d5d9c486520445285788c3f2f20c3c9",
            "ab262d42ec32455283e6a985115e09dc",
            "83dc802c05dd4cb4b9b61b23e754e545",
            "e14d0945463f4b1285d3c17261ec55ee",
            "11d17caaeed84714842faf6f3f625044",
            "38a9401f685942009f34e6b3e66e09da"
          ]
        },
        "id": "DoTpYKb2QVBw",
        "outputId": "e8b1e184-391d-4ffa-b620-76fff914adf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to install torch torchvision torchaudio\n",
            "Starting Multimodal AD Detection Model Training...\n",
            "Extracting /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train.tgz...\n",
            "Extracted to /content/drive/MyDrive/Voice/diagnosis_train\n",
            "Extracting /content/drive/MyDrive/Voice/ADReSSo21-progression-train.tgz...\n",
            "Extracted to /content/drive/MyDrive/Voice/progression_train\n",
            "Extracting /content/drive/MyDrive/Voice/ADReSSo21-progression-test.tgz...\n",
            "Extracted to /content/drive/MyDrive/Voice/progression_test\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bf06daf7ef343fa8c2b375431b7af36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83aa8a6596e244a3abb864fc6ad754f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd37c3f7ea09403f80d22ce18342b081"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "087fb7b4b0e5423188d3a88f68deae5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8fb59d637e34960a7fa06b743b23a87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading audio files...\n",
            "Found 166 audio files\n",
            "Creating datasets...\n",
            "Extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/132 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso257.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/132 [00:21<47:55, 21.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso183.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/132 [00:30<30:47, 14.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso178.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 3/132 [00:35<21:07,  9.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso125.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 4/132 [00:41<17:31,  8.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso268.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 5/132 [00:47<15:48,  7.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso262.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 6/132 [00:52<13:58,  6.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso274.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 7/132 [01:03<16:59,  8.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso248.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 8/132 [01:10<16:11,  7.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso192.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 9/132 [01:20<17:30,  8.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso177.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 10/132 [01:27<16:01,  7.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso160.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 11/132 [01:31<13:48,  6.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso156.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 12/132 [01:38<13:36,  6.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso180.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 13/132 [01:43<12:27,  6.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso157.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 14/132 [01:50<12:35,  6.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso110.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 15/132 [01:56<12:26,  6.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso106.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 16/132 [02:03<12:54,  6.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso028.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 17/132 [02:09<12:02,  6.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso316.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 18/132 [02:15<11:59,  6.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso093.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 19/132 [02:21<11:41,  6.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso010.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 20/132 [02:24<09:45,  5.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso259.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 21/132 [02:32<10:59,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso197.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 22/132 [02:39<11:25,  6.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso273.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 23/132 [02:45<11:14,  6.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso232.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 24/132 [02:51<11:22,  6.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso046.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 25/132 [03:00<12:45,  7.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso043.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 26/132 [03:11<14:21,  8.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso016.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 27/132 [03:15<12:12,  6.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso039.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 28/132 [03:21<11:35,  6.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso266.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 29/132 [03:27<11:09,  6.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso109.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 30/132 [03:34<11:23,  6.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso002.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 31/132 [03:41<11:29,  6.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso292.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 32/132 [03:46<10:05,  6.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso144.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 33/132 [03:53<10:35,  6.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso173.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 34/132 [03:59<10:23,  6.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso053.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 35/132 [04:14<14:24,  8.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso312.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 36/132 [04:21<13:28,  8.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso033.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 37/132 [04:28<12:27,  7.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso291.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 38/132 [04:35<12:09,  7.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso018.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 39/132 [04:41<10:50,  7.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso300.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 40/132 [04:44<09:18,  6.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso027.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 41/132 [04:52<09:55,  6.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso170.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 42/132 [04:56<08:43,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso003.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 43/132 [05:01<07:59,  5.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso035.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 44/132 [05:07<08:32,  5.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso070.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 45/132 [05:13<08:25,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso276.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 46/132 [05:26<11:28,  8.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso078.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 47/132 [05:38<12:43,  8.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso072.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▋      | 48/132 [05:43<10:59,  7.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso098.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 49/132 [05:49<10:16,  7.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso280.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 50/132 [05:58<10:42,  7.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso122.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 51/132 [06:03<09:18,  6.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso289.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 52/132 [06:10<09:07,  6.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso159.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 53/132 [06:14<08:16,  6.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso148.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 54/132 [06:23<08:56,  6.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso019.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 55/132 [06:28<08:05,  6.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso315.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 56/132 [06:33<07:41,  6.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso310.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 57/132 [06:39<07:33,  6.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso307.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 58/132 [06:45<07:19,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso264.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 59/132 [06:52<07:48,  6.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso165.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 60/132 [06:57<07:10,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso168.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 61/132 [07:06<07:51,  6.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso299.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 62/132 [07:18<09:44,  8.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso222.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 63/132 [07:24<08:46,  7.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso308.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 64/132 [07:30<08:14,  7.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso267.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 65/132 [07:36<07:34,  6.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso309.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 66/132 [07:41<06:50,  6.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso265.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 67/132 [07:50<07:49,  7.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso188.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 68/132 [07:57<07:25,  6.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso190.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 69/132 [08:07<08:10,  7.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso123.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 70/132 [08:12<07:17,  7.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso112.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 71/132 [08:18<06:53,  6.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso211.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 72/132 [08:24<06:25,  6.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso296.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 73/132 [08:33<07:19,  7.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso206.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 74/132 [08:40<06:58,  7.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso128.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 75/132 [08:48<07:09,  7.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso092.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 76/132 [08:52<06:00,  6.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso116.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 77/132 [09:02<06:44,  7.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso278.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 78/132 [09:05<05:31,  6.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso045.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 79/132 [09:21<08:05,  9.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso209.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 80/132 [09:32<08:22,  9.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso049.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 81/132 [09:45<08:57, 10.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso277.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 82/132 [09:51<07:39,  9.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso161.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 83/132 [09:55<06:24,  7.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso142.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 84/132 [09:59<05:15,  6.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso164.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 85/132 [10:09<05:52,  7.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso021.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 86/132 [10:15<05:25,  7.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso172.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 87/132 [10:23<05:35,  7.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso154.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 88/132 [10:28<04:52,  6.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso054.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 89/132 [10:41<06:04,  8.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso286.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 90/132 [10:46<05:11,  7.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso153.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 91/132 [10:54<05:22,  7.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso298.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 92/132 [11:01<05:01,  7.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso134.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 93/132 [11:06<04:21,  6.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso283.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 94/132 [11:13<04:15,  6.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso202.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 95/132 [11:26<05:26,  8.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso234.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 96/132 [11:33<04:57,  8.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso223.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 97/132 [11:41<04:43,  8.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso200.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 98/132 [11:53<05:12,  9.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso245.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 99/132 [11:57<04:14,  7.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso233.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 100/132 [12:05<04:08,  7.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso162.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 101/132 [12:11<03:45,  7.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso249.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 102/132 [12:16<03:18,  6.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso056.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 103/132 [12:38<05:20, 11.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso055.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 104/132 [12:46<04:46, 10.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso059.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 105/132 [12:50<03:47,  8.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso023.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 106/132 [12:56<03:18,  7.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso253.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 107/132 [13:02<02:57,  7.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso186.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 108/132 [13:06<02:27,  6.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso031.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 109/132 [13:13<02:31,  6.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso224.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 110/132 [13:19<02:17,  6.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso036.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 111/132 [13:24<02:04,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso158.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 112/132 [13:30<01:58,  5.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso090.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 113/132 [13:38<02:05,  6.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso302.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 114/132 [13:45<02:02,  6.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso060.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 115/132 [13:52<01:53,  6.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso068.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 116/132 [13:56<01:36,  6.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso071.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 117/132 [14:02<01:27,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso025.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 118/132 [14:17<02:03,  8.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso215.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 119/132 [14:25<01:48,  8.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso005.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 120/132 [14:31<01:31,  7.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso032.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 121/132 [14:38<01:22,  7.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso074.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 122/132 [14:47<01:18,  7.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso075.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 123/132 [14:51<01:00,  6.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso077.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 124/132 [14:55<00:48,  6.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso012.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 125/132 [15:02<00:43,  6.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso167.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 126/132 [15:09<00:38,  6.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso220.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 127/132 [15:19<00:38,  7.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso047.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 128/132 [15:25<00:28,  7.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso189.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 129/132 [15:31<00:20,  6.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso007.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 130/132 [15:34<00:11,  5.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso216.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 131/132 [15:51<00:09,  9.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso263.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 132/132 [15:57<00:00,  7.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/34 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso246.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 1/34 [00:04<02:44,  4.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso260.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 2/34 [00:10<02:46,  5.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso244.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 3/34 [00:17<03:12,  6.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso228.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 4/34 [00:23<03:05,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso198.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 5/34 [00:33<03:37,  7.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso141.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 6/34 [00:38<03:05,  6.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso281.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 7/34 [00:45<02:58,  6.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso130.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 8/34 [00:48<02:27,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso089.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 9/34 [00:54<02:20,  5.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso151.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 10/34 [00:59<02:12,  5.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso237.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 11/34 [01:05<02:06,  5.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso205.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 12/34 [01:11<02:08,  5.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso152.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 13/34 [01:17<01:59,  5.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso126.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 14/34 [01:24<02:05,  6.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso261.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 15/34 [01:35<02:24,  7.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso182.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 16/34 [01:42<02:11,  7.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso236.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 17/34 [01:47<01:56,  6.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso250.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 18/34 [01:54<01:50,  6.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso015.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 19/34 [02:02<01:46,  7.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso270.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 20/34 [02:08<01:37,  6.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso218.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 21/34 [02:15<01:27,  6.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso008.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 22/34 [02:20<01:14,  6.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso138.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 23/34 [02:26<01:06,  6.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso063.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 24/34 [02:31<01:00,  6.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso024.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 25/34 [02:49<01:26,  9.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso229.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 26/34 [02:58<01:15,  9.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso169.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 27/34 [03:02<00:54,  7.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso285.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 28/34 [03:07<00:41,  6.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso187.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 29/34 [03:14<00:35,  7.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso017.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 30/34 [03:20<00:26,  6.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso022.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 31/34 [03:25<00:18,  6.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/cn/adrso014.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 32/34 [03:30<00:11,  5.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso247.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 33/34 [03:37<00:06,  6.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech recognition failed for /content/drive/MyDrive/Voice/diagnosis_train/ADReSSo21/diagnosis/train/audio/ad/adrso212.wav: No librosa attribute output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 34/34 [03:47<00:00,  6.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio feature dimension: 141\n",
            "Text feature dimension: 768\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|██████████| 17/17 [00:00<00:00, 19.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 0.3956, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|██████████| 17/17 [00:00<00:00, 38.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|██████████| 17/17 [00:00<00:00, 39.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|██████████| 17/17 [00:00<00:00, 26.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|██████████| 17/17 [00:00<00:00, 29.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|██████████| 17/17 [00:00<00:00, 26.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|██████████| 17/17 [00:00<00:00, 27.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|██████████| 17/17 [00:00<00:00, 27.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|██████████| 17/17 [00:00<00:00, 27.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|██████████| 17/17 [00:00<00:00, 40.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|██████████| 17/17 [00:00<00:00, 40.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|██████████| 17/17 [00:00<00:00, 39.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|██████████| 17/17 [00:00<00:00, 40.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|██████████| 17/17 [00:00<00:00, 38.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|██████████| 17/17 [00:00<00:00, 38.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|██████████| 17/17 [00:00<00:00, 38.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|██████████| 17/17 [00:00<00:00, 39.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|██████████| 17/17 [00:00<00:00, 39.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|██████████| 17/17 [00:00<00:00, 39.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|██████████| 17/17 [00:00<00:00, 40.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|██████████| 17/17 [00:00<00:00, 38.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|██████████| 17/17 [00:00<00:00, 40.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|██████████| 17/17 [00:00<00:00, 37.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|██████████| 17/17 [00:00<00:00, 40.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|██████████| 17/17 [00:00<00:00, 39.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|██████████| 17/17 [00:00<00:00, 40.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|██████████| 17/17 [00:00<00:00, 39.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|██████████| 17/17 [00:00<00:00, 39.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|██████████| 17/17 [00:00<00:00, 40.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|██████████| 17/17 [00:00<00:00, 36.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|██████████| 17/17 [00:00<00:00, 31.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|██████████| 17/17 [00:00<00:00, 26.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|██████████| 17/17 [00:00<00:00, 25.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|██████████| 17/17 [00:00<00:00, 27.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|██████████| 17/17 [00:00<00:00, 25.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|██████████| 17/17 [00:00<00:00, 26.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|██████████| 17/17 [00:00<00:00, 36.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|██████████| 17/17 [00:00<00:00, 32.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|██████████| 17/17 [00:00<00:00, 29.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|██████████| 17/17 [00:00<00:00, 25.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|██████████| 17/17 [00:00<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|██████████| 17/17 [00:00<00:00, 22.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|██████████| 17/17 [00:00<00:00, 21.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|██████████| 17/17 [00:00<00:00, 20.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|██████████| 17/17 [00:00<00:00, 19.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|██████████| 17/17 [00:00<00:00, 19.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|██████████| 17/17 [00:00<00:00, 18.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|██████████| 17/17 [00:00<00:00, 19.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|██████████| 17/17 [00:00<00:00, 19.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|██████████| 17/17 [00:01<00:00, 15.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/50], Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    }
  ]
}