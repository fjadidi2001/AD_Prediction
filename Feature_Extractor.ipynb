{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0FelwvuRbS75c4TzW6HV7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40960d55efa441d2b158e6e0fe63077a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a17d9ab799164229ad08c9e998d84c51",
              "IPY_MODEL_53278ddc6fd1487492106840fa0751d9",
              "IPY_MODEL_db17250f75d442c1b7450d725bd03a6f"
            ],
            "layout": "IPY_MODEL_3848481dcf7c4db4a822ded47a5bf601"
          }
        },
        "a17d9ab799164229ad08c9e998d84c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_938d6fe7b4284499b6a6a55e8e095a22",
            "placeholder": "​",
            "style": "IPY_MODEL_d928e0a5813d435e819d3b05b349a3c3",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "53278ddc6fd1487492106840fa0751d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dd5610b4e1c4f599cee8193468234bd",
            "max": 159,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_197d4ae5095b41b8befcbc576609e6d4",
            "value": 159
          }
        },
        "db17250f75d442c1b7450d725bd03a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b07143b1572e4fd7842732d3dd757dc3",
            "placeholder": "​",
            "style": "IPY_MODEL_477a715d2e1a4d1faf7ced7136d69379",
            "value": " 159/159 [00:00&lt;00:00, 16.1kB/s]"
          }
        },
        "3848481dcf7c4db4a822ded47a5bf601": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "938d6fe7b4284499b6a6a55e8e095a22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d928e0a5813d435e819d3b05b349a3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dd5610b4e1c4f599cee8193468234bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "197d4ae5095b41b8befcbc576609e6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b07143b1572e4fd7842732d3dd757dc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "477a715d2e1a4d1faf7ced7136d69379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "088d5a120dd64a7aaa93e8d424683342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d62585867bf84642950a9fe65584ddd4",
              "IPY_MODEL_edf4369a7ba9479db9153994f0e13ca4",
              "IPY_MODEL_b94422555c044377ab6080d06159e7a6"
            ],
            "layout": "IPY_MODEL_ed98871df826448794d275a47c6785c1"
          }
        },
        "d62585867bf84642950a9fe65584ddd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2975592d064419386693374bfcd90d2",
            "placeholder": "​",
            "style": "IPY_MODEL_dbee618031074ea5a2e8c1ea9c539a95",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "edf4369a7ba9479db9153994f0e13ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a9ddc68fcfd4828945d925714939630",
            "max": 163,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a058c37c0a7b47999a7ee7c388a70f0a",
            "value": 163
          }
        },
        "b94422555c044377ab6080d06159e7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_291ef24f8476457c8340f7398ddad96b",
            "placeholder": "​",
            "style": "IPY_MODEL_64595b99ad5e40bd8442e7ce4be67369",
            "value": " 163/163 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "ed98871df826448794d275a47c6785c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2975592d064419386693374bfcd90d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbee618031074ea5a2e8c1ea9c539a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a9ddc68fcfd4828945d925714939630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a058c37c0a7b47999a7ee7c388a70f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "291ef24f8476457c8340f7398ddad96b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64595b99ad5e40bd8442e7ce4be67369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dff5a4609d714b6c91025747ebaa3478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c037648347944323b796c9a552ccc9e0",
              "IPY_MODEL_baf20cbb8c8b429a8aa0b16f3518fb12",
              "IPY_MODEL_4ab20b40e7ab4b3998c6572e27712ec4"
            ],
            "layout": "IPY_MODEL_5fdffaa8b962485cbe410ef39a363339"
          }
        },
        "c037648347944323b796c9a552ccc9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_256f4f0fa466471592a8832e1405eb8f",
            "placeholder": "​",
            "style": "IPY_MODEL_6ebdefd8857a499eaccf000b96e92739",
            "value": "config.json: 100%"
          }
        },
        "baf20cbb8c8b429a8aa0b16f3518fb12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_680c056f7a514ecfa654d43d6440fdbe",
            "max": 1596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_988aed1dbca845f6bdbbf66dd0f6304b",
            "value": 1596
          }
        },
        "4ab20b40e7ab4b3998c6572e27712ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30101f0e0cf142cea17a5b5898053da6",
            "placeholder": "​",
            "style": "IPY_MODEL_88537849a1a24b87a45aed47ff175ce0",
            "value": " 1.60k/1.60k [00:00&lt;00:00, 177kB/s]"
          }
        },
        "5fdffaa8b962485cbe410ef39a363339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256f4f0fa466471592a8832e1405eb8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ebdefd8857a499eaccf000b96e92739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "680c056f7a514ecfa654d43d6440fdbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988aed1dbca845f6bdbbf66dd0f6304b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30101f0e0cf142cea17a5b5898053da6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88537849a1a24b87a45aed47ff175ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a30fc303453469faf10dbe079407d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9fb1a4c35ca44bc86fe527d60e2763f",
              "IPY_MODEL_5bd9da0a83374709b0b2a61cea33aa00",
              "IPY_MODEL_5804ba69f0344ea1be846a2406fba1fd"
            ],
            "layout": "IPY_MODEL_4de16b2fbeff49de999963553339cb99"
          }
        },
        "d9fb1a4c35ca44bc86fe527d60e2763f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee762db049214f6c94e6a4610ec0b452",
            "placeholder": "​",
            "style": "IPY_MODEL_1df674a058b64ee5aa7ce882e63a8763",
            "value": "vocab.json: 100%"
          }
        },
        "5bd9da0a83374709b0b2a61cea33aa00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce1603e5a97a4481b9e24ff3da403f6c",
            "max": 291,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea3e92ffc10f41fc9b166394c60e4cc8",
            "value": 291
          }
        },
        "5804ba69f0344ea1be846a2406fba1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c17a3bd02e6e41efaa80bf3bf177e289",
            "placeholder": "​",
            "style": "IPY_MODEL_a6bf2424aded472fb2529c9739beecea",
            "value": " 291/291 [00:00&lt;00:00, 26.9kB/s]"
          }
        },
        "4de16b2fbeff49de999963553339cb99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee762db049214f6c94e6a4610ec0b452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1df674a058b64ee5aa7ce882e63a8763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce1603e5a97a4481b9e24ff3da403f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3e92ffc10f41fc9b166394c60e4cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c17a3bd02e6e41efaa80bf3bf177e289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6bf2424aded472fb2529c9739beecea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "063bbab92409464192c8780e98bb43db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9e9570dcb184e0b819db86b664fa64e",
              "IPY_MODEL_0b6a13fba02842d586e92650be8dbb80",
              "IPY_MODEL_5815193c69a348b7978773e8db83d1cc"
            ],
            "layout": "IPY_MODEL_3c39a512390149ac827311ddf0d8912f"
          }
        },
        "d9e9570dcb184e0b819db86b664fa64e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83d0e718636c4f4099b119c42edaf76d",
            "placeholder": "​",
            "style": "IPY_MODEL_e2119721ee1045078ccb7332d506fb4a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "0b6a13fba02842d586e92650be8dbb80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b1cb3d15f3243049e358fc13420519f",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e8d5707fc954af5b0ec58517ae2a2df",
            "value": 85
          }
        },
        "5815193c69a348b7978773e8db83d1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_930432ec5ae74649bb516508b18d065a",
            "placeholder": "​",
            "style": "IPY_MODEL_02853940d47c4aa182cd2bd2babbe22c",
            "value": " 85.0/85.0 [00:00&lt;00:00, 6.57kB/s]"
          }
        },
        "3c39a512390149ac827311ddf0d8912f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83d0e718636c4f4099b119c42edaf76d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2119721ee1045078ccb7332d506fb4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b1cb3d15f3243049e358fc13420519f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e8d5707fc954af5b0ec58517ae2a2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "930432ec5ae74649bb516508b18d065a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02853940d47c4aa182cd2bd2babbe22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/Feature_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation script for Google Colab\n",
        "# Run this cell first to install all required dependencies\n",
        "\n",
        "!pip install librosa\n",
        "!pip install opensmile\n",
        "!pip install transformers\n",
        "!pip install torch torchaudio\n",
        "!pip install SpeechRecognition\n",
        "!pip install pydub\n",
        "!pip install scipy\n",
        "!pip install scikit-learn\n",
        "\n",
        "# For audio processing\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq ffmpeg\n",
        "\n",
        "print(\"All dependencies installed successfully!\")\n",
        "\n",
        "# Additional setup for speech recognition\n",
        "import speech_recognition as sr\n",
        "print(f\"SpeechRecognition version: {sr.__version__}\")\n",
        "\n",
        "# Test imports\n",
        "try:\n",
        "    import librosa\n",
        "    import opensmile\n",
        "    import torch\n",
        "    import torchaudio\n",
        "    from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    print(\"✅ All imports successful!\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Import error: {e}\")\n",
        "\n",
        "# Create the main processing script\n",
        "processing_script = '''\n",
        "# ADReSSo21 Dataset Processing - Simplified Version for Colab\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class SimpleADReSSo21Processor:\n",
        "    def __init__(self, base_path=\"/content/drive/MyDrive/Voice/extracted/ADReSSo21\"):\n",
        "        self.base_path = base_path\n",
        "\n",
        "    def show_acoustic_features_info(self):\n",
        "        \"\"\"Step 1: Show each acoustic feature description\"\"\"\n",
        "        features_info = {\n",
        "            'eGeMAPS': {\n",
        "                'description': 'Extended Geneva Minimalistic Acoustic Parameter Set',\n",
        "                'features': 88,\n",
        "                'includes': ['Frequency features', 'Energy features', 'Spectral features', 'Temporal features']\n",
        "            },\n",
        "            'TRILL': {\n",
        "                'description': 'Triplet Loss Network for Universal Speech Representations',\n",
        "                'features': 512,\n",
        "                'includes': ['Self-supervised learned representations', 'Language-agnostic features']\n",
        "            },\n",
        "            'Allosaurus': {\n",
        "                'description': 'Universal phonetic recognition features',\n",
        "                'features': 'Variable',\n",
        "                'includes': ['Phonetic transcriptions', 'Cross-lingual phonetic features']\n",
        "            },\n",
        "            'Wav2Vec2': {\n",
        "                'description': 'Self-supervised speech representations',\n",
        "                'features': 768,\n",
        "                'includes': ['Contextualized speech representations', 'Transformer-based features']\n",
        "            },\n",
        "            'MFCCs': {\n",
        "                'description': 'Mel-Frequency Cepstral Coefficients',\n",
        "                'features': 52,\n",
        "                'includes': ['13 MFCC coefficients × 4 statistics (mean, std, max, min)']\n",
        "            },\n",
        "            'Log-Mel': {\n",
        "                'description': 'Log-Mel Spectrogram Features',\n",
        "                'features': 320,\n",
        "                'includes': ['80 mel-scale frequency bins × 4 statistics']\n",
        "            },\n",
        "            'Delta': {\n",
        "                'description': 'Delta and Delta-Delta Features',\n",
        "                'features': 52,\n",
        "                'includes': ['First derivatives (velocity)', 'Second derivatives (acceleration)']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(\"🎵 ACOUSTIC FEATURES OVERVIEW 🎵\\\\n\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for name, info in features_info.items():\n",
        "            print(f\"📊 {name}\")\n",
        "            print(f\"   Description: {info['description']}\")\n",
        "            print(f\"   Features: {info['features']}\")\n",
        "            print(f\"   Includes: {', '.join(info['includes'])}\")\n",
        "            print(\"-\"*40)\n",
        "\n",
        "        return features_info\n",
        "\n",
        "    def extract_basic_acoustic_features(self, audio_path):\n",
        "        \"\"\"Extract basic acoustic features that work reliably in Colab\"\"\"\n",
        "        try:\n",
        "            # Load audio\n",
        "            audio, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "            # Basic spectral features\n",
        "            spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
        "            spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
        "            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)\n",
        "            zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)\n",
        "\n",
        "            # MFCC features\n",
        "            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "\n",
        "            # Mel-spectrogram\n",
        "            mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=40)\n",
        "            log_mel = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "            # Delta features\n",
        "            delta_mfccs = librosa.feature.delta(mfccs)\n",
        "            delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
        "\n",
        "            # Compile features\n",
        "            features = {}\n",
        "\n",
        "            # Basic spectral statistics\n",
        "            features.update({\n",
        "                'spectral_centroid_mean': np.mean(spectral_centroids),\n",
        "                'spectral_centroid_std': np.std(spectral_centroids),\n",
        "                'spectral_rolloff_mean': np.mean(spectral_rolloff),\n",
        "                'spectral_rolloff_std': np.std(spectral_rolloff),\n",
        "                'spectral_bandwidth_mean': np.mean(spectral_bandwidth),\n",
        "                'spectral_bandwidth_std': np.std(spectral_bandwidth),\n",
        "                'zero_crossing_rate_mean': np.mean(zero_crossing_rate),\n",
        "                'zero_crossing_rate_std': np.std(zero_crossing_rate),\n",
        "            })\n",
        "\n",
        "            # MFCC statistics\n",
        "            for i in range(13):\n",
        "                features[f'mfcc_{i}_mean'] = np.mean(mfccs[i])\n",
        "                features[f'mfcc_{i}_std'] = np.std(mfccs[i])\n",
        "\n",
        "            # Log-Mel statistics (first 20 bands)\n",
        "            for i in range(20):\n",
        "                features[f'logmel_{i}_mean'] = np.mean(log_mel[i])\n",
        "                features[f'logmel_{i}_std'] = np.std(log_mel[i])\n",
        "\n",
        "            # Delta MFCC statistics\n",
        "            for i in range(13):\n",
        "                features[f'delta_mfcc_{i}_mean'] = np.mean(delta_mfccs[i])\n",
        "                features[f'delta2_mfcc_{i}_mean'] = np.mean(delta2_mfccs[i])\n",
        "\n",
        "            return features\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {audio_path}: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def simple_transcribe(self, audio_path):\n",
        "        \"\"\"Simple transcription placeholder - replace with actual ASR\"\"\"\n",
        "        # This is a placeholder - in practice, you would use:\n",
        "        # - Google Speech-to-Text API\n",
        "        # - Whisper model\n",
        "        # - Other ASR services\n",
        "\n",
        "        filename = os.path.basename(audio_path)\n",
        "        return f\"[Transcription placeholder for {filename}]\"\n",
        "\n",
        "    def process_sample_files(self):\n",
        "        \"\"\"Process the sample files provided\"\"\"\n",
        "        sample_files = [\n",
        "            \"/content/drive/MyDrive/Voice/extracted/ADReSSo21/diagnosis/train/audio/ad/adrso024.wav\",\n",
        "            \"/content/drive/MyDrive/Voice/extracted/ADReSSo21/diagnosis/train/audio/cn/adrso002.wav\",\n",
        "            \"/content/drive/MyDrive/Voice/extracted/ADReSSo21/progression/train/audio/decline/adrsp003.wav\",\n",
        "            \"/content/drive/MyDrive/Voice/extracted/ADReSSo21/progression/train/audio/no_decline/adrsp001.wav\",\n",
        "            \"/content/drive/MyDrive/Voice/extracted/ADReSSo21/progression/test-dist/audio/adrspt1.wav\"\n",
        "        ]\n",
        "\n",
        "        results = []\n",
        "        transcripts = []\n",
        "\n",
        "        print(\"🎤 PROCESSING AUDIO FILES 🎤\\\\n\")\n",
        "\n",
        "        for audio_path in sample_files:\n",
        "            if os.path.exists(audio_path):\n",
        "                print(f\"Processing: {os.path.basename(audio_path)}\")\n",
        "\n",
        "                # Extract features\n",
        "                features = self.extract_basic_acoustic_features(audio_path)\n",
        "\n",
        "                # Transcribe\n",
        "                transcript = self.simple_transcribe(audio_path)\n",
        "\n",
        "                # Determine task and label from path\n",
        "                path_parts = audio_path.split('/')\n",
        "                task = 'diagnosis' if 'diagnosis' in path_parts else 'progression'\n",
        "\n",
        "                if 'ad' in path_parts:\n",
        "                    label = 'ad'\n",
        "                elif 'cn' in path_parts:\n",
        "                    label = 'cn'\n",
        "                elif 'decline' in path_parts:\n",
        "                    label = 'decline'\n",
        "                elif 'no_decline' in path_parts:\n",
        "                    label = 'no_decline'\n",
        "                else:\n",
        "                    label = 'test'\n",
        "\n",
        "                file_id = os.path.basename(audio_path).replace('.wav', '')\n",
        "\n",
        "                # Compile result\n",
        "                result = {\n",
        "                    'file_id': file_id,\n",
        "                    'task': task,\n",
        "                    'label': label,\n",
        "                    'audio_path': audio_path,\n",
        "                    'transcript': transcript,\n",
        "                    **features\n",
        "                }\n",
        "\n",
        "                results.append(result)\n",
        "\n",
        "                # Save transcript info\n",
        "                transcripts.append({\n",
        "                    'file_id': file_id,\n",
        "                    'task': task,\n",
        "                    'label': label,\n",
        "                    'transcript': transcript,\n",
        "                    'audio_path': audio_path\n",
        "                })\n",
        "\n",
        "                print(f\"✅ Completed: {file_id}\")\n",
        "                print(f\"   Features extracted: {len(features)}\")\n",
        "                print(f\"   Transcript: {transcript[:50]}...\")\n",
        "                print()\n",
        "            else:\n",
        "                print(f\"❌ File not found: {audio_path}\")\n",
        "\n",
        "        return pd.DataFrame(results), pd.DataFrame(transcripts)\n",
        "\n",
        "    def save_transcripts_to_files(self, transcripts_df, output_dir='/content'):\n",
        "        \"\"\"Step 3: Save transcripts to individual files\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        saved_files = []\n",
        "\n",
        "        print(\"💾 SAVING TRANSCRIPT FILES 💾\\\\n\")\n",
        "\n",
        "        for idx, row in transcripts_df.iterrows():\n",
        "            filename = f\"{row['file_id']}_transcript.txt\"\n",
        "            filepath = os.path.join(output_dir, filename)\n",
        "\n",
        "            with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                f.write(f\"File ID: {row['file_id']}\\\\n\")\n",
        "                f.write(f\"Task: {row['task']}\\\\n\")\n",
        "                f.write(f\"Label: {row['label']}\\\\n\")\n",
        "                f.write(f\"Audio Path: {row['audio_path']}\\\\n\")\n",
        "                f.write(f\"Transcript: {row['transcript']}\\\\n\")\n",
        "\n",
        "            saved_files.append(filepath)\n",
        "            print(f\"✅ Saved: {filename}\")\n",
        "\n",
        "        print(f\"\\\\n📁 Total files saved: {len(saved_files)}\")\n",
        "        return saved_files\n",
        "\n",
        "    def extract_linguistic_features(self, text):\n",
        "        \"\"\"Step 5: Extract linguistic features for BERT preparation\"\"\"\n",
        "        # Basic text statistics\n",
        "        words = text.split()\n",
        "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
        "\n",
        "        features = {\n",
        "            'text': text,  # Original text for BERT\n",
        "            'word_count': len(words),\n",
        "            'char_count': len(text),\n",
        "            'sentence_count': len(sentences),\n",
        "            'avg_word_length': np.mean([len(word) for word in words]) if words else 0,\n",
        "            'avg_sentence_length': np.mean([len(s.split()) for s in sentences]) if sentences else 0,\n",
        "        }\n",
        "\n",
        "        # Lexical diversity\n",
        "        if words:\n",
        "            unique_words = set(word.lower() for word in words)\n",
        "            features['lexical_diversity'] = len(unique_words) / len(words)\n",
        "            features['unique_words'] = len(unique_words)\n",
        "        else:\n",
        "            features['lexical_diversity'] = 0\n",
        "            features['unique_words'] = 0\n",
        "\n",
        "        # Simple complexity measures\n",
        "        features['complexity_score'] = features['unique_words'] / features['sentence_count'] if features['sentence_count'] > 0 else 0\n",
        "\n",
        "        # BERT preparation features\n",
        "        features['bert_input'] = text  # Clean text for BERT tokenization\n",
        "        features['bert_length'] = len(text.split())  # For sequence length planning\n",
        "\n",
        "        return features\n",
        "\n",
        "def run_complete_pipeline():\n",
        "    \"\"\"Run the complete ADReSSo21 processing pipeline\"\"\"\n",
        "\n",
        "    print(\"🚀 ADReSSo21 DATASET PROCESSING PIPELINE 🚀\\\\n\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Initialize processor\n",
        "    processor = SimpleADReSSo21Processor()\n",
        "\n",
        "    # Step 0 & 1: Show acoustic features\n",
        "    print(\"\\\\n📋 STEP 0-1: ACOUSTIC FEATURES OVERVIEW\")\n",
        "    features_info = processor.show_acoustic_features_info()\n",
        "\n",
        "    # Step 2: Process files and extract transcripts\n",
        "    print(\"\\\\n🎵 STEP 2: EXTRACTING FEATURES AND TRANSCRIPTS\")\n",
        "    results_df, transcripts_df = processor.process_sample_files()\n",
        "\n",
        "    # Step 3: Save transcript files\n",
        "    print(\"\\\\n💾 STEP 3: SAVING TRANSCRIPT FILES\")\n",
        "    transcript_files = processor.save_transcripts_to_files(transcripts_df)\n",
        "\n",
        "    # Step 4: Show transcripts table\n",
        "    print(\"\\\\n📊 STEP 4: TRANSCRIPTS TABLE\")\n",
        "    print(\"=\"*60)\n",
        "    print(transcripts_df.to_string(index=False))\n",
        "\n",
        "    # Step 5: Extract linguistic features for BERT\n",
        "    print(\"\\\\n🤖 STEP 5: LINGUISTIC FEATURES FOR BERT\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    linguistic_features = []\n",
        "    for idx, row in transcripts_df.iterrows():\n",
        "        ling_feats = processor.extract_linguistic_features(row['transcript'])\n",
        "        ling_feats['file_id'] = row['file_id']\n",
        "        ling_feats['task'] = row['task']\n",
        "        ling_feats['label'] = row['label']\n",
        "        linguistic_features.append(ling_feats)\n",
        "\n",
        "    linguistic_df = pd.DataFrame(linguistic_features)\n",
        "\n",
        "    print(\"Linguistic Features Summary:\")\n",
        "    print(\"-\" * 40)\n",
        "    for col in ['word_count', 'sentence_count', 'lexical_diversity', 'complexity_score']:\n",
        "        if col in linguistic_df.columns:\n",
        "            print(f\"{col}: mean={linguistic_df[col].mean():.2f}, std={linguistic_df[col].std():.2f}\")\n",
        "\n",
        "    print(\"\\\\nDetailed Linguistic Features:\")\n",
        "    print(linguistic_df[['file_id', 'task', 'label', 'word_count', 'sentence_count', 'lexical_diversity']].to_string(index=False))\n",
        "\n",
        "    # Save all results\n",
        "    print(\"\\\\n💾 SAVING RESULTS\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    # Save complete features\n",
        "    results_df.to_csv('/content/complete_acoustic_features.csv', index=False)\n",
        "    print(\"✅ Saved: /content/complete_acoustic_features.csv\")\n",
        "\n",
        "    # Save transcripts table\n",
        "    transcripts_df.to_csv('/content/transcripts_table.csv', index=False)\n",
        "    print(\"✅ Saved: /content/transcripts_table.csv\")\n",
        "\n",
        "    # Save linguistic features\n",
        "    linguistic_df.to_csv('/content/linguistic_features_for_bert.csv', index=False)\n",
        "    print(\"✅ Saved: /content/linguistic_features_for_bert.csv\")\n",
        "\n",
        "    # Create BERT-ready dataset\n",
        "    bert_ready_df = linguistic_df[['file_id', 'task', 'label', 'bert_input', 'bert_length']].copy()\n",
        "    bert_ready_df.to_csv('/content/bert_ready_dataset.csv', index=False)\n",
        "    print(\"✅ Saved: /content/bert_ready_dataset.csv\")\n",
        "\n",
        "    print(\"\\\\n🎉 PIPELINE COMPLETED SUCCESSFULLY! 🎉\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\\\nSummary:\")\n",
        "    print(f\"- Processed {len(results_df)} audio files\")\n",
        "    print(f\"- Extracted {len([col for col in results_df.columns if col not in ['file_id', 'task', 'label', 'audio_path', 'transcript']])} acoustic features per file\")\n",
        "    print(f\"- Created {len(transcript_files)} transcript files\")\n",
        "    print(f\"- Generated linguistic features for BERT processing\")\n",
        "    print(\"\\\\nOutput files in /content/:\")\n",
        "    print(\"- complete_acoustic_features.csv\")\n",
        "    print(\"- transcripts_table.csv\")\n",
        "    print(\"- linguistic_features_for_bert.csv\")\n",
        "    print(\"- bert_ready_dataset.csv\")\n",
        "    print(\"- Individual transcript .txt files\")\n",
        "\n",
        "    return results_df, transcripts_df, linguistic_df\n",
        "\n",
        "# Additional utility functions for BERT preparation\n",
        "def prepare_bert_inputs(linguistic_df, max_length=512):\n",
        "    \"\"\"Prepare inputs specifically for BERT model\"\"\"\n",
        "\n",
        "    bert_inputs = []\n",
        "\n",
        "    for idx, row in linguistic_df.iterrows():\n",
        "        # Clean and prepare text\n",
        "        text = row['bert_input'].strip()\n",
        "\n",
        "        # Truncate if too long (BERT has max sequence length)\n",
        "        words = text.split()\n",
        "        if len(words) > max_length - 2:  # Account for [CLS] and [SEP] tokens\n",
        "            text = ' '.join(words[:max_length-2])\n",
        "\n",
        "        bert_input = {\n",
        "            'file_id': row['file_id'],\n",
        "            'task': row['task'],\n",
        "            'label': row['label'],\n",
        "            'text': text,\n",
        "            'length': len(text.split()),\n",
        "            'ready_for_tokenization': True\n",
        "        }\n",
        "\n",
        "        bert_inputs.append(bert_input)\n",
        "\n",
        "    return pd.DataFrame(bert_inputs)\n",
        "\n",
        "def show_feature_statistics(results_df):\n",
        "    \"\"\"Show statistics for extracted acoustic features\"\"\"\n",
        "\n",
        "    print(\"\\\\n📈 ACOUSTIC FEATURES STATISTICS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Get feature columns (exclude metadata)\n",
        "    feature_cols = [col for col in results_df.columns\n",
        "                   if col not in ['file_id', 'task', 'label', 'audio_path', 'transcript']]\n",
        "\n",
        "    print(f\"Total acoustic features extracted: {len(feature_cols)}\")\n",
        "    print(\"\\\\nFeature categories:\")\n",
        "\n",
        "    categories = {\n",
        "        'Spectral': [col for col in feature_cols if 'spectral' in col],\n",
        "        'MFCC': [col for col in feature_cols if 'mfcc' in col and 'delta' not in col],\n",
        "        'Log-Mel': [col for col in feature_cols if 'logmel' in col],\n",
        "        'Delta': [col for col in feature_cols if 'delta' in col],\n",
        "        'Other': [col for col in feature_cols if not any(cat in col for cat in ['spectral', 'mfcc', 'logmel', 'delta'])]\n",
        "    }\n",
        "\n",
        "    for category, cols in categories.items():\n",
        "        if cols:\n",
        "            print(f\"- {category}: {len(cols)} features\")\n",
        "\n",
        "    # Show sample statistics\n",
        "    print(\"\\\\nSample feature statistics (first 5 features):\")\n",
        "    sample_features = feature_cols[:5]\n",
        "    for feat in sample_features:\n",
        "        values = results_df[feat].dropna()\n",
        "        if len(values) > 0:\n",
        "            print(f\"{feat}: mean={values.mean():.4f}, std={values.std():.4f}\")\n",
        "\n",
        "print(\"✅ Processing script created successfully!\")\n",
        "print(\"\\\\n🚀 To run the complete pipeline, execute:\")\n",
        "print(\"results_df, transcripts_df, linguistic_df = run_complete_pipeline()\")\n",
        "'''\n",
        "\n",
        "# Save the processing script\n",
        "with open('/content/adresso21_processor.py', 'w') as f:\n",
        "    f.write(processing_script)\n",
        "\n",
        "print(\"\\\\n📄 Main processing script saved as: /content/adresso21_processor.py\")\n",
        "print(\"\\\\n🔧 SETUP COMPLETE! Ready to process ADReSSo21 dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-h3XnMO6ygne",
        "outputId": "15fd31c6-41a7-440d-fdfe-174686496361"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "Collecting opensmile\n",
            "  Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
            "Collecting audobject>=0.6.1 (from opensmile)\n",
            "  Downloading audobject-0.7.11-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting audinterface>=0.7.0 (from opensmile)\n",
            "  Downloading audinterface-1.2.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting audeer>=2.1.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audeer-2.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audformat-1.3.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting audiofile>=1.3.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audiofile-1.5.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting audmath>=1.4.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audmath-1.4.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (8.7.0)\n",
            "Collecting oyaml (from audobject>=0.6.1->opensmile)\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from audeer>=2.1.1->audinterface>=0.7.0->opensmile) (4.67.1)\n",
            "Collecting iso639-lang (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso639_lang-2.6.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (6.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (2.0.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (0.13.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.17.0)\n",
            "Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl (996 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.0/996.0 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audinterface-1.2.3-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audobject-0.7.11-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audeer-2.2.1-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audformat-1.3.2-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audiofile-1.5.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audmath-1.4.1-py3-none-any.whl (23 kB)\n",
            "Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading iso639_lang-2.6.0-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: oyaml, iso639-lang, iso3166, audresample, audmath, audeer, audobject, audiofile, audformat, audinterface, opensmile\n",
            "Successfully installed audeer-2.2.1 audformat-1.3.2 audinterface-1.2.3 audiofile-1.5.1 audmath-1.4.1 audobject-0.7.11 audresample-1.3.3 iso3166-2.1.1 iso639-lang-2.6.0 opensmile-2.5.1 oyaml-1.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m839.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "b2a7b2d272e840d3b671958285755514"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.13.2)\n",
            "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.3\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "All dependencies installed successfully!\n",
            "SpeechRecognition version: 3.14.3\n",
            "✅ All imports successful!\n",
            "\\n📄 Main processing script saved as: /content/adresso21_processor.py\n",
            "\\n🔧 SETUP COMPLETE! Ready to process ADReSSo21 dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "40960d55efa441d2b158e6e0fe63077a",
            "a17d9ab799164229ad08c9e998d84c51",
            "53278ddc6fd1487492106840fa0751d9",
            "db17250f75d442c1b7450d725bd03a6f",
            "3848481dcf7c4db4a822ded47a5bf601",
            "938d6fe7b4284499b6a6a55e8e095a22",
            "d928e0a5813d435e819d3b05b349a3c3",
            "7dd5610b4e1c4f599cee8193468234bd",
            "197d4ae5095b41b8befcbc576609e6d4",
            "b07143b1572e4fd7842732d3dd757dc3",
            "477a715d2e1a4d1faf7ced7136d69379",
            "088d5a120dd64a7aaa93e8d424683342",
            "d62585867bf84642950a9fe65584ddd4",
            "edf4369a7ba9479db9153994f0e13ca4",
            "b94422555c044377ab6080d06159e7a6",
            "ed98871df826448794d275a47c6785c1",
            "e2975592d064419386693374bfcd90d2",
            "dbee618031074ea5a2e8c1ea9c539a95",
            "3a9ddc68fcfd4828945d925714939630",
            "a058c37c0a7b47999a7ee7c388a70f0a",
            "291ef24f8476457c8340f7398ddad96b",
            "64595b99ad5e40bd8442e7ce4be67369",
            "dff5a4609d714b6c91025747ebaa3478",
            "c037648347944323b796c9a552ccc9e0",
            "baf20cbb8c8b429a8aa0b16f3518fb12",
            "4ab20b40e7ab4b3998c6572e27712ec4",
            "5fdffaa8b962485cbe410ef39a363339",
            "256f4f0fa466471592a8832e1405eb8f",
            "6ebdefd8857a499eaccf000b96e92739",
            "680c056f7a514ecfa654d43d6440fdbe",
            "988aed1dbca845f6bdbbf66dd0f6304b",
            "30101f0e0cf142cea17a5b5898053da6",
            "88537849a1a24b87a45aed47ff175ce0",
            "6a30fc303453469faf10dbe079407d2e",
            "d9fb1a4c35ca44bc86fe527d60e2763f",
            "5bd9da0a83374709b0b2a61cea33aa00",
            "5804ba69f0344ea1be846a2406fba1fd",
            "4de16b2fbeff49de999963553339cb99",
            "ee762db049214f6c94e6a4610ec0b452",
            "1df674a058b64ee5aa7ce882e63a8763",
            "ce1603e5a97a4481b9e24ff3da403f6c",
            "ea3e92ffc10f41fc9b166394c60e4cc8",
            "c17a3bd02e6e41efaa80bf3bf177e289",
            "a6bf2424aded472fb2529c9739beecea",
            "063bbab92409464192c8780e98bb43db",
            "d9e9570dcb184e0b819db86b664fa64e",
            "0b6a13fba02842d586e92650be8dbb80",
            "5815193c69a348b7978773e8db83d1cc",
            "3c39a512390149ac827311ddf0d8912f",
            "83d0e718636c4f4099b119c42edaf76d",
            "e2119721ee1045078ccb7332d506fb4a",
            "8b1cb3d15f3243049e358fc13420519f",
            "5e8d5707fc954af5b0ec58517ae2a2df",
            "930432ec5ae74649bb516508b18d065a",
            "02853940d47c4aa182cd2bd2babbe22c"
          ]
        },
        "id": "YCI354LQrVqU",
        "outputId": "14221a41-c872-4015-d900-637117618da8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40960d55efa441d2b158e6e0fe63077a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "088d5a120dd64a7aaa93e8d424683342"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dff5a4609d714b6c91025747ebaa3478"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a30fc303453469faf10dbe079407d2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "063bbab92409464192c8780e98bb43db"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.stats\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
        "import opensmile\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class ADReSSo21Processor:\n",
        "    def __init__(self, base_path):\n",
        "        self.base_path = base_path\n",
        "        self.transcripts = {}\n",
        "        self.acoustic_features = {}\n",
        "        self.linguistic_features = {}\n",
        "\n",
        "        # Initialize models\n",
        "        self.wav2vec2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "        self.wav2vec2_model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "        self.smile = opensmile.Smile(\n",
        "            feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "            feature_level=opensmile.FeatureLevel.Functionals,\n",
        "        )\n",
        "\n",
        "    def get_file_paths(self):\n",
        "        \"\"\"Get all audio and segmentation file paths\"\"\"\n",
        "        paths = {\n",
        "            'diagnosis': {\n",
        "                'train': {\n",
        "                    'audio': {'ad': [], 'cn': []},\n",
        "                    'segmentation': {'ad': [], 'cn': []}\n",
        "                }\n",
        "            },\n",
        "            'progression': {\n",
        "                'train': {\n",
        "                    'audio': {'decline': [], 'no_decline': []},\n",
        "                    'segmentation': {'decline': [], 'no_decline': []}\n",
        "                },\n",
        "                'test-dist': {\n",
        "                    'audio': [],\n",
        "                    'segmentation': []\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Populate paths based on directory structure\n",
        "        for task in ['diagnosis', 'progression']:\n",
        "            task_path = os.path.join(self.base_path, task)\n",
        "            if task == 'diagnosis':\n",
        "                for split in ['train']:\n",
        "                    for data_type in ['audio', 'segmentation']:\n",
        "                        for label in ['ad', 'cn']:\n",
        "                            dir_path = os.path.join(task_path, split, data_type, label)\n",
        "                            if os.path.exists(dir_path):\n",
        "                                files = [f for f in os.listdir(dir_path) if f.endswith('.wav' if data_type == 'audio' else '.csv')]\n",
        "                                paths[task][split][data_type][label] = [os.path.join(dir_path, f) for f in files]\n",
        "            else:  # progression\n",
        "                for split in ['train', 'test-dist']:\n",
        "                    if split == 'train':\n",
        "                        for data_type in ['audio', 'segmentation']:\n",
        "                            for label in ['decline', 'no_decline']:\n",
        "                                dir_path = os.path.join(task_path, split, data_type, label)\n",
        "                                if os.path.exists(dir_path):\n",
        "                                    files = [f for f in os.listdir(dir_path) if f.endswith('.wav' if data_type == 'audio' else '.csv')]\n",
        "                                    paths[task][split][data_type][label] = [os.path.join(dir_path, f) for f in files]\n",
        "                    else:  # test-dist\n",
        "                        for data_type in ['audio', 'segmentation']:\n",
        "                            dir_path = os.path.join(task_path, split, data_type)\n",
        "                            if os.path.exists(dir_path):\n",
        "                                files = [f for f in os.listdir(dir_path) if f.endswith('.wav' if data_type == 'audio' else '.csv')]\n",
        "                                paths[task][split][data_type] = [os.path.join(dir_path, f) for f in files]\n",
        "\n",
        "        return paths\n",
        "\n",
        "    def extract_egmaps_features(self, audio_path):\n",
        "        \"\"\"Extract eGeMAPS features using openSMILE\"\"\"\n",
        "        try:\n",
        "            features = self.smile.process_file(audio_path)\n",
        "            return features.values.flatten()\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting eGeMAPS from {audio_path}: {e}\")\n",
        "            return np.zeros(88)  # eGeMAPS has 88 features\n",
        "\n",
        "    def extract_trill_features(self, audio_path):\n",
        "        \"\"\"Extract TRILL features (placeholder - requires TensorFlow Hub)\"\"\"\n",
        "        # Note: This would require tensorflow_hub and the TRILL model\n",
        "        # For now, returning placeholder features\n",
        "        try:\n",
        "            audio, sr = librosa.load(audio_path, sr=16000)\n",
        "            # Placeholder: extract spectral features as proxy\n",
        "            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "            return np.mean(mfccs, axis=1)\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting TRILL from {audio_path}: {e}\")\n",
        "            return np.zeros(512)  # TRILL typically has 512 dimensions\n",
        "\n",
        "    def extract_allsaurus_features(self, audio_path):\n",
        "        \"\"\"Extract Allosaurus features (placeholder - requires allosaurus library)\"\"\"\n",
        "        try:\n",
        "            audio, sr = librosa.load(audio_path, sr=16000)\n",
        "            # Placeholder: extract phonetic-related features\n",
        "            spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
        "            spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
        "            zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)\n",
        "\n",
        "            features = np.concatenate([\n",
        "                np.mean(spectral_centroids),\n",
        "                np.std(spectral_centroids),\n",
        "                np.mean(spectral_rolloff),\n",
        "                np.std(spectral_rolloff),\n",
        "                np.mean(zero_crossing_rate),\n",
        "                np.std(zero_crossing_rate)\n",
        "            ])\n",
        "            return features\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting Allosaurus from {audio_path}: {e}\")\n",
        "            return np.zeros(6)\n",
        "\n",
        "    def extract_wav2vec2_features(self, audio_path):\n",
        "        \"\"\"Extract Wav2Vec2 features\"\"\"\n",
        "        try:\n",
        "            audio, sr = torchaudio.load(audio_path)\n",
        "            if sr != 16000:\n",
        "                resampler = torchaudio.transforms.Resample(sr, 16000)\n",
        "                audio = resampler(audio)\n",
        "\n",
        "            # Process with Wav2Vec2\n",
        "            inputs = self.wav2vec2_processor(audio.squeeze().numpy(),\n",
        "                                           sampling_rate=16000,\n",
        "                                           return_tensors=\"pt\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.wav2vec2_model(**inputs)\n",
        "                features = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "            return features\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting Wav2Vec2 from {audio_path}: {e}\")\n",
        "            return np.zeros(768)  # Wav2Vec2 base has 768 dimensions\n",
        "\n",
        "    def extract_mfcc_features(self, audio_path, n_mfcc=13):\n",
        "        \"\"\"Extract MFCC features\"\"\"\n",
        "        try:\n",
        "            audio, sr = librosa.load(audio_path, sr=16000)\n",
        "            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "            # Statistical features\n",
        "            features = []\n",
        "            features.extend(np.mean(mfccs, axis=1))\n",
        "            features.extend(np.std(mfccs, axis=1))\n",
        "            features.extend(np.max(mfccs, axis=1))\n",
        "            features.extend(np.min(mfccs, axis=1))\n",
        "\n",
        "            return np.array(features)\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting MFCC from {audio_path}: {e}\")\n",
        "            return np.zeros(n_mfcc * 4)\n",
        "\n",
        "    def extract_log_mel_features(self, audio_path, n_mels=80):\n",
        "        \"\"\"Extract Log-Mel spectrogram features\"\"\"\n",
        "        try:\n",
        "            audio, sr = librosa.load(audio_path, sr=16000)\n",
        "            mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n",
        "            log_mel = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "            # Statistical features\n",
        "            features = []\n",
        "            features.extend(np.mean(log_mel, axis=1))\n",
        "            features.extend(np.std(log_mel, axis=1))\n",
        "            features.extend(np.max(log_mel, axis=1))\n",
        "            features.extend(np.min(log_mel, axis=1))\n",
        "\n",
        "            return np.array(features)\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting Log-Mel from {audio_path}: {e}\")\n",
        "            return np.zeros(n_mels * 4)\n",
        "\n",
        "    def extract_delta_features(self, audio_path):\n",
        "        \"\"\"Extract Delta and Delta-Delta MFCC features\"\"\"\n",
        "        try:\n",
        "            audio, sr = librosa.load(audio_path, sr=16000)\n",
        "            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "\n",
        "            # Delta features\n",
        "            delta_mfccs = librosa.feature.delta(mfccs)\n",
        "            delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
        "\n",
        "            # Statistical features for each\n",
        "            features = []\n",
        "            for feat in [delta_mfccs, delta2_mfccs]:\n",
        "                features.extend(np.mean(feat, axis=1))\n",
        "                features.extend(np.std(feat, axis=1))\n",
        "\n",
        "            return np.array(features)\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting Delta features from {audio_path}: {e}\")\n",
        "            return np.zeros(13 * 4)  # 13 deltas + 13 delta-deltas, mean+std each\n",
        "\n",
        "    def extract_all_acoustic_features(self, audio_path):\n",
        "        \"\"\"Extract all acoustic features\"\"\"\n",
        "        features = {}\n",
        "\n",
        "        print(f\"Processing: {os.path.basename(audio_path)}\")\n",
        "\n",
        "        features['eGeMAPS'] = self.extract_egmaps_features(audio_path)\n",
        "        features['TRILL'] = self.extract_trill_features(audio_path)\n",
        "        features['Allosaurus'] = self.extract_allsaurus_features(audio_path)\n",
        "        features['Wav2Vec2'] = self.extract_wav2vec2_features(audio_path)\n",
        "        features['MFCCs'] = self.extract_mfcc_features(audio_path)\n",
        "        features['Log-Mel'] = self.extract_log_mel_features(audio_path)\n",
        "        features['Delta'] = self.extract_delta_features(audio_path)\n",
        "\n",
        "        return features\n",
        "\n",
        "    def transcribe_audio(self, audio_path):\n",
        "        \"\"\"Transcribe audio using speech recognition\"\"\"\n",
        "        try:\n",
        "            # Convert to WAV if needed\n",
        "            recognizer = sr.Recognizer()\n",
        "\n",
        "            with sr.AudioFile(audio_path) as source:\n",
        "                audio_data = recognizer.record(source)\n",
        "\n",
        "            # Try Google Speech Recognition (free tier)\n",
        "            try:\n",
        "                transcript = recognizer.recognize_google(audio_data)\n",
        "                return transcript\n",
        "            except sr.UnknownValueError:\n",
        "                return \"Could not understand audio\"\n",
        "            except sr.RequestError as e:\n",
        "                return f\"Error with speech recognition service: {e}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error transcribing {audio_path}: {e}\")\n",
        "            return \"Transcription failed\"\n",
        "\n",
        "    def process_dataset(self):\n",
        "        \"\"\"Process the entire dataset\"\"\"\n",
        "        file_paths = self.get_file_paths()\n",
        "        results = []\n",
        "\n",
        "        # Process diagnosis task\n",
        "        for split in ['train']:\n",
        "            for label in ['ad', 'cn']:\n",
        "                audio_files = file_paths['diagnosis'][split]['audio'][label]\n",
        "                for audio_path in audio_files:\n",
        "                    file_id = os.path.basename(audio_path).replace('.wav', '')\n",
        "\n",
        "                    # Extract acoustic features\n",
        "                    acoustic_feats = self.extract_all_acoustic_features(audio_path)\n",
        "\n",
        "                    # Transcribe\n",
        "                    transcript = self.transcribe_audio(audio_path)\n",
        "\n",
        "                    results.append({\n",
        "                        'file_id': file_id,\n",
        "                        'task': 'diagnosis',\n",
        "                        'split': split,\n",
        "                        'label': label,\n",
        "                        'audio_path': audio_path,\n",
        "                        'transcript': transcript,\n",
        "                        **{f'acoustic_{k}': v for k, v in acoustic_feats.items()}\n",
        "                    })\n",
        "\n",
        "        # Process progression task\n",
        "        for split in ['train']:\n",
        "            for label in ['decline', 'no_decline']:\n",
        "                audio_files = file_paths['progression'][split]['audio'][label]\n",
        "                for audio_path in audio_files:\n",
        "                    file_id = os.path.basename(audio_path).replace('.wav', '')\n",
        "\n",
        "                    # Extract acoustic features\n",
        "                    acoustic_feats = self.extract_all_acoustic_features(audio_path)\n",
        "\n",
        "                    # Transcribe\n",
        "                    transcript = self.transcribe_audio(audio_path)\n",
        "\n",
        "                    results.append({\n",
        "                        'file_id': file_id,\n",
        "                        'task': 'progression',\n",
        "                        'split': split,\n",
        "                        'label': label,\n",
        "                        'audio_path': audio_path,\n",
        "                        'transcript': transcript,\n",
        "                        **{f'acoustic_{k}': v for k, v in acoustic_feats.items()}\n",
        "                    })\n",
        "\n",
        "        # Process test-dist\n",
        "        audio_files = file_paths['progression']['test-dist']['audio']\n",
        "        for audio_path in audio_files:\n",
        "            file_id = os.path.basename(audio_path).replace('.wav', '')\n",
        "\n",
        "            # Extract acoustic features\n",
        "            acoustic_feats = self.extract_all_acoustic_features(audio_path)\n",
        "\n",
        "            # Transcribe\n",
        "            transcript = self.transcribe_audio(audio_path)\n",
        "\n",
        "            results.append({\n",
        "                'file_id': file_id,\n",
        "                'task': 'progression',\n",
        "                'split': 'test-dist',\n",
        "                'label': 'unknown',\n",
        "                'audio_path': audio_path,\n",
        "                'transcript': transcript,\n",
        "                **{f'acoustic_{k}': v for k, v in acoustic_feats.items()}\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    def save_transcripts(self, df, output_dir='/content'):\n",
        "        \"\"\"Save transcripts to files\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        transcript_files = []\n",
        "        for idx, row in df.iterrows():\n",
        "            filename = f\"{row['file_id']}_transcript.txt\"\n",
        "            filepath = os.path.join(output_dir, filename)\n",
        "\n",
        "            with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                f.write(f\"File ID: {row['file_id']}\\n\")\n",
        "                f.write(f\"Task: {row['task']}\\n\")\n",
        "                f.write(f\"Label: {row['label']}\\n\")\n",
        "                f.write(f\"Transcript: {row['transcript']}\\n\")\n",
        "\n",
        "            transcript_files.append(filepath)\n",
        "\n",
        "        return transcript_files\n",
        "\n",
        "    def extract_linguistic_features(self, text):\n",
        "        \"\"\"Extract linguistic features for BERT preparation\"\"\"\n",
        "        features = {}\n",
        "\n",
        "        # Basic text statistics\n",
        "        features['word_count'] = len(text.split())\n",
        "        features['char_count'] = len(text)\n",
        "        features['sentence_count'] = len([s for s in text.split('.') if s.strip()])\n",
        "        features['avg_word_length'] = np.mean([len(word) for word in text.split()])\n",
        "\n",
        "        # Lexical diversity\n",
        "        words = text.lower().split()\n",
        "        unique_words = set(words)\n",
        "        features['lexical_diversity'] = len(unique_words) / len(words) if words else 0\n",
        "\n",
        "        # Part-of-speech complexity (simplified)\n",
        "        # This would typically require NLTK or spaCy\n",
        "        features['complexity_score'] = len(unique_words) / features['sentence_count'] if features['sentence_count'] > 0 else 0\n",
        "\n",
        "        return features\n",
        "\n",
        "# Usage example\n",
        "def main():\n",
        "    # Initialize processor\n",
        "    base_path = \"/content/drive/MyDrive/Voice/extracted/ADReSSo21\"\n",
        "    processor = ADReSSo21Processor(base_path)\n",
        "\n",
        "    print(\"=== Step 0: Acoustic Features Overview ===\")\n",
        "    print(\"Available acoustic features:\")\n",
        "    features_info = {\n",
        "        'eGeMAPS': 'Extended Geneva Minimalistic Acoustic Parameter Set (88 features)',\n",
        "        'TRILL': 'Triplet Loss Network for speech representations (512 features)',\n",
        "        'Allosaurus': 'Universal phonetic features (variable dimensions)',\n",
        "        'Wav2Vec2': 'Self-supervised speech representations (768 features)',\n",
        "        'MFCCs': 'Mel-Frequency Cepstral Coefficients (52 features: 13*4 statistics)',\n",
        "        'Log-Mel': 'Log-Mel spectrogram features (320 features: 80*4 statistics)',\n",
        "        'Delta': 'Delta and Delta-Delta MFCC features (52 features)'\n",
        "    }\n",
        "\n",
        "    for name, desc in features_info.items():\n",
        "        print(f\"- {name}: {desc}\")\n",
        "\n",
        "    print(\"\\n=== Step 1: Processing Dataset ===\")\n",
        "    df = processor.process_dataset()\n",
        "\n",
        "    print(\"\\n=== Step 2: Extracting Transcripts ===\")\n",
        "    # Transcripts are already extracted in process_dataset()\n",
        "\n",
        "    print(\"\\n=== Step 3: Saving Transcript Files ===\")\n",
        "    transcript_files = processor.save_transcripts(df)\n",
        "    print(f\"Saved {len(transcript_files)} transcript files to /content/\")\n",
        "\n",
        "    print(\"\\n=== Step 4: Transcripts Table ===\")\n",
        "    transcript_df = df[['file_id', 'task', 'label', 'transcript']].copy()\n",
        "    print(transcript_df.head(10))\n",
        "\n",
        "    print(\"\\n=== Step 5: Linguistic Features for BERT ===\")\n",
        "    linguistic_features = []\n",
        "    for idx, row in df.iterrows():\n",
        "        ling_feats = processor.extract_linguistic_features(row['transcript'])\n",
        "        ling_feats['file_id'] = row['file_id']\n",
        "        ling_feats['text'] = row['transcript']  # For BERT input\n",
        "        linguistic_features.append(ling_feats)\n",
        "\n",
        "    linguistic_df = pd.DataFrame(linguistic_features)\n",
        "    print(\"Linguistic features extracted:\")\n",
        "    print(linguistic_df.head())\n",
        "\n",
        "    # Save all results\n",
        "    df.to_csv('/content/complete_features.csv', index=False)\n",
        "    linguistic_df.to_csv('/content/linguistic_features.csv', index=False)\n",
        "    transcript_df.to_csv('/content/transcripts_table.csv', index=False)\n",
        "\n",
        "    print(\"\\n=== Processing Complete ===\")\n",
        "    print(\"Files saved:\")\n",
        "    print(\"- /content/complete_features.csv (all features)\")\n",
        "    print(\"- /content/linguistic_features.csv (for BERT)\")\n",
        "    print(\"- /content/transcripts_table.csv (transcripts table)\")\n",
        "\n",
        "    return df, linguistic_df, transcript_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df, linguistic_df, transcript_df = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ADtkg8rxJ9q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}