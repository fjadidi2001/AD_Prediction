{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/Feature_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7cgR7FO3HGX"
      },
      "source": [
        "# Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ADtkg8rxJ9q",
        "outputId": "660d1cdb-7178-4346-b33b-350d5b4132aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Collecting opensmile\n",
            "  Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
            "Collecting speechbrain\n",
            "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Collecting audobject>=0.6.1 (from opensmile)\n",
            "  Downloading audobject-0.7.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting audinterface>=0.7.0 (from opensmile)\n",
            "  Downloading audinterface-1.3.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Collecting audeer>=2.1.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audeer-2.2.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audformat-1.3.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting audiofile>=1.3.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audiofile-1.5.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting audmath>=1.4.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audmath-1.4.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting asttokens>=2.0.0 (from audobject>=0.6.1->opensmile)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (8.7.0)\n",
            "Collecting oyaml (from audobject>=0.6.1->opensmile)\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain) (1.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.13-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting iso639-lang (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso639_lang-2.6.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (18.1.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.22.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.17.0)\n",
            "Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl (996 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.0/996.0 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audinterface-1.3.1-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audobject-0.7.12-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading audeer-2.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audformat-1.3.2-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audiofile-1.5.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audmath-1.4.1-py3-none-any.whl (23 kB)\n",
            "Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.13-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading iso639_lang-2.6.0-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803404 sha256=8d423cdff75679188230c8ab621a5b620f43b828a80cf89857d531d8df62bf1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: ruamel.yaml.clib, oyaml, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, iso639-lang, iso3166, audresample, audmath, audeer, asttokens, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, audobject, nvidia-cusolver-cu12, hyperpyyaml, audiofile, audformat, openai-whisper, audinterface, speechbrain, opensmile\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed asttokens-3.0.0 audeer-2.2.2 audformat-1.3.2 audinterface-1.3.1 audiofile-1.5.1 audmath-1.4.1 audobject-0.7.12 audresample-1.3.3 hyperpyyaml-1.2.2 iso3166-2.1.1 iso639-lang-2.6.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 opensmile-2.5.1 oyaml-1.0 ruamel.yaml-0.18.13 ruamel.yaml.clib-0.2.12 speechbrain-1.0.3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa soundfile opensmile speechbrain transformers torch openai-whisper\n",
        "!pip install pandas numpy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTPwrA5i3Wfg"
      },
      "source": [
        "# Mount to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHcrv0EN3muX",
        "outputId": "75a19310-788b-4b1f-e0a9-89c0452aebc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrkxMgd53v8D"
      },
      "source": [
        "# ADReSSoAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJZObdjoWoEy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import json\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import opensmile\n",
        "import torch\n",
        "import whisper\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2Model, BertTokenizer, BertModel\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1102hd7BjhZ"
      },
      "outputs": [],
      "source": [
        "class ADReSSoAnalyzer:\n",
        "    def __init__(self, base_path=\"/content/drive/MyDrive/Voice/extracted/ADReSSo21\"):\n",
        "        self.base_path = base_path\n",
        "        self.output_path = \"/content\"\n",
        "        self.features = {}\n",
        "        self.transcripts = {}\n",
        "\n",
        "        # Initialize feature extractors\n",
        "        self.smile = opensmile.Smile(\n",
        "            feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "            feature_level=opensmile.FeatureLevel.Functionals,\n",
        "        )\n",
        "\n",
        "        # Initialize Whisper for transcription\n",
        "        self.whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "        # Initialize Wav2Vec2\n",
        "        self.wav2vec_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "        self.wav2vec_model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "        # Initialize BERT\n",
        "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def get_audio_files(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"Get all audio files from the dataset\"\"\"\n",
        "        audio_files = {\n",
        "            'diagnosis_ad': [],\n",
        "            'diagnosis_cn': [],\n",
        "            'progression_decline': [],\n",
        "            'progression_no_decline': [],\n",
        "            'progression_test': []\n",
        "        }\n",
        "\n",
        "        # Diagnosis files\n",
        "        diag_ad_path = f\"{self.base_path}/diagnosis/train/audio/ad\"\n",
        "        diag_cn_path = f\"{self.base_path}/diagnosis/train/audio/cn\"\n",
        "\n",
        "        if os.path.exists(diag_ad_path):\n",
        "            audio_files['diagnosis_ad'] = [f\"{diag_ad_path}/{f}\" for f in os.listdir(diag_ad_path) if f.endswith('.wav')]\n",
        "        if os.path.exists(diag_cn_path):\n",
        "            audio_files['diagnosis_cn'] = [f\"{diag_cn_path}/{f}\" for f in os.listdir(diag_cn_path) if f.endswith('.wav')]\n",
        "\n",
        "        # Progression files\n",
        "        prog_decline_path = f\"{self.base_path}/progression/train/audio/decline\"\n",
        "        prog_no_decline_path = f\"{self.base_path}/progression/train/audio/no_decline\"\n",
        "        prog_test_path = f\"{self.base_path}/progression/test-dist/audio\"\n",
        "\n",
        "        if os.path.exists(prog_decline_path):\n",
        "            audio_files['progression_decline'] = [f\"{prog_decline_path}/{f}\" for f in os.listdir(prog_decline_path) if f.endswith('.wav')]\n",
        "        if os.path.exists(prog_no_decline_path):\n",
        "            audio_files['progression_no_decline'] = [f\"{prog_no_decline_path}/{f}\" for f in os.listdir(prog_no_decline_path) if f.endswith('.wav')]\n",
        "        if os.path.exists(prog_test_path):\n",
        "            audio_files['progression_test'] = [f\"{prog_test_path}/{f}\" for f in os.listdir(prog_test_path) if f.endswith('.wav')]\n",
        "\n",
        "        return audio_files\n",
        "\n",
        "    def extract_acoustic_features(self, audio_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Extract all acoustic features from audio file\"\"\"\n",
        "        features = {}\n",
        "\n",
        "        try:\n",
        "            # Load audio - resample to 16kHz for Wav2Vec2 compatibility\n",
        "            y, sr = librosa.load(audio_path, sr=16000)  # Force 16kHz sampling rate\n",
        "\n",
        "            # 1. eGeMAPS features using openSMILE\n",
        "            try:\n",
        "                features['egemaps'] = self.smile.process_file(audio_path).values.flatten()\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: eGeMAPS extraction failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['egemaps'] = np.zeros(88)  # Default eGeMAPS feature size\n",
        "\n",
        "            # 2. MFCC features\n",
        "            try:\n",
        "                mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "                features['mfccs'] = {\n",
        "                    'mean': np.mean(mfccs, axis=1),\n",
        "                    'std': np.std(mfccs, axis=1),\n",
        "                    'delta': np.mean(librosa.feature.delta(mfccs), axis=1),\n",
        "                    'delta2': np.mean(librosa.feature.delta(mfccs, order=2), axis=1)\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: MFCC extraction failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['mfccs'] = {\n",
        "                    'mean': np.zeros(13),\n",
        "                    'std': np.zeros(13),\n",
        "                    'delta': np.zeros(13),\n",
        "                    'delta2': np.zeros(13)\n",
        "                }\n",
        "\n",
        "            # 3. Log-mel spectrogram\n",
        "            try:\n",
        "                mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80)\n",
        "                log_mel = librosa.power_to_db(mel_spec)\n",
        "                features['log_mel'] = {\n",
        "                    'mean': np.mean(log_mel, axis=1),\n",
        "                    'std': np.std(log_mel, axis=1)\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: Log-mel extraction failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['log_mel'] = {\n",
        "                    'mean': np.zeros(80),\n",
        "                    'std': np.zeros(80)\n",
        "                }\n",
        "\n",
        "            # 4. Wav2Vec2 features - with proper sampling rate handling\n",
        "            try:\n",
        "                # Ensure sampling rate is exactly 16000 Hz for Wav2Vec2\n",
        "                if len(y) == 0:\n",
        "                    raise ValueError(\"Empty audio signal\")\n",
        "\n",
        "                input_values = self.wav2vec_processor(\n",
        "                    y,\n",
        "                    sampling_rate=16000,  # Explicitly set to 16000\n",
        "                    return_tensors=\"pt\"\n",
        "                ).input_values\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    wav2vec_features = self.wav2vec_model(input_values).last_hidden_state\n",
        "                features['wav2vec2'] = torch.mean(wav2vec_features, dim=1).squeeze().numpy()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: Wav2Vec2 extraction failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['wav2vec2'] = np.zeros(768)  # Default Wav2Vec2 feature size\n",
        "\n",
        "            # 5. Additional prosodic features\n",
        "            try:\n",
        "                # Handle potential issues with F0 extraction\n",
        "                f0 = librosa.yin(y, fmin=50, fmax=300, sr=sr)\n",
        "                f0_clean = f0[f0 > 0]  # Remove unvoiced frames\n",
        "\n",
        "                features['prosodic'] = {\n",
        "                    'f0_mean': np.mean(f0_clean) if len(f0_clean) > 0 else 0.0,\n",
        "                    'f0_std': np.std(f0_clean) if len(f0_clean) > 0 else 0.0,\n",
        "                    'energy_mean': np.mean(librosa.feature.rms(y=y)),\n",
        "                    'energy_std': np.std(librosa.feature.rms(y=y)),\n",
        "                    'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(y)),\n",
        "                    'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
        "                    'spectral_rolloff': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),\n",
        "                    'duration': len(y) / sr\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: Prosodic feature extraction failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['prosodic'] = {\n",
        "                    'f0_mean': 0.0, 'f0_std': 0.0, 'energy_mean': 0.0, 'energy_std': 0.0,\n",
        "                    'zero_crossing_rate': 0.0, 'spectral_centroid': 0.0, 'spectral_rolloff': 0.0,\n",
        "                    'duration': 0.0\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {audio_path}: {str(e)}\")\n",
        "            features = None\n",
        "\n",
        "        return features\n",
        "\n",
        "    def show_acoustic_features(self, sample_file: str):\n",
        "        \"\"\"Display acoustic features for a sample file\"\"\"\n",
        "        features = self.extract_acoustic_features(sample_file)\n",
        "\n",
        "        if features is None:\n",
        "            print(f\"Could not extract features from {sample_file}\")\n",
        "            return\n",
        "\n",
        "        print(f\"=== Acoustic Features for {os.path.basename(sample_file)} ===\\n\")\n",
        "\n",
        "        # eGeMAPS\n",
        "        print(f\"1. eGeMAPS Features: {len(features['egemaps'])} features\")\n",
        "        print(f\"   Shape: {features['egemaps'].shape}\")\n",
        "        print(f\"   Sample values: {features['egemaps'][:5]}\")\n",
        "        print()\n",
        "\n",
        "        # MFCCs\n",
        "        print(\"2. MFCC Features:\")\n",
        "        print(f\"   Mean: {features['mfccs']['mean'].shape} - {features['mfccs']['mean'][:5]}\")\n",
        "        print(f\"   Std: {features['mfccs']['std'].shape} - {features['mfccs']['std'][:5]}\")\n",
        "        print(f\"   Delta: {features['mfccs']['delta'].shape} - {features['mfccs']['delta'][:5]}\")\n",
        "        print(f\"   Delta-Delta: {features['mfccs']['delta2'].shape} - {features['mfccs']['delta2'][:5]}\")\n",
        "        print()\n",
        "\n",
        "        # Log-mel\n",
        "        print(\"3. Log-Mel Spectrogram Features:\")\n",
        "        print(f\"   Mean: {features['log_mel']['mean'].shape} - {features['log_mel']['mean'][:5]}\")\n",
        "        print(f\"   Std: {features['log_mel']['std'].shape} - {features['log_mel']['std'][:5]}\")\n",
        "        print()\n",
        "\n",
        "        # Wav2Vec2\n",
        "        print(f\"4. Wav2Vec2 Features: {features['wav2vec2'].shape}\")\n",
        "        print(f\"   Sample values: {features['wav2vec2'][:5]}\")\n",
        "        print()\n",
        "\n",
        "        # Prosodic\n",
        "        print(\"5. Prosodic Features:\")\n",
        "        for key, value in features['prosodic'].items():\n",
        "            print(f\"   {key}: {value:.4f}\")\n",
        "        print()\n",
        "\n",
        "    def extract_transcripts(self, audio_files: Dict[str, List[str]]) -> Dict[str, str]:\n",
        "        \"\"\"Extract transcripts using Whisper\"\"\"\n",
        "        transcripts = {}\n",
        "\n",
        "        print(\"Extracting transcripts...\")\n",
        "\n",
        "        for category, files in audio_files.items():\n",
        "            print(f\"\\nProcessing {category}...\")\n",
        "            for file_path in files:\n",
        "                try:\n",
        "                    filename = os.path.basename(file_path)\n",
        "                    print(f\"  Transcribing {filename}...\")\n",
        "\n",
        "                    result = self.whisper_model.transcribe(file_path)\n",
        "                    transcript_text = result[\"text\"].strip()\n",
        "\n",
        "                    transcripts[f\"{category}_{filename}\"] = {\n",
        "                        'file_path': file_path,\n",
        "                        'category': category,\n",
        "                        'filename': filename,\n",
        "                        'transcript': transcript_text,\n",
        "                        'language': result.get('language', 'en'),\n",
        "                        'segments': len(result.get('segments', []))\n",
        "                    }\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"    Error transcribing {filename}: {str(e)}\")\n",
        "                    transcripts[f\"{category}_{filename}\"] = {\n",
        "                        'file_path': file_path,\n",
        "                        'category': category,\n",
        "                        'filename': filename,\n",
        "                        'transcript': \"\",\n",
        "                        'error': str(e)\n",
        "                    }\n",
        "\n",
        "        return transcripts\n",
        "\n",
        "    def save_transcripts(self, transcripts: Dict[str, str]):\n",
        "        \"\"\"Save transcripts to files\"\"\"\n",
        "        os.makedirs(f\"{self.output_path}/transcripts\", exist_ok=True)\n",
        "\n",
        "        # Save individual transcript files\n",
        "        for key, data in transcripts.items():\n",
        "            filename = f\"{key}_transcript.txt\"\n",
        "            filepath = f\"{self.output_path}/transcripts/{filename}\"\n",
        "\n",
        "            with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                f.write(data['transcript'])\n",
        "\n",
        "        # Save consolidated JSON\n",
        "        with open(f\"{self.output_path}/transcripts/all_transcripts.json\", 'w', encoding='utf-8') as f:\n",
        "            json.dump(transcripts, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        # Save as pickle for easy loading\n",
        "        with open(f\"{self.output_path}/transcripts/transcripts.pkl\", 'wb') as f:\n",
        "            pickle.dump(transcripts, f)\n",
        "\n",
        "        print(f\"Transcripts saved to {self.output_path}/transcripts/\")\n",
        "\n",
        "    def create_transcript_table(self, transcripts: Dict[str, str]) -> pd.DataFrame:\n",
        "        \"\"\"Create a DataFrame with transcript information\"\"\"\n",
        "        data = []\n",
        "\n",
        "        for key, info in transcripts.items():\n",
        "            data.append({\n",
        "                'File_ID': key,\n",
        "                'Category': info['category'],\n",
        "                'Filename': info['filename'],\n",
        "                'Transcript_Length': len(info['transcript']),\n",
        "                'Word_Count': len(info['transcript'].split()) if info['transcript'] else 0,\n",
        "                'Language': info.get('language', 'N/A'),\n",
        "                'Segments': info.get('segments', 'N/A'),\n",
        "                'Has_Error': 'error' in info,\n",
        "                'Transcript_Preview': info['transcript'][:100] + \"...\" if len(info['transcript']) > 100 else info['transcript']\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # Save the table\n",
        "        df.to_csv(f\"{self.output_path}/transcript_summary.csv\", index=False)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def extract_linguistic_features(self, transcripts: Dict[str, str]) -> Dict[str, Any]:\n",
        "        \"\"\"Extract linguistic features for BERT preparation\"\"\"\n",
        "        linguistic_features = {}\n",
        "\n",
        "        print(\"Extracting linguistic features...\")\n",
        "\n",
        "        for key, data in transcripts.items():\n",
        "            transcript = data['transcript']\n",
        "\n",
        "            if not transcript:\n",
        "                linguistic_features[key] = {\n",
        "                    'raw_text': '',\n",
        "                    'word_count': 0,\n",
        "                    'sentence_count': 0,\n",
        "                    'avg_word_length': 0,\n",
        "                    'bert_tokens': [],\n",
        "                    'bert_input_ids': [],\n",
        "                    'bert_attention_mask': []\n",
        "                }\n",
        "                continue\n",
        "\n",
        "            # Basic linguistic features\n",
        "            words = transcript.split()\n",
        "            sentences = transcript.split('.')\n",
        "\n",
        "            # BERT tokenization\n",
        "            bert_encoding = self.bert_tokenizer(\n",
        "                transcript,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=512,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            linguistic_features[key] = {\n",
        "                'raw_text': transcript,\n",
        "                'word_count': len(words),\n",
        "                'sentence_count': len([s for s in sentences if s.strip()]),\n",
        "                'avg_word_length': np.mean([len(word) for word in words]) if words else 0,\n",
        "                'unique_words': len(set(words)),\n",
        "                'lexical_diversity': len(set(words)) / len(words) if words else 0,\n",
        "                'bert_tokens': self.bert_tokenizer.tokenize(transcript),\n",
        "                'bert_input_ids': bert_encoding['input_ids'].squeeze().tolist(),\n",
        "                'bert_attention_mask': bert_encoding['attention_mask'].squeeze().tolist(),\n",
        "                'bert_encoding': bert_encoding\n",
        "            }\n",
        "\n",
        "        # Save linguistic features\n",
        "        with open(f\"{self.output_path}/linguistic_features.pkl\", 'wb') as f:\n",
        "            pickle.dump(linguistic_features, f)\n",
        "\n",
        "        return linguistic_features\n",
        "\n",
        "    def run_complete_pipeline(self):\n",
        "        \"\"\"Run the complete analysis pipeline\"\"\"\n",
        "        print(\"=== ADReSSo21 Speech Analysis Pipeline ===\\n\")\n",
        "\n",
        "        # Step 0: Get audio files\n",
        "        print(\"Step 0: Getting audio files...\")\n",
        "        audio_files = self.get_audio_files()\n",
        "\n",
        "        total_files = sum(len(files) for files in audio_files.values())\n",
        "        print(f\"Found {total_files} audio files across all categories\")\n",
        "\n",
        "        for category, files in audio_files.items():\n",
        "            print(f\"  {category}: {len(files)} files\")\n",
        "\n",
        "        if total_files == 0:\n",
        "            print(\"No audio files found. Please check the dataset path.\")\n",
        "            return\n",
        "\n",
        "        # Step 1: Show acoustic features for sample files\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Step 1: Demonstrating acoustic features...\")\n",
        "\n",
        "        # Show features for one file from each category that has files\n",
        "        for category, files in audio_files.items():\n",
        "            if files:\n",
        "                print(f\"\\nShowing features for {category}:\")\n",
        "                self.show_acoustic_features(files[0])\n",
        "                break  # Just show one example to avoid too much output\n",
        "\n",
        "        # Step 2: Extract transcripts\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Step 2: Extracting transcripts...\")\n",
        "        transcripts = self.extract_transcripts(audio_files)\n",
        "\n",
        "        # Step 3: Save transcripts\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Step 3: Saving transcripts...\")\n",
        "        self.save_transcripts(transcripts)\n",
        "\n",
        "        # Step 4: Create transcript table\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Step 4: Creating transcript table...\")\n",
        "        transcript_df = self.create_transcript_table(transcripts)\n",
        "\n",
        "        print(\"Transcript Summary Table:\")\n",
        "        print(transcript_df.to_string(index=False))\n",
        "\n",
        "        # Step 5: Extract linguistic features for BERT\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Step 5: Extracting linguistic features for BERT...\")\n",
        "        linguistic_features = self.extract_linguistic_features(transcripts)\n",
        "\n",
        "        print(\"\\nPipeline completed successfully!\")\n",
        "        print(f\"Results saved to: {self.output_path}\")\n",
        "        print(\"\\nOutput files:\")\n",
        "        print(f\"  - Transcripts: {self.output_path}/transcripts/\")\n",
        "        print(f\"  - Transcript summary: {self.output_path}/transcript_summary.csv\")\n",
        "        print(f\"  - Linguistic features: {self.output_path}/linguistic_features.pkl\")\n",
        "\n",
        "        return {\n",
        "            'audio_files': audio_files,\n",
        "            'transcripts': transcripts,\n",
        "            'transcript_df': transcript_df,\n",
        "            'linguistic_features': linguistic_features\n",
        "        }\n",
        "\n",
        "# # Usage example\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Initialize analyzer\n",
        "#     analyzer = ADReSSoAnalyzer()\n",
        "\n",
        "#     # Run complete pipeline\n",
        "#     results = analyzer.run_complete_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6HXS8QyIcym",
        "outputId": "06d62466-89d5-4fe9-9b90-51ecceefedd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_6qNR5k5O8U"
      },
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAQVVECXn9mT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
        "from torch_geometric.data import Data, Batch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import networkx as nx\n",
        "from transformers import BertModel\n",
        "import pickle\n",
        "import json\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class GraphAttentionModule(nn.Module):\n",
        "    \"\"\"Graph-based attention module for semantic relationships\"\"\"\n",
        "    def __init__(self, input_dim=768, hidden_dim=256, num_heads=8, num_layers=3):\n",
        "        super(GraphAttentionModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # Graph attention layers\n",
        "        self.gat_layers = nn.ModuleList([\n",
        "            GATConv(input_dim if i == 0 else hidden_dim,\n",
        "                   hidden_dim, heads=num_heads, dropout=0.2)\n",
        "            for i in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Final projection\n",
        "        self.projection = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x, edge_index, batch=None):\n",
        "        # Apply GAT layers\n",
        "        for i, gat_layer in enumerate(self.gat_layers):\n",
        "            x = gat_layer(x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        # Global pooling if batch is provided\n",
        "        if batch is not None:\n",
        "            x = global_mean_pool(x, batch)\n",
        "        else:\n",
        "            x = torch.mean(x, dim=0, keepdim=True)\n",
        "\n",
        "        return self.projection(x)\n",
        "\n",
        "class VisionTransformerModule(nn.Module):\n",
        "    \"\"\"Vision Transformer for processing spectrograms\"\"\"\n",
        "    def __init__(self, input_dim=80, patch_size=8, embed_dim=768, num_heads=12, num_layers=6):\n",
        "        super(VisionTransformerModule, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # Patch embedding\n",
        "        self.patch_embed = nn.Conv2d(1, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.pos_embed = nn.Parameter(torch.randn(1, 1000, embed_dim))  # Max patches\n",
        "\n",
        "        # Transformer layers\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim, nhead=num_heads, dim_feedforward=embed_dim*4,\n",
        "            dropout=0.1, activation='gelu'\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Linear(embed_dim, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, channels, height, width)\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        # Create patches\n",
        "        x = self.patch_embed(x)  # (B, embed_dim, H', W')\n",
        "        x = x.flatten(2).transpose(1, 2)  # (B, num_patches, embed_dim)\n",
        "\n",
        "        # Add positional encoding\n",
        "        num_patches = x.shape[1]\n",
        "        x = x + self.pos_embed[:, :num_patches, :]\n",
        "\n",
        "        # Apply transformer\n",
        "        x = x.transpose(0, 1)  # (num_patches, B, embed_dim)\n",
        "        x = self.transformer(x)\n",
        "        x = x.transpose(0, 1)  # (B, num_patches, embed_dim)\n",
        "\n",
        "        # Global average pooling\n",
        "        x = torch.mean(x, dim=1)  # (B, embed_dim)\n",
        "\n",
        "        return self.classifier(x)\n",
        "\n",
        "class UNetModule(nn.Module):\n",
        "    \"\"\"U-Net for audio feature processing\"\"\"\n",
        "    def __init__(self, in_channels=1, out_channels=128):\n",
        "        super(UNetModule, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = self.conv_block(in_channels, 64)\n",
        "        self.enc2 = self.conv_block(64, 128)\n",
        "        self.enc3 = self.conv_block(128, 256)\n",
        "        self.enc4 = self.conv_block(256, 512)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = self.conv_block(512, 1024)\n",
        "\n",
        "        # Decoder\n",
        "        self.dec4 = self.upconv_block(1024, 512)\n",
        "        self.dec3 = self.upconv_block(512, 256)\n",
        "        self.dec2 = self.upconv_block(256, 128)\n",
        "        self.dec1 = self.upconv_block(128, 64)\n",
        "\n",
        "        # Final layer\n",
        "        self.final = nn.Conv1d(64, out_channels, kernel_size=1)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "    def conv_block(self, in_ch, out_ch):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv1d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def upconv_block(self, in_ch, out_ch):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose1d(in_ch, out_ch, kernel_size=2, stride=2),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(F.max_pool1d(e1, 2))\n",
        "        e3 = self.enc3(F.max_pool1d(e2, 2))\n",
        "        e4 = self.enc4(F.max_pool1d(e3, 2))\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(F.max_pool1d(e4, 2))\n",
        "\n",
        "        # Decoder\n",
        "        d4 = self.dec4(b)\n",
        "        d3 = self.dec3(d4)\n",
        "        d2 = self.dec2(d3)\n",
        "        d1 = self.dec1(d2)\n",
        "\n",
        "        # Final\n",
        "        out = self.final(d1)\n",
        "        out = self.pool(out).squeeze(-1)  # Global average pooling\n",
        "\n",
        "        return out\n",
        "\n",
        "class AlexNetModule(nn.Module):\n",
        "    \"\"\"Modified AlexNet for feature extraction\"\"\"\n",
        "    def __init__(self, input_dim=768, num_classes=256):\n",
        "        super(AlexNetModule, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Linear(input_dim, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(2048, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "class MultiModalADReSSoModel(nn.Module):\n",
        "    \"\"\"Complete multi-modal architecture\"\"\"\n",
        "    def __init__(self,\n",
        "                 audio_feature_dim=768,\n",
        "                 text_feature_dim=768,\n",
        "                 spectrogram_height=80,\n",
        "                 num_classes=2):\n",
        "        super(MultiModalADReSSoModel, self).__init__()\n",
        "\n",
        "        # Initialize modules\n",
        "        self.graph_attention = GraphAttentionModule(input_dim=text_feature_dim)\n",
        "        self.vision_transformer = VisionTransformerModule(input_dim=spectrogram_height)\n",
        "        self.unet = UNetModule()\n",
        "        self.alexnet = AlexNetModule(input_dim=audio_feature_dim)\n",
        "\n",
        "        # BERT for text processing\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Fusion layers\n",
        "        self.fusion_layer = nn.Sequential(\n",
        "            nn.Linear(256 + 256 + 128 + 256, 512),  # Graph + ViT + UNet + AlexNet\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # Final classifier\n",
        "        self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "    def create_semantic_graph(self, text_features, audio_features):\n",
        "        \"\"\"Create semantic relationship graph between audio and text\"\"\"\n",
        "        batch_size = text_features.shape[0]\n",
        "        graphs = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            # Compute similarity matrix\n",
        "            text_feat = text_features[i].unsqueeze(0)  # (1, dim)\n",
        "            audio_feat = audio_features[i].unsqueeze(0)  # (1, dim)\n",
        "\n",
        "            # Create nodes (text + audio features)\n",
        "            node_features = torch.cat([text_feat, audio_feat], dim=0)  # (2, dim)\n",
        "\n",
        "            # Create edges based on similarity\n",
        "            similarity = F.cosine_similarity(text_feat, audio_feat, dim=1)\n",
        "\n",
        "            # Create bidirectional edges if similarity > threshold\n",
        "            if similarity.item() > 0.1:\n",
        "                edge_index = torch.tensor([[0, 1], [1, 0]], dtype=torch.long).t()\n",
        "            else:\n",
        "                # Self-loops only\n",
        "                edge_index = torch.tensor([[0, 1], [0, 1]], dtype=torch.long).t()\n",
        "\n",
        "            graph = Data(x=node_features, edge_index=edge_index)\n",
        "            graphs.append(graph)\n",
        "\n",
        "        return Batch.from_data_list(graphs)\n",
        "\n",
        "    def forward(self, audio_features, text_input_ids, text_attention_mask, spectrograms):\n",
        "        batch_size = audio_features.shape[0]\n",
        "\n",
        "        # Process text with BERT\n",
        "        bert_outputs = self.bert(input_ids=text_input_ids, attention_mask=text_attention_mask)\n",
        "        text_features = bert_outputs.last_hidden_state.mean(dim=1)  # (batch_size, 768)\n",
        "\n",
        "        # Create semantic graph\n",
        "        graph_batch = self.create_semantic_graph(text_features, audio_features)\n",
        "\n",
        "        # Process through different modules\n",
        "        graph_out = self.graph_attention(graph_batch.x, graph_batch.edge_index, graph_batch.batch)\n",
        "        vit_out = self.vision_transformer(spectrograms)\n",
        "\n",
        "        # Prepare audio for U-Net (add channel dimension)\n",
        "        audio_1d = audio_features.unsqueeze(1)  # (batch_size, 1, features)\n",
        "        unet_out = self.unet(audio_1d)\n",
        "\n",
        "        alexnet_out = self.alexnet(audio_features)\n",
        "\n",
        "        # Fusion\n",
        "        fused_features = torch.cat([graph_out, vit_out, unet_out, alexnet_out], dim=1)\n",
        "        fused_features = self.fusion_layer(fused_features)\n",
        "\n",
        "        # Final classification\n",
        "        output = self.classifier(fused_features)\n",
        "\n",
        "        return output\n",
        "\n",
        "class ADReSSoDataset(Dataset):\n",
        "    \"\"\"Dataset class for ADReSSo data\"\"\"\n",
        "    def __init__(self, features_dict, linguistic_features, labels, transform=None):\n",
        "        self.features_dict = features_dict\n",
        "        self.linguistic_features = linguistic_features\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.file_ids = list(features_dict.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_id = self.file_ids[idx]\n",
        "\n",
        "        # Get features\n",
        "        features = self.features_dict[file_id]\n",
        "        linguistic = self.linguistic_features[file_id]\n",
        "\n",
        "        # Prepare audio features (Wav2Vec2)\n",
        "        audio_features = torch.FloatTensor(features['wav2vec2'])\n",
        "\n",
        "        # Prepare text features\n",
        "        text_input_ids = torch.LongTensor(linguistic['bert_input_ids'])\n",
        "        text_attention_mask = torch.LongTensor(linguistic['bert_attention_mask'])\n",
        "\n",
        "        # Prepare spectrogram (create from log-mel features)\n",
        "        log_mel_mean = features['log_mel']['mean']\n",
        "        log_mel_std = features['log_mel']['std']\n",
        "        spectrogram = np.stack([log_mel_mean, log_mel_std])  # (2, 80)\n",
        "        spectrogram = np.expand_dims(spectrogram.mean(axis=0), axis=0)  # (1, 80)\n",
        "        spectrogram = np.tile(spectrogram, (1, 1, 80))  # (1, 80, 80) - square image\n",
        "        spectrogram = torch.FloatTensor(spectrogram)\n",
        "\n",
        "        label = torch.LongTensor([self.labels[file_id]])\n",
        "\n",
        "        return {\n",
        "            'audio_features': audio_features,\n",
        "            'text_input_ids': text_input_ids,\n",
        "            'text_attention_mask': text_attention_mask,\n",
        "            'spectrogram': spectrogram,\n",
        "            'label': label,\n",
        "            'file_id': file_id\n",
        "        }\n",
        "\n",
        "class ADReSSoTrainer:\n",
        "    \"\"\"Training and evaluation class\"\"\"\n",
        "    def __init__(self, model, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer, mode='min', factor=0.5, patience=5\n",
        "        )\n",
        "\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.train_accuracies = []\n",
        "        self.val_accuracies = []\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            # Move to device\n",
        "            audio_features = batch['audio_features'].to(self.device)\n",
        "            text_input_ids = batch['text_input_ids'].to(self.device)\n",
        "            text_attention_mask = batch['text_attention_mask'].to(self.device)\n",
        "            spectrograms = batch['spectrogram'].to(self.device)\n",
        "            labels = batch['label'].squeeze().to(self.device)\n",
        "\n",
        "            # Forward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(audio_features, text_input_ids, text_attention_mask, spectrograms)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        accuracy = 100. * correct / total\n",
        "\n",
        "        return avg_loss, accuracy\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                # Move to device\n",
        "                audio_features = batch['audio_features'].to(self.device)\n",
        "                text_input_ids = batch['text_input_ids'].to(self.device)\n",
        "                text_attention_mask = batch['text_attention_mask'].to(self.device)\n",
        "                spectrograms = batch['spectrogram'].to(self.device)\n",
        "                labels = batch['label'].squeeze().to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(audio_features, text_input_ids, text_attention_mask, spectrograms)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "                # Statistics\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                # Store for detailed metrics\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probs.extend(F.softmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "        avg_loss = total_loss / len(val_loader)\n",
        "        accuracy = 100. * correct / total\n",
        "\n",
        "        return avg_loss, accuracy, all_preds, all_labels, all_probs\n",
        "\n",
        "    def train(self, train_loader, val_loader, num_epochs=5):\n",
        "        print(f\"Training on {self.device}\")\n",
        "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
        "\n",
        "        best_val_acc = 0\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "            print('-' * 50)\n",
        "\n",
        "            # Training\n",
        "            train_loss, train_acc = self.train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "            self.train_accuracies.append(train_acc)\n",
        "\n",
        "            # Validation\n",
        "            val_loss, val_acc, val_preds, val_labels, val_probs = self.validate(val_loader)\n",
        "            self.val_losses.append(val_loss)\n",
        "            self.val_accuracies.append(val_acc)\n",
        "\n",
        "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "            # Learning rate scheduling\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping and model saving\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                torch.save(self.model.state_dict(), 'best_adresso_model.pth')\n",
        "                patience_counter = 0\n",
        "                print(f'New best validation accuracy: {best_val_acc:.2f}%')\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= 10:\n",
        "                    print('Early stopping triggered')\n",
        "                    break\n",
        "\n",
        "        print(f'\\nTraining completed. Best validation accuracy: {best_val_acc:.2f}%')\n",
        "\n",
        "    def evaluate_detailed(self, test_loader, class_names=['CN', 'AD']):\n",
        "        \"\"\"Detailed evaluation with metrics and visualizations\"\"\"\n",
        "        self.model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "        all_file_ids = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # Move to device\n",
        "                audio_features = batch['audio_features'].to(self.device)\n",
        "                text_input_ids = batch['text_input_ids'].to(self.device)\n",
        "                text_attention_mask = batch['text_attention_mask'].to(self.device)\n",
        "                spectrograms = batch['spectrogram'].to(self.device)\n",
        "                labels = batch['label'].squeeze().to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(audio_features, text_input_ids, text_attention_mask, spectrograms)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                # Store results\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "                all_file_ids.extend(batch['file_id'])\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "\n",
        "        # ROC AUC (for binary classification)\n",
        "        if len(class_names) == 2:\n",
        "            probs_positive = [prob[1] for prob in all_probs]\n",
        "            auc = roc_auc_score(all_labels, probs_positive)\n",
        "        else:\n",
        "            auc = None\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "        # Print results\n",
        "        print(\"=\"*60)\n",
        "        print(\"DETAILED EVALUATION RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1-Score: {f1:.4f}\")\n",
        "        if auc:\n",
        "            print(f\"ROC AUC: {auc:.4f}\")\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Plot training curves\n",
        "        self.plot_training_curves()\n",
        "\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame({\n",
        "            'file_id': all_file_ids,\n",
        "            'true_label': all_labels,\n",
        "            'predicted_label': all_preds,\n",
        "            'confidence': [max(prob) for prob in all_probs],\n",
        "            'prob_CN': [prob[0] for prob in all_probs],\n",
        "            'prob_AD': [prob[1] for prob in all_probs] if len(all_probs[0]) > 1 else [0] * len(all_probs)\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'auc': auc,\n",
        "            'confusion_matrix': cm,\n",
        "            'results_df': results_df\n",
        "        }\n",
        "\n",
        "    def plot_training_curves(self):\n",
        "        \"\"\"Plot training and validation curves\"\"\"\n",
        "        fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # Loss curves\n",
        "        ax1.plot(self.train_losses, label='Training Loss', color='blue')\n",
        "        ax1.plot(self.val_losses, label='Validation Loss', color='red')\n",
        "        ax1.set_title('Training and Validation Loss')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # Accuracy curves\n",
        "        ax2.plot(self.train_accuracies, label='Training Accuracy', color='blue')\n",
        "        ax2.plot(self.val_accuracies, label='Validation Accuracy', color='red')\n",
        "        ax2.set_title('Training and Validation Accuracy')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Accuracy (%)')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def visualize_semantic_graph(text_features, audio_features, file_id, save_path=None):\n",
        "    \"\"\"Visualize semantic relationships between audio and text\"\"\"\n",
        "    # Compute similarity\n",
        "    similarity = F.cosine_similarity(text_features, audio_features, dim=0).item()\n",
        "\n",
        "    # Create networkx graph\n",
        "    G = nx.Graph()\n",
        "    G.add_node(\"Text\", type=\"text\", features=text_features[:5].tolist())\n",
        "    G.add_node(\"Audio\", type=\"audio\", features=audio_features[:5].tolist())\n",
        "\n",
        "    # Add edge if similarity is significant\n",
        "    if similarity > 0.1:\n",
        "        G.add_edge(\"Text\", \"Audio\", weight=similarity, similarity=similarity)\n",
        "\n",
        "    # Visualize\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    pos = nx.spring_layout(G, k=3, iterations=50)\n",
        "\n",
        "    # Draw nodes\n",
        "    node_colors = ['lightblue' if G.nodes[node]['type'] == 'text' else 'lightcoral'\n",
        "                   for node in G.nodes()]\n",
        "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=3000, alpha=0.7)\n",
        "\n",
        "    # Draw edges\n",
        "    if G.edges():\n",
        "        edge_widths = [G[u][v]['weight'] * 10 for u, v in G.edges()]\n",
        "        nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.6, edge_color='gray')\n",
        "\n",
        "    # Draw labels\n",
        "    nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')\n",
        "\n",
        "    # Add edge labels\n",
        "    if G.edges():\n",
        "        edge_labels = {(u, v): f\"Sim: {G[u][v]['similarity']:.3f}\"\n",
        "                      for u, v in G.edges()}\n",
        "        nx.draw_networkx_edge_labels(G, pos, edge_labels, font_size=10)\n",
        "\n",
        "    plt.title(f'Semantic Relationship Graph - {file_id}\\nSimilarity: {similarity:.3f}')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return G, similarity\n",
        "\n",
        "# Step 6: Model Architecture Extension for ADReSSoAnalyzer\n",
        "def extend_analyzer_with_model():\n",
        "    \"\"\"Extend the ADReSSoAnalyzer class with the new model architecture\"\"\"\n",
        "\n",
        "    class ADReSSoAnalyzerExtended(ADReSSoAnalyzer):\n",
        "        def __init__(self, base_path=\"/content/drive/MyDrive/Voice/extracted/ADReSSo21\"):\n",
        "            super().__init__(base_path)\n",
        "            self.model = None\n",
        "            self.trainer = None\n",
        "            self.scaler = StandardScaler()\n",
        "\n",
        "        def step_6_define_model_architecture(self):\n",
        "            \"\"\"Step 6: Define the multi-modal model architecture\"\"\"\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"STEP 6: DEFINING MODEL ARCHITECTURE\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            print(\"Initializing Multi-Modal Architecture:\")\n",
        "            print(\"- Graph-based Attention Module\")\n",
        "            print(\"- Vision Transformer Module\")\n",
        "            print(\"- U-Net Module\")\n",
        "            print(\"- AlexNet Module\")\n",
        "            print(\"- BERT for text processing\")\n",
        "            print(\"- Fusion and Classification layers\")\n",
        "\n",
        "            # Initialize model\n",
        "            self.model = MultiModalADReSSoModel(\n",
        "                audio_feature_dim=768,  # Wav2Vec2 dimension\n",
        "                text_feature_dim=768,   # BERT dimension\n",
        "                spectrogram_height=80,  # Mel spectrogram bins\n",
        "                num_classes=2           # AD vs CN\n",
        "            )\n",
        "\n",
        "            # Initialize trainer\n",
        "            self.trainer = ADReSSoTrainer(self.model)\n",
        "\n",
        "            print(f\"\\nModel initialized with {sum(p.numel() for p in self.model.parameters()):,} parameters\")\n",
        "            print(\"Architecture components ready for training!\")\n",
        "\n",
        "            return self.model\n",
        "\n",
        "        def step_7_train_model(self, features_dict, linguistic_features, batch_size=8, num_epochs=30):\n",
        "            \"\"\"Step 7: Train the multi-modal model\"\"\"\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"STEP 7: TRAINING MODEL\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            if self.model is None:\n",
        "                print(\"Model not initialized. Running Step 6 first...\")\n",
        "                self.step_6_define_model_architecture()\n",
        "\n",
        "            # Prepare labels based on file categories\n",
        "            labels = {}\n",
        "            for file_id in features_dict.keys():\n",
        "                if 'diagnosis_ad' in file_id or 'progression_decline' in file_id:\n",
        "                    labels[file_id] = 1  # AD/Decline\n",
        "                else:\n",
        "                    labels[file_id] = 0  # CN/No decline\n",
        "\n",
        "            print(f\"Dataset summary:\")\n",
        "            print(f\"- Total files: {len(features_dict)}\")\n",
        "            print(f\"- AD/Decline cases: {sum(labels.values())}\")\n",
        "            print(f\"- CN/No decline cases: {len(labels) - sum(labels.values())}\")\n",
        "\n",
        "            # Split data\n",
        "            file_ids = list(features_dict.keys())\n",
        "            train_ids, test_ids = train_test_split(file_ids, test_size=0.2,\n",
        "                                                 stratify=[labels[f] for f in file_ids],\n",
        "                                                 random_state=42)\n",
        "            train_ids, val_ids = train_test_split(train_ids, test_size=0.2,\n",
        "                                                stratify=[labels[f] for f in train_ids],\n",
        "                                                random_state=42)\n",
        "\n",
        "            print(f\"\\nData split:\")\n",
        "            print(f\"- Training: {len(train_ids)} files\")\n",
        "            print(f\"- Validation: {len(val_ids)} files\")\n",
        "            print(f\"- Testing: {len(test_ids)} files\")\n",
        "\n",
        "            # Create datasets\n",
        "            train_features = {fid: features_dict[fid] for fid in train_ids}\n",
        "            val_features = {fid: features_dict[fid] for fid in val_ids}\n",
        "            test_features = {fid: features_dict[fid] for fid in test_ids}\n",
        "\n",
        "            train_linguistic = {fid: linguistic_features[fid] for fid in train_ids}\n",
        "            val_linguistic = {fid: linguistic_features[fid] for fid in val_ids}\n",
        "            test_linguistic = {fid: linguistic_features[fid] for fid in test_ids}\n",
        "\n",
        "            train_labels = {fid: labels[fid] for fid in train_ids}\n",
        "            val_labels = {fid: labels[fid] for fid in val_ids}\n",
        "            test_labels = {fid: labels[fid] for fid in test_ids}\n",
        "\n",
        "            # Create data loaders\n",
        "            train_dataset = ADReSSoDataset(train_features, train_linguistic, train_labels)\n",
        "            val_dataset = ADReSSoDataset(val_features, val_linguistic, val_labels)\n",
        "            test_dataset = ADReSSoDataset(test_features, test_linguistic, test_labels)\n",
        "\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "            print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
        "\n",
        "            # Train the model\n",
        "            self.trainer.train(train_loader, val_loader, num_epochs=num_epochs)\n",
        "\n",
        "            # Store test loader for evaluation\n",
        "            self.test_loader = test_loader\n",
        "\n",
        "            print(\"Training completed!\")\n",
        "            return self.trainer\n",
        "\n",
        "        def step_8_evaluate_model(self, visualize_graphs=True, num_graph_samples=5):\n",
        "            \"\"\"Step 8: Evaluate model and visualize semantic relationships\"\"\"\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"STEP 8: MODEL EVALUATION AND SEMANTIC ANALYSIS\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            if self.trainer is None:\n",
        "                print(\"Model not trained. Please run Step 7 first.\")\n",
        "                return None\n",
        "\n",
        "            # Load best model\n",
        "            self.model.load_state_dict(torch.load('best_adresso_model.pth'))\n",
        "\n",
        "            # Detailed evaluation\n",
        "            print(\"Performing detailed evaluation...\")\n",
        "            evaluation_results = self.trainer.evaluate_detailed(\n",
        "                self.test_loader, class_names=['CN', 'AD']\n",
        "            )\n",
        "\n",
        "            # Visualize semantic relationships\n",
        "            if visualize_graphs:\n",
        "                print(f\"\\nVisualizing semantic relationships for {num_graph_samples} samples...\")\n",
        "                self.visualize_semantic_relationships(num_samples=num_graph_samples)\n",
        "\n",
        "            # Additional analysis\n",
        "            self.analyze_feature_importance()\n",
        "            self.generate_evaluation_report(evaluation_results)\n",
        "\n",
        "            return evaluation_results\n",
        "\n",
        "        def visualize_semantic_relationships(self, num_samples=5):\n",
        "            \"\"\"Visualize semantic graphs for sample files\"\"\"\n",
        "            self.model.eval()\n",
        "            sample_count = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in self.test_loader:\n",
        "                    if sample_count >= num_samples:\n",
        "                        break\n",
        "\n",
        "                    # Process batch\n",
        "                    audio_features = batch['audio_features'].to(self.trainer.device)\n",
        "                    text_input_ids = batch['text_input_ids'].to(self.trainer.device)\n",
        "                    text_attention_mask = batch['text_attention_mask'].to(self.trainer.device)\n",
        "                    file_ids = batch['file_id']\n",
        "\n",
        "                    # Get BERT features\n",
        "                    bert_outputs = self.model.bert(\n",
        "                        input_ids=text_input_ids,\n",
        "                        attention_mask=text_attention_mask\n",
        "                    )\n",
        "                    text_features = bert_outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "                    # Visualize each sample in batch\n",
        "                    for i in range(min(len(file_ids), num_samples - sample_count)):\n",
        "                        file_id = file_ids[i]\n",
        "                        text_feat = text_features[i]\n",
        "                        audio_feat = audio_features[i]\n",
        "\n",
        "                        print(f\"\\nVisualizing semantic relationships for: {file_id}\")\n",
        "\n",
        "                        # Create and visualize graph\n",
        "                        graph, similarity = visualize_semantic_graph(\n",
        "                            text_feat.cpu(),\n",
        "                            audio_feat.cpu(),\n",
        "                            file_id,\n",
        "                            save_path=f\"semantic_graph_{file_id}.png\"\n",
        "                        )\n",
        "\n",
        "                        # Print relationship analysis\n",
        "                        self.analyze_semantic_relationship(text_feat.cpu(), audio_feat.cpu(), file_id)\n",
        "\n",
        "                        sample_count += 1\n",
        "\n",
        "                        if sample_count >= num_samples:\n",
        "                            break\n",
        "\n",
        "        def analyze_semantic_relationship(self, text_features, audio_features, file_id):\n",
        "            \"\"\"Analyze the semantic relationship between audio and text\"\"\"\n",
        "            # Compute various similarity metrics\n",
        "            cosine_sim = F.cosine_similarity(text_features, audio_features, dim=0).item()\n",
        "\n",
        "            # L2 distance (normalized)\n",
        "            l2_distance = torch.norm(text_features - audio_features).item()\n",
        "            normalized_l2 = l2_distance / (torch.norm(text_features) + torch.norm(audio_features)).item()\n",
        "\n",
        "            # Dot product similarity\n",
        "            dot_product = torch.dot(text_features, audio_features).item()\n",
        "\n",
        "            print(f\"Semantic Relationship Analysis for {file_id}:\")\n",
        "            print(f\"  - Cosine Similarity: {cosine_sim:.4f}\")\n",
        "            print(f\"  - Normalized L2 Distance: {normalized_l2:.4f}\")\n",
        "            print(f\"  - Dot Product: {dot_product:.4f}\")\n",
        "\n",
        "            # Interpretation\n",
        "            if cosine_sim > 0.7:\n",
        "                relationship = \"Strong positive correlation\"\n",
        "            elif cosine_sim > 0.3:\n",
        "                relationship = \"Moderate positive correlation\"\n",
        "            elif cosine_sim > 0.1:\n",
        "                relationship = \"Weak positive correlation\"\n",
        "            elif cosine_sim > -0.1:\n",
        "                relationship = \"No significant correlation\"\n",
        "            else:\n",
        "                relationship = \"Negative correlation\"\n",
        "\n",
        "            print(f\"  - Relationship Interpretation: {relationship}\")\n",
        "\n",
        "            return {\n",
        "                'cosine_similarity': cosine_sim,\n",
        "                'l2_distance': normalized_l2,\n",
        "                'dot_product': dot_product,\n",
        "                'relationship': relationship\n",
        "            }\n",
        "\n",
        "        def analyze_feature_importance(self):\n",
        "            \"\"\"Analyze feature importance across different modalities\"\"\"\n",
        "            print(\"\\nAnalyzing feature importance across modalities...\")\n",
        "\n",
        "            self.model.eval()\n",
        "            modality_contributions = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in self.test_loader:\n",
        "                    # Get features\n",
        "                    audio_features = batch['audio_features'].to(self.trainer.device)\n",
        "                    text_input_ids = batch['text_input_ids'].to(self.trainer.device)\n",
        "                    text_attention_mask = batch['text_attention_mask'].to(self.trainer.device)\n",
        "                    spectrograms = batch['spectrogram'].to(self.trainer.device)\n",
        "\n",
        "                    # Process text with BERT\n",
        "                    bert_outputs = self.model.bert(input_ids=text_input_ids, attention_mask=text_attention_mask)\n",
        "                    text_features = bert_outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "                    # Get individual modality outputs\n",
        "                    graph_batch = self.model.create_semantic_graph(text_features, audio_features)\n",
        "                    graph_out = self.model.graph_attention(graph_batch.x, graph_batch.edge_index, graph_batch.batch)\n",
        "                    vit_out = self.model.vision_transformer(spectrograms)\n",
        "\n",
        "                    audio_1d = audio_features.unsqueeze(1)\n",
        "                    unet_out = self.model.unet(audio_1d)\n",
        "                    alexnet_out = self.model.alexnet(audio_features)\n",
        "\n",
        "                    # Calculate contribution magnitudes\n",
        "                    contributions = {\n",
        "                        'Graph Attention': torch.norm(graph_out, dim=1).mean().item(),\n",
        "                        'Vision Transformer': torch.norm(vit_out, dim=1).mean().item(),\n",
        "                        'U-Net': torch.norm(unet_out, dim=1).mean().item(),\n",
        "                        'AlexNet': torch.norm(alexnet_out, dim=1).mean().item()\n",
        "                    }\n",
        "\n",
        "                    modality_contributions.append(contributions)\n",
        "\n",
        "                    # Only analyze first few batches to save time\n",
        "                    if len(modality_contributions) >= 5:\n",
        "                        break\n",
        "\n",
        "            # Aggregate results\n",
        "            avg_contributions = {}\n",
        "            for modality in modality_contributions[0].keys():\n",
        "                avg_contributions[modality] = np.mean([contrib[modality] for contrib in modality_contributions])\n",
        "\n",
        "            # Visualize feature importance\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            modalities = list(avg_contributions.keys())\n",
        "            contributions = list(avg_contributions.values())\n",
        "\n",
        "            bars = plt.bar(modalities, contributions, color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
        "            plt.title('Average Feature Contribution by Modality')\n",
        "            plt.ylabel('Average L2 Norm')\n",
        "            plt.xlabel('Modality')\n",
        "            plt.xticks(rotation=45)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for bar, value in zip(bars, contributions):\n",
        "                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                        f'{value:.3f}', ha='center', va='bottom')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            print(\"Feature Importance Analysis:\")\n",
        "            for modality, contribution in avg_contributions.items():\n",
        "                print(f\"  - {modality}: {contribution:.4f}\")\n",
        "\n",
        "            return avg_contributions\n",
        "\n",
        "        def generate_evaluation_report(self, evaluation_results):\n",
        "            \"\"\"Generate comprehensive evaluation report\"\"\"\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"COMPREHENSIVE EVALUATION REPORT\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            # Performance metrics\n",
        "            print(\"PERFORMANCE METRICS:\")\n",
        "            print(f\"  - Overall Accuracy: {evaluation_results['accuracy']:.4f}\")\n",
        "            print(f\"  - Precision: {evaluation_results['precision']:.4f}\")\n",
        "            print(f\"  - Recall: {evaluation_results['recall']:.4f}\")\n",
        "            print(f\"  - F1-Score: {evaluation_results['f1']:.4f}\")\n",
        "            if evaluation_results['auc']:\n",
        "                print(f\"  - ROC AUC: {evaluation_results['auc']:.4f}\")\n",
        "\n",
        "            # Results by category\n",
        "            results_df = evaluation_results['results_df']\n",
        "\n",
        "            print(\"\\nRESULTS BY CATEGORY:\")\n",
        "            for category in ['diagnosis_ad', 'diagnosis_cn', 'progression_decline', 'progression_no_decline']:\n",
        "                category_results = results_df[results_df['file_id'].str.contains(category)]\n",
        "                if len(category_results) > 0:\n",
        "                    accuracy = (category_results['true_label'] == category_results['predicted_label']).mean()\n",
        "                    avg_confidence = category_results['confidence'].mean()\n",
        "                    print(f\"  - {category}:\")\n",
        "                    print(f\"    * Accuracy: {accuracy:.4f}\")\n",
        "                    print(f\"    * Average Confidence: {avg_confidence:.4f}\")\n",
        "                    print(f\"    * Sample Count: {len(category_results)}\")\n",
        "\n",
        "            # Misclassification analysis\n",
        "            print(\"\\nMISCLASSIFICATION ANALYSIS:\")\n",
        "            misclassified = results_df[results_df['true_label'] != results_df['predicted_label']]\n",
        "            print(f\"  - Total Misclassified: {len(misclassified)}\")\n",
        "            print(f\"  - Misclassification Rate: {len(misclassified)/len(results_df):.4f}\")\n",
        "\n",
        "            if len(misclassified) > 0:\n",
        "                print(\"  - Misclassified Samples:\")\n",
        "                for _, row in misclassified.head().iterrows():\n",
        "                    print(f\"    * {row['file_id']}: True={row['true_label']}, Pred={row['predicted_label']}, Conf={row['confidence']:.3f}\")\n",
        "\n",
        "            # High confidence predictions\n",
        "            high_conf = results_df[results_df['confidence'] > 0.9]\n",
        "            print(f\"\\nHIGH CONFIDENCE PREDICTIONS (>0.9):\")\n",
        "            print(f\"  - Count: {len(high_conf)}\")\n",
        "            print(f\"  - Accuracy: {(high_conf['true_label'] == high_conf['predicted_label']).mean():.4f}\")\n",
        "\n",
        "            # Save detailed results\n",
        "            results_df.to_csv(f\"{self.output_path}/detailed_evaluation_results.csv\", index=False)\n",
        "\n",
        "            # Save evaluation summary\n",
        "            summary_dict = {\n",
        "                'accuracy': evaluation_results['accuracy'],\n",
        "                'precision': evaluation_results['precision'],\n",
        "                'recall': evaluation_results['recall'],\n",
        "                'f1_score': evaluation_results['f1'],\n",
        "                'roc_auc': evaluation_results['auc'],\n",
        "                'total_samples': len(results_df),\n",
        "                'misclassified_count': len(misclassified),\n",
        "                'high_confidence_count': len(high_conf)\n",
        "            }\n",
        "\n",
        "            with open(f\"{self.output_path}/evaluation_summary.json\", 'w') as f:\n",
        "                json.dump(summary_dict, f, indent=2)\n",
        "\n",
        "            print(f\"\\nDetailed results saved to:\")\n",
        "            print(f\"  - {self.output_path}/detailed_evaluation_results.csv\")\n",
        "            print(f\"  - {self.output_path}/evaluation_summary.json\")\n",
        "\n",
        "            return summary_dict\n",
        "\n",
        "        def run_complete_pipeline_with_model(self, num_epochs=30, batch_size=8):\n",
        "            \"\"\"Run the complete pipeline including model training and evaluation\"\"\"\n",
        "            print(\"=\"*80)\n",
        "            print(\"COMPLETE ADReSSo MULTI-MODAL ANALYSIS PIPELINE\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            # Run original pipeline (Steps 0-5)\n",
        "            results = self.run_complete_pipeline()\n",
        "\n",
        "            if results is None:\n",
        "                print(\"Error in initial pipeline. Cannot proceed with model training.\")\n",
        "                return None\n",
        "\n",
        "            # Extract features and linguistic data\n",
        "            features_dict = {}\n",
        "            audio_files = results['audio_files']\n",
        "\n",
        "            # Extract acoustic features for all files\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"EXTRACTING ACOUSTIC FEATURES FOR MODEL TRAINING\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            for category, files in audio_files.items():\n",
        "                print(f\"\\nProcessing {category}...\")\n",
        "                for file_path in files:\n",
        "                    filename = os.path.basename(file_path)\n",
        "                    file_id = f\"{category}_{filename}\"\n",
        "\n",
        "                    print(f\"  Extracting features for {filename}...\")\n",
        "                    features = self.extract_acoustic_features(file_path)\n",
        "\n",
        "                    if features is not None:\n",
        "                        features_dict[file_id] = features\n",
        "                    else:\n",
        "                        print(f\"  Warning: Could not extract features for {filename}\")\n",
        "\n",
        "            print(f\"\\nSuccessfully extracted features for {len(features_dict)} files\")\n",
        "\n",
        "            # Step 6: Define model architecture\n",
        "            self.step_6_define_model_architecture()\n",
        "\n",
        "            # Step 7: Train model\n",
        "            self.step_7_train_model(\n",
        "                features_dict,\n",
        "                results['linguistic_features'],\n",
        "                batch_size=batch_size,\n",
        "                num_epochs=num_epochs\n",
        "            )\n",
        "\n",
        "            # Step 8: Evaluate model\n",
        "            evaluation_results = self.step_8_evaluate_model()\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "            print(\"=\"*80)\n",
        "            print(\"\\nAll results saved to output directory.\")\n",
        "            print(\"Model training and evaluation completed with semantic relationship analysis.\")\n",
        "\n",
        "            return {\n",
        "                'original_results': results,\n",
        "                'features_dict': features_dict,\n",
        "                'model': self.model,\n",
        "                'trainer': self.trainer,\n",
        "                'evaluation_results': evaluation_results\n",
        "            }\n",
        "\n",
        "    return ADReSSoAnalyzerExtended\n",
        "\n",
        "# Usage Example\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Create extended analyzer\n",
        "#     ExtendedAnalyzer = extend_analyzer_with_model()\n",
        "#     analyzer = ExtendedAnalyzer()\n",
        "\n",
        "#     # Run complete pipeline\n",
        "#     print(\"Starting ADReSSo Multi-Modal Analysis Pipeline...\")\n",
        "#     complete_results = analyzer.run_complete_pipeline_with_model(\n",
        "#         num_epochs=5,  # Adjust based on your computational resources\n",
        "#         batch_size=4    # Adjust based on your GPU memory\n",
        "#     )\n",
        "\n",
        "#     if complete_results:\n",
        "#         print(\"\\nPipeline completed successfully!\")\n",
        "#         print(\"Check the output directory for all results and visualizations.\")\n",
        "#     else:\n",
        "#         print(\"Pipeline encountered errors. Please check the dataset path and requirements.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d5b48d7520374a8fb2b22dd87a4407f6",
            "a9ba4ffe7d914dd2acd3e1dc66c2b3d6",
            "183d388405ab475ea18004de38ee0227",
            "1cd03aa7a27048fd93df2ce4e77908dc",
            "1bc67752d48946a994b28cdc0c1c3941",
            "526a34ce4884418da30ed8e1ec6c95e5",
            "c6ca8f17ba6a42898c6461b2d9de8601",
            "6eaa0759a6cc4abf8f90c02e241fc5d4",
            "492acdc324f74447a839c0b4e9ba7204",
            "28fb02af24ce458a8b2a15a7a52eeaab",
            "7c373a821dd64c3fb86d89664f94babe",
            "3a0d86b39da24a279de885f20e7bee38",
            "8fb33603007a4715a5188c876adbd835",
            "9cf28078d4fe4b10bee00ec11249c109",
            "ad2cb552503041709d21b18cf391d2ea",
            "27ad1f752d134db8b72f3522d27d7b62",
            "323d1e2fe3b648e1b2c91f7e8412bb77",
            "780649ebbfdd457da4a259304e76b1e2",
            "df43fd5608d84b15907cbae7c1c0b903",
            "32ce043088a846bab906238f3215e7db",
            "c993f549273647468ab53d084a72f3d6",
            "ec91e010905c40ea89074c6e2109c043",
            "66e6d84399584a4da3ce66bfac7b9d31",
            "8eec64c1b96d4050ac8a9b15595ceebc",
            "9223a66867ea4b1686d1a343a516b445",
            "311a77b3e2394b25aae2d306604a358f",
            "d3b845da15864ea79be15c429b2149ac",
            "085c40ce31074421a5c82ce5de8ff7ae",
            "3be28192135d47fcb1b6a729f30a268e",
            "12a86b5b5a0e4a2a836e7486dfed3dd2",
            "6bc3b947c6424c6e8b93a2a6698cb359",
            "92ae1cdb1a3f4cfbab6d6af0ef8375cf",
            "379904d0000b42e2a38a0bf983da0073",
            "922350dbab764457b66d0bb232379f7b",
            "b226daa87ede4b45921d01d68303b598",
            "4463c417d7d144adb4ea048cacd80fef",
            "0c454637e4904ce2b2d8ea22479a2c76",
            "82c2814f62f143f9813a6bddbf275620",
            "5c7a5700240b4c9397d8e0e6cb99db68",
            "b45ff45a35ec413681987a4961c47007",
            "00d2d7c8a32042d59f455db492659fa8",
            "825e5cc9e6624670a2e68765e9c872ec",
            "01eb3cb50e0f4d308a83df0db0cec5df",
            "fbbcf58b18614fe896e6566607e4ecf8",
            "2ee149d1cdf947e4b2202136dc7d05a2",
            "b502424a9bcb4709a8dfa5adb99ebfa0",
            "ee3936033c5d4d0cbe7a6604fd9537e1",
            "6d3dca3c6a3447659b9704754162fee7",
            "ea261aa99df64131b6764a1d45c4f8ab",
            "79b17702bc1645eca397b3c4d256d86c",
            "7d0e0ca80dad44c29617f2c77ab22297",
            "4e85951aecb048688e251c1eb8aa8513",
            "90b26cb3a9e245549f2d7ee725b7199e",
            "75ad9c3cdd3c49a6b7c3c541c83a47aa",
            "6c5c537380c3430bbea71579912fab56",
            "8a4cf81841484d39927abf4e3ae2a0d2",
            "264f958643dc460485a1e70be6e737da",
            "04644ba96db34197a2ecd69763f9786a",
            "af76f0c8d9894c5a8a49faefd2917da3",
            "319364b2a63d45b3896c9e874aa10c16",
            "26e7cdd427b84218bc6f6607863560ba",
            "fcffb97fb1d44f979241d3e634cd7e3a",
            "dd1bb15cc2bf41db8d66a15bc159bcd9",
            "ab9a6d44e29e4d488701b76a0642e602",
            "8635cc72523d4f79b562d0c066840f3c",
            "47e04a35e17a4e34817e52faa1d38b45",
            "42d827b72aea448d8219ffe7bb921fd0",
            "5f00b685abaf4f89a5a9b451d0e32774",
            "007249e062f1443d889d23932b234557",
            "56557b9ef418434dae91ca177fd78d4b",
            "ecca5ac4df0d4302b3f76829857c39de",
            "eaed34bc74f8487da826206b1013c8a4",
            "259cf80ed17042cf911bdc53b88ed9a6",
            "095b431fe1224689973221b42f2169a4",
            "0fc842326d724812bc47a0c2ecec5c4d",
            "ee765f009b9a4b948b55453dfe7bf29f",
            "40c65782835742b98d1efbe92891d3a0",
            "582f0f2655cc4a5996aab903b04575b9",
            "85bf0247df4c4dddb3c15b4f51997b9b",
            "d6936089476e40a3b41545600cd657e8",
            "aea5ec73bf134e60bc73beb4c6dac44c",
            "6567241487384d88868f8da74ca84e19",
            "ef85fa48af17473a8dda483e47ebceea",
            "86768e90e3544f149d8ab36417ed697c",
            "dded59f4012e447a82f334d92598cec0",
            "eb66ecf3fe1f40dc90c495baa2079349",
            "08de1c36f11840ada3a01fa309033172",
            "c0c929813f87494786da47f737674130",
            "2ba66772ade84fab8e0dfab71822a839",
            "f48abeb78e564a788799ec3dabb77de2",
            "5026be8619184bcba4bcf45f663c7fa3",
            "ddd45d1edcea402ca186f09656ffaa1c",
            "511928fea5ab406cadf149e88d3a8ac7",
            "525e34fe0cb64b259816596458cd6783",
            "c4c0e4ae6fac4ed181b60ae0676facab",
            "1117e567fc274d14bfa7efc770cb923f",
            "b08e58c1f3424b87ae1bca7cc0b02918",
            "626f5fa3d87d49199eb451d089db33c7",
            "94c51560b35744589e5c4afc484073f9",
            "f812dfe6009c48d8b762fcfe642e5cda",
            "218a0a92bfbe4b318a4ef81016ddb0c4",
            "e4ee293d041944dc9128c1968cbb14b7",
            "41fe29f4861e4b3e91761b4c68fb1179",
            "f379255f4397418caf8704114c864e2b",
            "5f80cf032dbb47e9b6cf2bbbcb120270",
            "76b98eba0fea4276b4106114459fe8ec",
            "2e51747a456a495bb0fb05df47e5e8ce",
            "328c1d20304948b18bf24fb86aede35c",
            "48b901cee33842029fe8be6d5954f9e6",
            "151ed1673f4e4b7993a7c9211cbf7e1b",
            "ebf86f2106cb4e33810c83fad03d416c",
            "b976ffa9643a43b98f97cf337118a82c",
            "dd559c6175514656a90a7bf0f932217d",
            "4dd14bc5800842c0a02325db07a6828f",
            "086dc534062b4474a1f1ae78870ff707",
            "36188ba445414141888bd4fbfa992ac3",
            "ceeacc4c5f444c8a814555c934a26148",
            "bafc0f56bde94361a55f7356cccff7e7",
            "71be055d24654f889ef716038c0d7a65",
            "be2bc7d280144a0585d46aacfc878e3e",
            "a3b9409e86bb4a95bea9758d0d2219b7"
          ]
        },
        "id": "cU-HI2DE50DC",
        "outputId": "cc02e234-ecec-4aec-986b-0dd72ebc2766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: opensmile in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: audobject>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from opensmile) (0.7.12)\n",
            "Requirement already satisfied: audinterface>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from opensmile) (1.3.1)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: audeer>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from audinterface>=0.7.0->opensmile) (2.2.2)\n",
            "Requirement already satisfied: audformat<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from audinterface>=0.7.0->opensmile) (1.3.2)\n",
            "Requirement already satisfied: audiofile>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from audinterface>=0.7.0->opensmile) (1.5.1)\n",
            "Requirement already satisfied: audmath>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from audinterface>=0.7.0->opensmile) (1.4.1)\n",
            "Requirement already satisfied: audresample<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from audinterface>=0.7.0->opensmile) (1.3.3)\n",
            "Requirement already satisfied: asttokens>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (3.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (8.7.0)\n",
            "Requirement already satisfied: oyaml in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain) (1.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain) (0.18.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: iso639-lang in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.6.0)\n",
            "Requirement already satisfied: iso3166 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.1.1)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (18.1.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.22.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 44.7MiB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5b48d7520374a8fb2b22dd87a4407f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a0d86b39da24a279de885f20e7bee38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66e6d84399584a4da3ce66bfac7b9d31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "922350dbab764457b66d0bb232379f7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ee149d1cdf947e4b2202136dc7d05a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a4cf81841484d39927abf4e3ae2a0d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42d827b72aea448d8219ffe7bb921fd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "582f0f2655cc4a5996aab903b04575b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ba66772ade84fab8e0dfab71822a839",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f812dfe6009c48d8b762fcfe642e5cda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebf86f2106cb4e33810c83fad03d416c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No checkpoint found, starting fresh\n",
            "================================================================================\n",
            "RUNNING ADReSSo PIPELINE WITH CHECKPOINTING\n",
            "================================================================================\n",
            "=== ADReSSo21 Speech Analysis Pipeline ===\n",
            "\n",
            "Step 0: Getting audio files...\n",
            "Found 271 audio files across all categories\n",
            "  diagnosis_ad: 87 files\n",
            "  diagnosis_cn: 79 files\n",
            "  progression_decline: 15 files\n",
            "  progression_no_decline: 58 files\n",
            "  progression_test: 32 files\n",
            "\n",
            "==================================================\n",
            "Step 1: Demonstrating acoustic features...\n",
            "\n",
            "Showing features for diagnosis_ad:\n",
            "=== Acoustic Features for adrso047.wav ===\n",
            "\n",
            "1. eGeMAPS Features: 88 features\n",
            "   Shape: (88,)\n",
            "   Sample values: [25.866777    0.31971478 16.288124   26.47413    34.226044  ]\n",
            "\n",
            "2. MFCC Features:\n",
            "   Mean: (13,) - [-283.20312     76.72155      4.9237657   23.371506   -11.170574 ]\n",
            "   Std: (13,) - [79.158615 30.192682 25.279158 24.67176  18.788862]\n",
            "   Delta: (13,) - [ 0.3264354  -0.00845834 -0.01544069  0.0086811  -0.01617551]\n",
            "   Delta-Delta: (13,) - [ 0.01663556  0.00127252  0.00217276 -0.00220479  0.00038056]\n",
            "\n",
            "3. Log-Mel Spectrogram Features:\n",
            "   Mean: (80,) - [-23.605774  -18.057337  -11.690929  -10.313613   -7.5411944]\n",
            "   Std: (80,) - [11.996229  9.398558  6.633258  6.546015  8.263119]\n",
            "\n",
            "4. Wav2Vec2 Features: (768,)\n",
            "   Sample values: [-0.02854712 -0.00418562 -0.07545928 -0.05687362  0.00764589]\n",
            "\n",
            "5. Prosodic Features:\n",
            "   f0_mean: 142.0958\n",
            "   f0_std: 67.3784\n",
            "   energy_mean: 0.0243\n",
            "   energy_std: 0.0264\n",
            "   zero_crossing_rate: 0.1436\n",
            "   spectral_centroid: 1989.2703\n",
            "   spectral_rolloff: 4091.9595\n",
            "   duration: 60.3156\n",
            "\n",
            "\n",
            "==================================================\n",
            "Step 2: Extracting transcripts...\n",
            "Extracting transcripts...\n",
            "\n",
            "Processing diagnosis_ad...\n",
            "  Transcribing adrso047.wav...\n",
            "  Transcribing adrso128.wav...\n",
            "  Transcribing adrso110.wav...\n",
            "  Transcribing adrso036.wav...\n",
            "  Transcribing adrso045.wav...\n",
            "  Transcribing adrso093.wav...\n",
            "  Transcribing adrso112.wav...\n",
            "  Transcribing adrso189.wav...\n",
            "  Transcribing adrso089.wav...\n",
            "  Transcribing adrso205.wav...\n",
            "  Transcribing adrso060.wav...\n",
            "  Transcribing adrso232.wav...\n",
            "  Transcribing adrso075.wav...\n",
            "  Transcribing adrso106.wav...\n",
            "  Transcribing adrso063.wav...\n",
            "  Transcribing adrso043.wav...\n",
            "  Transcribing adrso206.wav...\n",
            "  Transcribing adrso126.wav...\n",
            "  Transcribing adrso109.wav...\n",
            "  Transcribing adrso202.wav...\n",
            "  Transcribing adrso071.wav...\n",
            "  Transcribing adrso039.wav...\n",
            "  Transcribing adrso209.wav...\n",
            "  Transcribing adrso228.wav...\n",
            "  Transcribing adrso122.wav...\n",
            "  Transcribing adrso116.wav...\n",
            "  Transcribing adrso244.wav...\n",
            "  Transcribing adrso141.wav...\n",
            "  Transcribing adrso248.wav...\n",
            "  Transcribing adrso130.wav...\n",
            "  Transcribing adrso055.wav...\n",
            "  Transcribing adrso070.wav...\n",
            "  Transcribing adrso222.wav...\n",
            "  Transcribing adrso190.wav...\n",
            "  Transcribing adrso223.wav...\n",
            "  Transcribing adrso215.wav...\n",
            "  Transcribing adrso234.wav...\n",
            "  Transcribing adrso236.wav...\n",
            "  Transcribing adrso059.wav...\n",
            "  Transcribing adrso098.wav...\n",
            "  Transcribing adrso192.wav...\n",
            "  Transcribing adrso090.wav...\n",
            "  Transcribing adrso250.wav...\n",
            "  Transcribing adrso025.wav...\n",
            "  Transcribing adrso224.wav...\n",
            "  Transcribing adrso031.wav...\n",
            "  Transcribing adrso074.wav...\n",
            "  Transcribing adrso211.wav...\n",
            "  Transcribing adrso229.wav...\n",
            "  Transcribing adrso197.wav...\n",
            "  Transcribing adrso049.wav...\n",
            "  Transcribing adrso138.wav...\n",
            "  Transcribing adrso123.wav...\n",
            "  Transcribing adrso072.wav...\n",
            "  Transcribing adrso027.wav...\n",
            "  Transcribing adrso068.wav...\n",
            "  Transcribing adrso187.wav...\n",
            "  Transcribing adrso054.wav...\n",
            "  Transcribing adrso249.wav...\n",
            "  Transcribing adrso200.wav...\n",
            "  Transcribing adrso028.wav...\n",
            "  Transcribing adrso053.wav...\n",
            "  Transcribing adrso078.wav...\n",
            "  Transcribing adrso056.wav...\n",
            "  Transcribing adrso245.wav...\n",
            "  Transcribing adrso092.wav...\n",
            "  Transcribing adrso134.wav...\n",
            "  Transcribing adrso216.wav...\n",
            "  Transcribing adrso142.wav...\n",
            "  Transcribing adrso077.wav...\n",
            "  Transcribing adrso198.wav...\n",
            "  Transcribing adrso220.wav...\n",
            "  Transcribing adrso024.wav...\n",
            "  Transcribing adrso212.wav...\n",
            "  Transcribing adrso046.wav...\n",
            "  Transcribing adrso233.wav...\n",
            "  Transcribing adrso247.wav...\n",
            "  Transcribing adrso035.wav...\n",
            "  Transcribing adrso125.wav...\n",
            "  Transcribing adrso188.wav...\n",
            "  Transcribing adrso033.wav...\n",
            "  Transcribing adrso237.wav...\n",
            "  Transcribing adrso253.wav...\n",
            "  Transcribing adrso218.wav...\n",
            "  Transcribing adrso144.wav...\n",
            "  Transcribing adrso032.wav...\n",
            "  Transcribing adrso246.wav...\n",
            "\n",
            "Processing diagnosis_cn...\n",
            "  Transcribing adrso173.wav...\n",
            "  Transcribing adrso015.wav...\n",
            "  Transcribing adrso307.wav...\n",
            "  Transcribing adrso283.wav...\n",
            "  Transcribing adrso167.wav...\n",
            "  Transcribing adrso168.wav...\n",
            "  Transcribing adrso172.wav...\n",
            "  Transcribing adrso292.wav...\n",
            "  Transcribing adrso316.wav...\n",
            "  Transcribing adrso162.wav...\n",
            "  Transcribing adrso278.wav...\n",
            "  Transcribing adrso296.wav...\n",
            "  Transcribing adrso300.wav...\n",
            "  Transcribing adrso291.wav...\n",
            "  Transcribing adrso169.wav...\n",
            "  Transcribing adrso178.wav...\n",
            "  Transcribing adrso165.wav...\n",
            "  Transcribing adrso177.wav...\n",
            "  Transcribing adrso262.wav...\n",
            "  Transcribing adrso265.wav...\n",
            "  Transcribing adrso014.wav...\n",
            "  Transcribing adrso021.wav...\n",
            "  Transcribing adrso268.wav...\n",
            "  Transcribing adrso261.wav...\n",
            "  Transcribing adrso156.wav...\n",
            "  Transcribing adrso148.wav...\n",
            "  Transcribing adrso016.wav...\n",
            "  Transcribing adrso310.wav...\n",
            "  Transcribing adrso302.wav...\n",
            "  Transcribing adrso308.wav...\n",
            "  Transcribing adrso018.wav...\n",
            "  Transcribing adrso309.wav...\n",
            "  Transcribing adrso298.wav...\n",
            "  Transcribing adrso180.wav...\n",
            "  Transcribing adrso154.wav...\n",
            "  Transcribing adrso273.wav...\n",
            "  Transcribing adrso159.wav...\n",
            "  Transcribing adrso259.wav...\n",
            "  Transcribing adrso151.wav...\n",
            "  Transcribing adrso267.wav...\n",
            "  Transcribing adrso019.wav...\n",
            "  Transcribing adrso153.wav...\n",
            "  Transcribing adrso274.wav...\n",
            "  Transcribing adrso023.wav...\n",
            "  Transcribing adrso012.wav...\n",
            "  Transcribing adrso002.wav...\n",
            "  Transcribing adrso022.wav...\n",
            "  Transcribing adrso266.wav...\n",
            "  Transcribing adrso280.wav...\n",
            "  Transcribing adrso152.wav...\n",
            "  Transcribing adrso007.wav...\n",
            "  Transcribing adrso276.wav...\n",
            "  Transcribing adrso260.wav...\n",
            "  Transcribing adrso017.wav...\n",
            "  Transcribing adrso005.wav...\n",
            "  Transcribing adrso299.wav...\n",
            "  Transcribing adrso157.wav...\n",
            "  Transcribing adrso182.wav...\n",
            "  Transcribing adrso008.wav...\n",
            "  Transcribing adrso161.wav...\n",
            "  Transcribing adrso263.wav...\n",
            "  Transcribing adrso257.wav...\n",
            "  Transcribing adrso164.wav...\n",
            "  Transcribing adrso289.wav...\n",
            "  Transcribing adrso270.wav...\n",
            "  Transcribing adrso264.wav...\n",
            "  Transcribing adrso277.wav...\n",
            "  Transcribing adrso160.wav...\n",
            "  Transcribing adrso186.wav...\n",
            "  Transcribing adrso003.wav...\n",
            "  Transcribing adrso286.wav...\n",
            "  Transcribing adrso285.wav...\n",
            "  Transcribing adrso170.wav...\n",
            "  Transcribing adrso183.wav...\n",
            "  Transcribing adrso281.wav...\n",
            "  Transcribing adrso010.wav...\n",
            "  Transcribing adrso315.wav...\n",
            "  Transcribing adrso312.wav...\n",
            "  Transcribing adrso158.wav...\n",
            "\n",
            "Processing progression_decline...\n",
            "  Transcribing adrsp055.wav...\n",
            "  Transcribing adrsp300.wav...\n",
            "  Transcribing adrsp003.wav...\n",
            "  Transcribing adrsp266.wav...\n",
            "  Transcribing adrsp320.wav...\n",
            "  Transcribing adrsp313.wav...\n",
            "  Transcribing adrsp179.wav...\n",
            "  Transcribing adrsp051.wav...\n",
            "  Transcribing adrsp326.wav...\n",
            "  Transcribing adrsp101.wav...\n",
            "  Transcribing adrsp127.wav...\n",
            "  Transcribing adrsp357.wav...\n",
            "  Transcribing adrsp276.wav...\n",
            "  Transcribing adrsp209.wav...\n",
            "  Transcribing adrsp318.wav...\n",
            "\n",
            "Processing progression_no_decline...\n",
            "  Transcribing adrsp109.wav...\n",
            "  Transcribing adrsp255.wav...\n",
            "  Transcribing adrsp306.wav...\n",
            "  Transcribing adrsp157.wav...\n",
            "  Transcribing adrsp197.wav...\n",
            "  Transcribing adrsp031.wav...\n",
            "  Transcribing adrsp368.wav...\n",
            "  Transcribing adrsp032.wav...\n",
            "  Transcribing adrsp091.wav...\n",
            "  Transcribing adrsp124.wav...\n",
            "  Transcribing adrsp344.wav...\n",
            "  Transcribing adrsp195.wav...\n",
            "  Transcribing adrsp253.wav...\n",
            "  Transcribing adrsp039.wav...\n",
            "  Transcribing adrsp251.wav...\n",
            "  Transcribing adrsp001.wav...\n",
            "  Transcribing adrsp207.wav...\n",
            "  Transcribing adrsp041.wav...\n",
            "  Transcribing adrsp324.wav...\n",
            "  Transcribing adrsp379.wav...\n",
            "  Transcribing adrsp384.wav...\n",
            "  Transcribing adrsp177.wav...\n",
            "  Transcribing adrsp023.wav...\n",
            "  Transcribing adrsp148.wav...\n",
            "  Transcribing adrsp122.wav...\n",
            "  Transcribing adrsp359.wav...\n",
            "  Transcribing adrsp030.wav...\n",
            "  Transcribing adrsp319.wav...\n",
            "  Transcribing adrsp200.wav...\n",
            "  Transcribing adrsp193.wav...\n",
            "  Transcribing adrsp378.wav...\n",
            "  Transcribing adrsp128.wav...\n",
            "  Transcribing adrsp161.wav...\n",
            "  Transcribing adrsp192.wav...\n",
            "  Transcribing adrsp196.wav...\n",
            "  Transcribing adrsp136.wav...\n",
            "  Transcribing adrsp130.wav...\n",
            "  Transcribing adrsp024.wav...\n",
            "  Transcribing adrsp007.wav...\n",
            "  Transcribing adrsp382.wav...\n",
            "  Transcribing adrsp349.wav...\n",
            "  Transcribing adrsp321.wav...\n",
            "  Transcribing adrsp043.wav...\n",
            "  Transcribing adrsp198.wav...\n",
            "  Transcribing adrsp019.wav...\n",
            "  Transcribing adrsp333.wav...\n",
            "  Transcribing adrsp310.wav...\n",
            "  Transcribing adrsp137.wav...\n",
            "  Transcribing adrsp380.wav...\n",
            "  Transcribing adrsp056.wav...\n",
            "  Transcribing adrsp028.wav...\n",
            "  Transcribing adrsp096.wav...\n",
            "  Transcribing adrsp052.wav...\n",
            "  Transcribing adrsp042.wav...\n",
            "  Transcribing adrsp377.wav...\n",
            "  Transcribing adrsp350.wav...\n",
            "  Transcribing adrsp363.wav...\n",
            "  Transcribing adrsp204.wav...\n",
            "\n",
            "Processing progression_test...\n",
            "  Transcribing adrspt15.wav...\n",
            "  Transcribing adrspt20.wav...\n",
            "  Transcribing adrspt4.wav...\n",
            "  Transcribing adrspt27.wav...\n",
            "  Transcribing adrspt16.wav...\n",
            "  Transcribing adrspt28.wav...\n",
            "  Transcribing adrspt9.wav...\n",
            "  Transcribing adrspt10.wav...\n",
            "  Transcribing adrspt26.wav...\n",
            "  Transcribing adrspt13.wav...\n",
            "  Transcribing adrspt31.wav...\n",
            "  Transcribing adrspt23.wav...\n",
            "  Transcribing adrspt14.wav...\n",
            "  Transcribing adrspt12.wav...\n",
            "  Transcribing adrspt32.wav...\n",
            "  Transcribing adrspt6.wav...\n",
            "  Transcribing adrspt1.wav...\n",
            "  Transcribing adrspt21.wav...\n",
            "  Transcribing adrspt30.wav...\n",
            "  Transcribing adrspt29.wav...\n",
            "  Transcribing adrspt8.wav...\n",
            "  Transcribing adrspt3.wav...\n",
            "  Transcribing adrspt19.wav...\n",
            "  Transcribing adrspt18.wav...\n",
            "  Transcribing adrspt24.wav...\n",
            "  Transcribing adrspt2.wav...\n",
            "  Transcribing adrspt25.wav...\n",
            "  Transcribing adrspt17.wav...\n",
            "  Transcribing adrspt11.wav...\n",
            "  Transcribing adrspt22.wav...\n",
            "  Transcribing adrspt7.wav...\n",
            "  Transcribing adrspt5.wav...\n",
            "\n",
            "==================================================\n",
            "Step 3: Saving transcripts...\n",
            "Transcripts saved to /content/transcripts/\n",
            "\n",
            "==================================================\n",
            "Step 4: Creating transcript table...\n",
            "Transcript Summary Table:\n",
            "                            File_ID               Category     Filename  Transcript_Length  Word_Count Language  Segments  Has_Error                                                                                      Transcript_Preview\n",
            "          diagnosis_ad_adrso047.wav           diagnosis_ad adrso047.wav                578          98       en        19      False She was watching this lady right here. She was watching this lady. This man here, he's trying to put...\n",
            "          diagnosis_ad_adrso128.wav           diagnosis_ad adrso128.wav                349          65       en        13      False I just want you to tell me everything that you see happening in that picture. Everything is going on...\n",
            "          diagnosis_ad_adrso110.wav           diagnosis_ad adrso110.wav                623         118       en        12      False Okay, can you tell me everything you see going on in the picture? Over here, standing on the chair, ...\n",
            "          diagnosis_ad_adrso036.wav           diagnosis_ad adrso036.wav                266          54       en         8      False Tell me what's going on all the action what's going on in this picture? Oh the boy is up I And the w...\n",
            "          diagnosis_ad_adrso045.wav           diagnosis_ad adrso045.wav               2157         434       en        48      False This picture and tell me everything that you see going on in that picture. What's happening there? T...\n",
            "          diagnosis_ad_adrso093.wav           diagnosis_ad adrso093.wav                837         165       en        21      False I tell me what's going on in that picture. This little girl is talking to this boy up on this tipper...\n",
            "          diagnosis_ad_adrso112.wav           diagnosis_ad adrso112.wav                523          96       en        16      False Okay, so he's going on in the picture. Ha ha ha. Boys, we've been cooking jaw to take the stools fal...\n",
            "          diagnosis_ad_adrso189.wav           diagnosis_ad adrso189.wav                565         114       en        12      False There it is. Thanks for the light. Yeah. Can I look at it and tell you? Just tell me as you see it d...\n",
            "          diagnosis_ad_adrso089.wav           diagnosis_ad adrso089.wav                591         119       en        11      False Well, they're stealing on the cookies and the little girl is going to take in one tour. He's going t...\n",
            "          diagnosis_ad_adrso205.wav           diagnosis_ad adrso205.wav                647         126       en        22      False The little boys up on this thing here and it's bees up trying to get something out of a garden selec...\n",
            "          diagnosis_ad_adrso060.wav           diagnosis_ad adrso060.wav                329          67       en        13      False This is a side cooking, honey. You just come in and you can do more of this. Oh, cooking your arm. T...\n",
            "          diagnosis_ad_adrso232.wav           diagnosis_ad adrso232.wav                582         114       en        14      False I'd like for you to take a look at this picture. I'd like for you to tell me everything that you see...\n",
            "          diagnosis_ad_adrso075.wav           diagnosis_ad adrso075.wav                410          74       en        12      False I'm going to be going on in a picture. The waters running over the sink. She's ignoring it and the k...\n",
            "          diagnosis_ad_adrso106.wav           diagnosis_ad adrso106.wav                694         145       en        12      False What's going on in the picture? The water is running out of a sink and all of this. The little boy i...\n",
            "          diagnosis_ad_adrso063.wav           diagnosis_ad adrso063.wav                247          47       en        10      False Can you see the picture here? Tell me what's going on. What happened there? Just tell me what we've ...\n",
            "          diagnosis_ad_adrso043.wav           diagnosis_ad adrso043.wav                524          98       en        42      False Have a look at that picture and tell me everything that you see going on in that picture, all the ac...\n",
            "          diagnosis_ad_adrso206.wav           diagnosis_ad adrso206.wav                627         123       en        18      False Just tell me everything that you see happening in the picture. Hi. A little girl in the little boy i...\n",
            "          diagnosis_ad_adrso126.wav           diagnosis_ad adrso126.wav                501          94       en        16      False Just to take a look at this picture and tell me everything that you see going along in the picture. ...\n",
            "          diagnosis_ad_adrso109.wav           diagnosis_ad adrso109.wav                819         157       en        19      False Take a look at that picture. Take a look at that picture and tell me everything that you see happeni...\n",
            "          diagnosis_ad_adrso202.wav           diagnosis_ad adrso202.wav                643         128       en        23      False Here's the picture. All of the act. Start the other is grinders. And the sink is overflowing. One mo...\n",
            "          diagnosis_ad_adrso071.wav           diagnosis_ad adrso071.wav                465          87       en         7      False Well, the guy was getting in the cookie jar and standing on the stool, that was falling over and his...\n",
            "          diagnosis_ad_adrso039.wav           diagnosis_ad adrso039.wav                259          53       en        11      False I can take a table of the same spot. This thing is running over. I can also make you for a cooking. ...\n",
            "          diagnosis_ad_adrso209.wav           diagnosis_ad adrso209.wav                641         124       en        17      False Tell me all the action going on in that picture. Can you tell me the action that you see going on in...\n",
            "          diagnosis_ad_adrso228.wav           diagnosis_ad adrso228.wav                459          83       en        12      False Tell me. Just start out anywhere. Where every life. A little girl. Falling stool. A young lad that's...\n",
            "          diagnosis_ad_adrso122.wav           diagnosis_ad adrso122.wav                444          82       en        15      False What we need to do is take a good look at this picture. And tell me everything that you see going on...\n",
            "          diagnosis_ad_adrso116.wav           diagnosis_ad adrso116.wav                748         147       en        19      False Now I'm going to give you a picture that has a lot of things going on in it. I want you to tell me e...\n",
            "          diagnosis_ad_adrso244.wav           diagnosis_ad adrso244.wav                566         106       en        30      False I think you see going on in that picture. Well, start from the... The... The... The... The... How ca...\n",
            "          diagnosis_ad_adrso141.wav           diagnosis_ad adrso141.wav                272          49       en         6      False You want me to tell you? Okay, the boy's getting in the cookie jar. His sister's waiting for cookies...\n",
            "          diagnosis_ad_adrso248.wav           diagnosis_ad adrso248.wav                361          68       en         7      False The girl's washing dishes, the water is spilling over onto the floor. The boy is taking some cookies...\n",
            "          diagnosis_ad_adrso130.wav           diagnosis_ad adrso130.wav                353          66       en         7      False picture that has a lot of action going on. There's a lot of things going on in the picture. Tell me ...\n",
            "          diagnosis_ad_adrso055.wav           diagnosis_ad adrso055.wav                608         122       en        16      False What do you see going on in that picture? Oh yeah, kids climbing up on the stone, reaching up in the...\n",
            "          diagnosis_ad_adrso070.wav           diagnosis_ad adrso070.wav                521          98       en        24      False What do you see happening in that picture? Oh, water fell off the sink. Little boy fell off his... W...\n",
            "          diagnosis_ad_adrso222.wav           diagnosis_ad adrso222.wav                600         124       en        15      False All the action you see going on in the picture. Now I think I had it within the kitchen and I was th...\n",
            "          diagnosis_ad_adrso190.wav           diagnosis_ad adrso190.wav               1193         228       en        24      False Here's the patient. Oh boy. We always went up on a cookie jar to get cookie and then he's falling of...\n",
            "          diagnosis_ad_adrso223.wav           diagnosis_ad adrso223.wav                884         157       en        31      False Okay, and I want you to tell me everything that you see going on in that picture. Just tell me every...\n",
            "          diagnosis_ad_adrso215.wav           diagnosis_ad adrso215.wav                480          92       en        17      False I want you to tell me everything that you see going on in the picture. Tell me everything that you s...\n",
            "          diagnosis_ad_adrso234.wav           diagnosis_ad adrso234.wav                503         107       en        12      False What action do you see going on in that picture? I see another washing dishes, I see the water blowi...\n",
            "          diagnosis_ad_adrso236.wav           diagnosis_ad adrso236.wav                325          64       en         7      False Okay, the picture. All you see going on in the picture. All right. Do you tell me? Oh, the boys in t...\n",
            "          diagnosis_ad_adrso059.wav           diagnosis_ad adrso059.wav                361          70       en         4      False in the picture. Oh, oh, oh, well, kind of climatic isn't it? The mother just is, I assume this is th...\n",
            "          diagnosis_ad_adrso098.wav           diagnosis_ad adrso098.wav                840         168       en        27      False I want you to tell me everything that's happening in that picture. I want you to tell me everything'...\n",
            "          diagnosis_ad_adrso192.wav           diagnosis_ad adrso192.wav                624         127       en        10      False You see a guy going on here. Just look at this picture and tell me what you see. Well, well, you see...\n",
            "          diagnosis_ad_adrso090.wav           diagnosis_ad adrso090.wav                390          78       en        17      False I'm on a wheelchair. What? A boy? He's a cookie jar. He has a cookie in his hand. He's like, oh! He'...\n",
            "          diagnosis_ad_adrso250.wav           diagnosis_ad adrso250.wav                791         155       en        20      False What do you mean, the picture? Here's the picture. Tell me everything you see going on in that pictu...\n",
            "          diagnosis_ad_adrso025.wav           diagnosis_ad adrso025.wav               1030         200       en        37      False Tell me everything that's going on. I guess we're going to go on our... Corner. We're great. I think...\n",
            "          diagnosis_ad_adrso224.wav           diagnosis_ad adrso224.wav                659         138       en        15      False in the picture. Cookie jar. And two children. One, the boys up on a stool and a little girl standing...\n",
            "          diagnosis_ad_adrso031.wav           diagnosis_ad adrso031.wav                552         114       en        14      False Where do you see going on? The board is on the ladder and the ladder is to toe and not a ladder to s...\n",
            "          diagnosis_ad_adrso074.wav           diagnosis_ad adrso074.wav                539         110       en        14      False I see two kids up at the roof of the Jart 1 on the stool, out of standing on the floor. The cover do...\n",
            "          diagnosis_ad_adrso211.wav           diagnosis_ad adrso211.wav                819         167       en        18      False Look at that picture and tell me what you see a lot. An average home that looks very much like ours ...\n",
            "          diagnosis_ad_adrso229.wav           diagnosis_ad adrso229.wav               1042         201       en        38      False Okay, let's try something different, okay? Tell me what you see in that picture. Oh, the cookie jar....\n",
            "          diagnosis_ad_adrso197.wav           diagnosis_ad adrso197.wav                308          58       en        16      False got 51 written used isn't RAW Let's see. Oh! Oh, that's his feet. I think there's something running ...\n",
            "          diagnosis_ad_adrso049.wav           diagnosis_ad adrso049.wav                990         202       en        24      False And there's the picture all the action that you can see The little boy's having up in some cook cook...\n",
            "          diagnosis_ad_adrso138.wav           diagnosis_ad adrso138.wav                579         114       en        16      False Sure. And tell me everything that you see happening in that picture, everything that's going on in t...\n",
            "          diagnosis_ad_adrso123.wav           diagnosis_ad adrso123.wav                414          76       en        11      False Look at this picture. Tell me everything that you see going on in this picture. Everything that you ...\n",
            "          diagnosis_ad_adrso072.wav           diagnosis_ad adrso072.wav                589         113       en        18      False Tell me what's going on. Well, the kids are taking cookies out of the cookie jar. The other ones are...\n",
            "          diagnosis_ad_adrso027.wav           diagnosis_ad adrso027.wav                468          88       en        13      False Nice depiction. That's a little girl and a little boy standing on top of a stool and it looks like a...\n",
            "          diagnosis_ad_adrso068.wav           diagnosis_ad adrso068.wav                388          70       en        16      False Well, the kid has been falling off the stool. Yeah, these... And the mother's washing dishes, drying...\n",
            "          diagnosis_ad_adrso187.wav           diagnosis_ad adrso187.wav                716         143       en        20      False You see going on in the picture. Tell me all the action. Mm-hmm. Okay. There's a young boy going in ...\n",
            "          diagnosis_ad_adrso054.wav           diagnosis_ad adrso054.wav                787         156       en        29      False What's happening in that picture? What's happening there? Okay What else is going on I don't know if...\n",
            "          diagnosis_ad_adrso249.wav           diagnosis_ad adrso249.wav                462          88       en        14      False Okay. There, she's washing the dishes and there the kids are trying to get cookies out of the cookie...\n",
            "          diagnosis_ad_adrso200.wav           diagnosis_ad adrso200.wav               1187         241       en        42      False I'm going to look at the picture and tell me everything that you see going on in that picture. Tell ...\n",
            "          diagnosis_ad_adrso028.wav           diagnosis_ad adrso028.wav                438          88       en        16      False How she will find her mother who wishes to try the dishes. These tools are set. She's a bit long-giv...\n",
            "          diagnosis_ad_adrso053.wav           diagnosis_ad adrso053.wav               1077         214       en        30      False And there it is. Chair is tilting. Let us off of the cookie jar. Cooking another left arm of the boy...\n",
            "          diagnosis_ad_adrso078.wav           diagnosis_ad adrso078.wav                601         112       en        28      False I'm going to take a shower. Okay. Oh, my God. She's... And still in the water from... from washing t...\n",
            "          diagnosis_ad_adrso056.wav           diagnosis_ad adrso056.wav               1718         335       en        61      False Just tell me what's happening in the picture. We're on our arms, get a grip of the foot. See what I'...\n",
            "          diagnosis_ad_adrso245.wav           diagnosis_ad adrso245.wav                509         104       en        10      False I'm on in that picture. I'm very kind of not on the scene yet but so I was watching clothes I mean w...\n",
            "          diagnosis_ad_adrso092.wav           diagnosis_ad adrso092.wav                490          96       en        12      False I want you to take a look at that picture. Oh boy. I want you to tell me everything you see happenin...\n",
            "          diagnosis_ad_adrso134.wav           diagnosis_ad adrso134.wav                304          57       en         7      False Why don't you take a look at this picture? Tell me everything you see happening that picture everyth...\n",
            "          diagnosis_ad_adrso216.wav           diagnosis_ad adrso216.wav                395          72       en        15      False Oh, good. I want you to look at that picture. Then tell me everything that you see happening in the ...\n",
            "          diagnosis_ad_adrso142.wav           diagnosis_ad adrso142.wav                354          66       en         8      False What's happening in that picture? What do you see going on in there? Oh, here's the child reaching o...\n",
            "          diagnosis_ad_adrso077.wav           diagnosis_ad adrso077.wav                365          72       en        10      False You may like that woman doing the dishes and you know water running out in the sink, little blanket ...\n",
            "          diagnosis_ad_adrso198.wav           diagnosis_ad adrso198.wav                464          80       en        18      False What's going on in the picture? What do you see happening in that picture? I'm lazy. I'm lazy and I'...\n",
            "          diagnosis_ad_adrso220.wav           diagnosis_ad adrso220.wav                563         111       en        27      False Tell me all the action that you can see. Action. What's going on in the picture? It's a kid. I'm loo...\n",
            "          diagnosis_ad_adrso024.wav           diagnosis_ad adrso024.wav               1125         225       en        31      False There's a cookie jar and the lid that is off the cookie jar. The boy is about to turn down the floor...\n",
            "          diagnosis_ad_adrso212.wav           diagnosis_ad adrso212.wav                579         117       en        21      False And here's the picture. The boy is taking cookies I'm getting to the ground. Those places put in my ...\n",
            "          diagnosis_ad_adrso046.wav           diagnosis_ad adrso046.wav                744         157       en        30      False But it's not real clear so do what you can with it. You see anything going on? Yeah, I see the woman...\n",
            "          diagnosis_ad_adrso233.wav           diagnosis_ad adrso233.wav                763         142       en        26      False And here's the picture. It's still turning over. She's gonna try to steal cookies out of the cookie ...\n",
            "          diagnosis_ad_adrso247.wav           diagnosis_ad adrso247.wav                698         135       en        23      False Oh, oh, oh, oh. No, boys, they're getting in the cookies. He's climbing up a chair and it's about fa...\n",
            "          diagnosis_ad_adrso035.wav           diagnosis_ad adrso035.wav                631         123       en        15      False Okay, here's the picture. Tell me how I'm going to tell you what's going on in the picture. Oh boy. ...\n",
            "          diagnosis_ad_adrso125.wav           diagnosis_ad adrso125.wav                571         108       en        22      False Take a look at this picture. Just tell me what you see going on in that picture. Tell me everything ...\n",
            "          diagnosis_ad_adrso188.wav           diagnosis_ad adrso188.wav                358          66       en        10      False This is the picture. Just tell me what I'm doing in the picture. The boy is slipping off the stool. ...\n",
            "          diagnosis_ad_adrso033.wav           diagnosis_ad adrso033.wav                570         113       en        26      False What's going on in the picture? In here? This way? Mm-hmm. I'm gonna don't know, because I have gott...\n",
            "          diagnosis_ad_adrso237.wav           diagnosis_ad adrso237.wav                498          96       en        11      False Now, everything that you see going on in that picture. Oh, the ladies drying their dishes. They had ...\n",
            "          diagnosis_ad_adrso253.wav           diagnosis_ad adrso253.wav                504         103       en        11      False Well, my boy is trying to get some cookies. And the girls hold her hand up because he has gotten one...\n",
            "          diagnosis_ad_adrso218.wav           diagnosis_ad adrso218.wav                382          74       en        11      False I wanted to tell me everything that you see going on in that picture. Just tell me everything that y...\n",
            "          diagnosis_ad_adrso144.wav           diagnosis_ad adrso144.wav                586         114       en        18      False Sure. Can you tell me now? Well, this one is in the cookie jar. And this is, she tried to climb the,...\n",
            "          diagnosis_ad_adrso032.wav           diagnosis_ad adrso032.wav                956         191       en        22      False What's going on in the kitchen? Well, the children are planning up and he's about to go out and get ...\n",
            "          diagnosis_ad_adrso246.wav           diagnosis_ad adrso246.wav                424          86       en        14      False Tell me what you see going on the picture. Well, the boy is in the cookie jar and the dog and his si...\n",
            "          diagnosis_cn_adrso173.wav           diagnosis_cn adrso173.wav                757         147       en        18      False And one of what you do is take a look at this picture and tell me everything that you see happening ...\n",
            "          diagnosis_cn_adrso015.wav           diagnosis_cn adrso015.wav                793         150       en        16      False Okay. I'm going to show you some pictures. Okay? Here's a picture. Tell me everything that you see g...\n",
            "          diagnosis_cn_adrso307.wav           diagnosis_cn adrso307.wav                912         179       en        29      False down in the picture. The boys, the girls make a fun of the boys. You may find them so much while he ...\n",
            "          diagnosis_cn_adrso283.wav           diagnosis_cn adrso283.wav                657         124       en        14      False There's a picture. Doesn't matter where you start, you know. Alright, there's a little boy on a step...\n",
            "          diagnosis_cn_adrso167.wav           diagnosis_cn adrso167.wav                874         174       en        10      False I'd like you to do is just look at the picture and tell me anything at all that you see going on. Ch...\n",
            "          diagnosis_cn_adrso168.wav           diagnosis_cn adrso168.wav                722         141       en        15      False Tell me everything that you see happening with that creature. Everything you see going on. Alright, ...\n",
            "          diagnosis_cn_adrso172.wav           diagnosis_cn adrso172.wav                710         132       en        17      False Good, and here's the picture. First of all, the sink is over-floating. Another is washing dishes or ...\n",
            "          diagnosis_cn_adrso292.wav           diagnosis_cn adrso292.wav                280          53       en        10      False Now let's sit. Joven and Dan Cookies. School's going to fall. The sink is overflowing. Another's was...\n",
            "          diagnosis_cn_adrso316.wav           diagnosis_cn adrso316.wav                562         107       en        10      False Sir, I'd like to tell you everything that you see going on in the picture. And that's the picture. A...\n",
            "          diagnosis_cn_adrso162.wav           diagnosis_cn adrso162.wav                710         131       en        23      False Okay, here's the picture. Okay, mother is drying the dishes, but the water is flowing out over the s...\n",
            "          diagnosis_cn_adrso278.wav           diagnosis_cn adrso278.wav                302          55       en         7      False Any action or anything you see? Oh, well, the same server flowing, the lady's washing dishes. The bo...\n",
            "          diagnosis_cn_adrso296.wav           diagnosis_cn adrso296.wav                860         161       en        22      False Ah, the sinks running over. Water's coming all over the floor. Here, the boy, the step ladders, turn...\n",
            "          diagnosis_cn_adrso300.wav           diagnosis_cn adrso300.wav                336          70       en         9      False I'm doing a child each and for a cookie. It's your third. You're all off the way moving there. I'm g...\n",
            "          diagnosis_cn_adrso291.wav           diagnosis_cn adrso291.wav               1020         209       en        17      False What I'd like you to do here is take a look at this picture and tell me everything that you see happ...\n",
            "          diagnosis_cn_adrso169.wav           diagnosis_cn adrso169.wav                282          50       en        10      False There's a kid stealing cookies from the cookie jar. Stools about to topple over. The sisters asking ...\n",
            "          diagnosis_cn_adrso178.wav           diagnosis_cn adrso178.wav                536         102       en        17      False But I want you to do to look at this picture and tell me everything that you see going all the way. ...\n",
            "          diagnosis_cn_adrso165.wav           diagnosis_cn adrso165.wav                447          86       en         9      False in the texture. They're all reaching out. The boy is taking cookies out of the cookie jar. The stool...\n",
            "          diagnosis_cn_adrso177.wav           diagnosis_cn adrso177.wav                691         132       en        16      False I want you to tell me everything that you see going on in this picture. Everything that you see happ...\n",
            "          diagnosis_cn_adrso262.wav           diagnosis_cn adrso262.wav                376          75       en         8      False Okay, you can start then. Okay, the mother is wiping a dish at the sink. The water is overflowing fr...\n",
            "          diagnosis_cn_adrso265.wav           diagnosis_cn adrso265.wav               1380         269       en        43      False Let me just look at the picture and tell her to make galore. Okay? This is going to be like looking ...\n",
            "          diagnosis_cn_adrso014.wav           diagnosis_cn adrso014.wav                697         134       en        16      False I see a woman who has zoned out. She's in the world of her own, obviously. She's not aware of what's...\n",
            "          diagnosis_cn_adrso021.wav           diagnosis_cn adrso021.wav                906         164       en        22      False Everything you see going on in this picture. Ground safety hazards as it referred to as a military. ...\n",
            "          diagnosis_cn_adrso268.wav           diagnosis_cn adrso268.wav                753         150       en        13      False Alright, the action I see is a little girl with her finger up to her mouth and one arm is thened up ...\n",
            "          diagnosis_cn_adrso261.wav           diagnosis_cn adrso261.wav                515         102       en        10      False A boy, a puppy in his one hand in the sand in the cookie jar, standing on a stool which is tipping o...\n",
            "          diagnosis_cn_adrso156.wav           diagnosis_cn adrso156.wav                525         101       en        13      False Just everything that you see happening. Oh, wow. Well, the money must be daydreaming because the wat...\n",
            "          diagnosis_cn_adrso148.wav           diagnosis_cn adrso148.wav               1330         259       en        36      False I wish you make us laugh. Are you ready? Well, the sink is overflowing. Let it was standing in the w...\n",
            "          diagnosis_cn_adrso016.wav           diagnosis_cn adrso016.wav                420          81       en        13      False Hmm, what a fall. Um, and safety problems. So this boy is getting cookies from a cookie jar and to t...\n",
            "          diagnosis_cn_adrso310.wav           diagnosis_cn adrso310.wav                542         107       en        18      False I just want you to tell me what you see going on in that picture. The water is running over. The ste...\n",
            "          diagnosis_cn_adrso302.wav           diagnosis_cn adrso302.wav                948         191       en        21      False We'll start with the girl she's Pointed we see will cookie her brothers her brothers taking cookies ...\n",
            "          diagnosis_cn_adrso308.wav           diagnosis_cn adrso308.wav                504         100       en        11      False It's a kitchen scene and the mother is doing the dishes. The children are trying to get into the coo...\n",
            "          diagnosis_cn_adrso018.wav           diagnosis_cn adrso018.wav                708         148       en        14      False Just look at this one and tell me everything you see going on Oh, mom Mommy having a good day She th...\n",
            "          diagnosis_cn_adrso309.wav           diagnosis_cn adrso309.wav                599         112       en        10      False I mean, picture. Tell me everything is going on in there. Mother is drying the dishes, looking out t...\n",
            "          diagnosis_cn_adrso298.wav           diagnosis_cn adrso298.wav                481          93       en        13      False A little girl is reaching for her brother to give her a cookie. The stool is falling over. The boy h...\n",
            "          diagnosis_cn_adrso180.wav           diagnosis_cn adrso180.wav                620         117       en         7      False Tell me everything you see happening in that picture. Everything that's going on there. I mean right...\n",
            "          diagnosis_cn_adrso154.wav           diagnosis_cn adrso154.wav                356          66       en        10      False That's the picture. Boy is taking cookies from the cookie jar, giving one to his sister, also fallin...\n",
            "          diagnosis_cn_adrso273.wav           diagnosis_cn adrso273.wav                520         102       en         9      False There's the two children are in the process of stealing cookies from the cookie jar. And the little ...\n",
            "          diagnosis_cn_adrso159.wav           diagnosis_cn adrso159.wav                350          68       en         9      False So, the action that you see going on in that picture. Anything that I want. Okay, the boys reaching ...\n",
            "          diagnosis_cn_adrso259.wav           diagnosis_cn adrso259.wav                965         179       en        22      False Okay. Okay. Many, all right. The mother is washing the dishes and the sink is overflowing. She has s...\n",
            "          diagnosis_cn_adrso151.wav           diagnosis_cn adrso151.wav                351          65       en         8      False Okay, here's the picture. All of the action you see going on. Boy, taking cookies out of the cookie ...\n",
            "          diagnosis_cn_adrso267.wav           diagnosis_cn adrso267.wav                460          87       en        10      False going on in the picture. Okay there it is. Yes, kind of. Kids are taking cookies from the cookie jar...\n",
            "          diagnosis_cn_adrso019.wav           diagnosis_cn adrso019.wav                708         139       en        10      False Okay little boy is on a stool that he looks like he's going to fall. He's going to the cookie jar an...\n",
            "          diagnosis_cn_adrso153.wav           diagnosis_cn adrso153.wav                419          70       en        26      False Start whenever you want. Cooked jar, a land standing on a stool, tearing, having other cookies. Sist...\n",
            "          diagnosis_cn_adrso274.wav           diagnosis_cn adrso274.wav               1458         294       en        34      False Alright, the boy is taking a cookie out of the cookie jar. He has one of his left hand to reach down...\n",
            "          diagnosis_cn_adrso023.wav           diagnosis_cn adrso023.wav                572         107       en        18      False Tell me everything you see going on in this picture. This one? Yes, ma'am. Oh, a little boy, six and...\n",
            "          diagnosis_cn_adrso012.wav           diagnosis_cn adrso012.wav                673         134       en        13      False Well, I see a kitchen and a housewife or a homemaker at the sink and her two kids are having a great...\n",
            "          diagnosis_cn_adrso002.wav           diagnosis_cn adrso002.wav                884         172       en        15      False Okay, I see a mom doing the dishes and the water's overflowing from the sink and she seems to be com...\n",
            "          diagnosis_cn_adrso022.wav           diagnosis_cn adrso022.wav                505          95       en         7      False And then here on this one, tell me everything you see going on in this picture. Well, I see the moth...\n",
            "          diagnosis_cn_adrso266.wav           diagnosis_cn adrso266.wav                463          87       en        17      False Tell me everything is the hand. I don't know. The girl was watching the boy going to the cookin' jar...\n",
            "          diagnosis_cn_adrso280.wav           diagnosis_cn adrso280.wav                844         163       en        20      False There's the picture. This little boy has a cookie jar. He has got no one on his stool, which is tipp...\n",
            "          diagnosis_cn_adrso152.wav           diagnosis_cn adrso152.wav                654         129       en        15      False Hello boys on the stool which is tipping over and he's getting into the cooking jar which is up in c...\n",
            "          diagnosis_cn_adrso007.wav           diagnosis_cn adrso007.wav                334          63       en         5      False A mother standing by the sink, kind of looks like lost and thought, wiping a dish. The sink is overf...\n",
            "          diagnosis_cn_adrso276.wav           diagnosis_cn adrso276.wav               2523         492       en        41      False Oh, it's the same picture. It should give you a different one. They're afraid too. Why? It could be ...\n",
            "          diagnosis_cn_adrso260.wav           diagnosis_cn adrso260.wav                498         100       en        17      False And you can begin right there. Well, the little boy is on a step stool trying to reach the cookie ja...\n",
            "          diagnosis_cn_adrso017.wav           diagnosis_cn adrso017.wav                876         175       en        23      False All right, we have a few more tasks to go through before we break for today. Okay. So, here's a pict...\n",
            "          diagnosis_cn_adrso005.wav           diagnosis_cn adrso005.wav                740         139       en        15      False Oh my, I'm such a mess that I think is overflowing. And I don't know why she's not even carrying. Sh...\n",
            "          diagnosis_cn_adrso299.wav           diagnosis_cn adrso299.wav                860         152       en        22      False Why don't you take a look at this picture? And I want you to tell me everything that's happening the...\n",
            "          diagnosis_cn_adrso157.wav           diagnosis_cn adrso157.wav                660         127       en        14      False Okay, and there's the picture. Oh, yes. Just go ahead and tell you. You just say the mother is dryin...\n",
            "          diagnosis_cn_adrso182.wav           diagnosis_cn adrso182.wav                621         119       en        11      False I'd like for you to take a look at this picture and tell me everything that you see happening in the...\n",
            "          diagnosis_cn_adrso008.wav           diagnosis_cn adrso008.wav                708         137       en        10      False Well, I see what seems to be a mother or could be a babysitter with two children, a boy and a girl. ...\n",
            "          diagnosis_cn_adrso161.wav           diagnosis_cn adrso161.wav                421          76       en         8      False Well, this little boy is up on his stool, taking cookies, handing him down to the sister, and she's ...\n",
            "          diagnosis_cn_adrso263.wav           diagnosis_cn adrso263.wav                503          88       en        20      False Okay, there's the fixer. Everything is there. You can miss house or whatever. Yeah. Uh-huh. You want...\n",
            "          diagnosis_cn_adrso257.wav           diagnosis_cn adrso257.wav                575         119       en        12      False Just look at the picture and tell me everything that you see. I'm going to get a copy of the cookie ...\n",
            "          diagnosis_cn_adrso164.wav           diagnosis_cn adrso164.wav                924         176       en        21      False What do you see going on? I see a little boy on the school and he's just falling over taking cookie-...\n",
            "          diagnosis_cn_adrso289.wav           diagnosis_cn adrso289.wav                578         103       en        28      False And that's the picture. Climbing, dishwasher, washing, pointing, stealing cookies, wind is blowing o...\n",
            "          diagnosis_cn_adrso270.wav           diagnosis_cn adrso270.wav                601         115       en        17      False The mother's arm trying to dish and the water's running over. And then the boy is taking cookies out...\n",
            "          diagnosis_cn_adrso264.wav           diagnosis_cn adrso264.wav                539          99       en        16      False And there's the picture. So yeah. Do I get to describe that everything? Yeah, I tell you that. Yeah,...\n",
            "          diagnosis_cn_adrso277.wav           diagnosis_cn adrso277.wav                568         118       en        21      False Don't do so in your research. They have a lot of action going on. What I need you to do is tell me a...\n",
            "          diagnosis_cn_adrso160.wav           diagnosis_cn adrso160.wav                417          80       en        12      False The first thing we're going to do is take a look at that picture and tell me everything you see happ...\n",
            "          diagnosis_cn_adrso186.wav           diagnosis_cn adrso186.wav                490          95       en        12      False Tell me everything you see happening in the bath pressure. Everything is going on there. Okay. On th...\n",
            "          diagnosis_cn_adrso003.wav           diagnosis_cn adrso003.wav                428          81       en         5      False Starting from the left, I see two children standing on a tipping stool, reaching for the cookie jar....\n",
            "          diagnosis_cn_adrso286.wav           diagnosis_cn adrso286.wav                685         129       en        19      False Tell me everything that you see going on in the picture. Just tell me what's happening there. Well, ...\n",
            "          diagnosis_cn_adrso285.wav           diagnosis_cn adrso285.wav                259          38       en         5      False Touching lip, raising arm, zappetune, the end time for cookie, handing cookie down, slipping from st...\n",
            "          diagnosis_cn_adrso170.wav           diagnosis_cn adrso170.wav                519         102       en        10      False I'll just take a lot of this picture and tell me everything you see is going on. Okay, the boy is st...\n",
            "          diagnosis_cn_adrso183.wav           diagnosis_cn adrso183.wav                822         156       en        22      False What should you tell me, everything you see happening in that picture? Everything that's going on th...\n",
            "          diagnosis_cn_adrso281.wav           diagnosis_cn adrso281.wav                665         135       en        19      False There's a cookie jar on the shelf. The old boy's up on a store and the store is about to fall. He's ...\n",
            "          diagnosis_cn_adrso010.wav           diagnosis_cn adrso010.wav                232          42       en         5      False Well, let's see, our mama appears to be busy doing the dishes. Wow, she's had a problem. The sink is...\n",
            "          diagnosis_cn_adrso315.wav           diagnosis_cn adrso315.wav                490          95       en        11      False Just the action. The girl is reaching for a cookie that the boy is trying to get water while he's Th...\n",
            "          diagnosis_cn_adrso312.wav           diagnosis_cn adrso312.wav                684         135       en        20      False What do you see going on in that picture? Oh, I see the sink that's running over. I see the stores t...\n",
            "          diagnosis_cn_adrso158.wav           diagnosis_cn adrso158.wav                574         114       en        14      False So now, yeah. The boy reaching on his own stool, reaching for cookies, and the stool is ready to fol...\n",
            "   progression_decline_adrsp055.wav    progression_decline adrsp055.wav                381          71       en        26      False Okay, I'll take how with the deer, the cat, a dog. That awful. A lion, tiger. A mouse count. Yes. Ye...\n",
            "   progression_decline_adrsp300.wav    progression_decline adrsp300.wav               1293         272       en        26      False And what I want you to do for me is in one minute's time I want you to name as many animals as you c...\n",
            "   progression_decline_adrsp003.wav    progression_decline adrsp003.wav                385          73       en        19      False Spine. Okay, thank you very much for me. Many animals as you can in one minute. Starting now. Just n...\n",
            "   progression_decline_adrsp266.wav    progression_decline adrsp266.wav                982         199       en        46      False You can start now. How's Figs? Chickens? She. I can't even think. You want me animals you can think ...\n",
            "   progression_decline_adrsp320.wav    progression_decline adrsp320.wav                894         158       en        46      False All the animals are Canadian in there. Ready? Go ahead. Camp, dog, drew, ranch, elephant, rhinoceros...\n",
            "   progression_decline_adrsp313.wav    progression_decline adrsp313.wav                681         133       en        38      False And you can start now. Just name them. Well, I can't. Okay. Dog. I think it's a neighbor's what they...\n",
            "   progression_decline_adrsp179.wav    progression_decline adrsp179.wav               1433         302       en        45      False I want you to try and tell me all the animals that you can think of. Or you just think of all the an...\n",
            "   progression_decline_adrsp051.wav    progression_decline adrsp051.wav                216          48       en        12      False Okay, and you can begin now. All of the ingredients. I bought one for you. Can I have three birds? O...\n",
            "   progression_decline_adrsp326.wav    progression_decline adrsp326.wav                522         110       en        19      False Can you name some animals for me? Any animal at all? Can you name some animals? Think of some animal...\n",
            "   progression_decline_adrsp101.wav    progression_decline adrsp101.wav                593         123       en        22      False Another meal. Again? Well now. Got some cat, skinny, um... forces of... New conges. Yeah, um... That...\n",
            "   progression_decline_adrsp127.wav    progression_decline adrsp127.wav                421          79       en        26      False Good, animals and you can begin now. That, okay. A goat, a horse, a dove. A bike. Okay, there's some...\n",
            "   progression_decline_adrsp357.wav    progression_decline adrsp357.wav               1286         245       en        68      False In one minute's time, and in that minute, I want to create a name as many animals as you can think o...\n",
            "   progression_decline_adrsp276.wav    progression_decline adrsp276.wav                983         209       en        37      False We're going to ask you if you want to see how many animals you can name for me in one minute. I'll t...\n",
            "   progression_decline_adrsp209.wav    progression_decline adrsp209.wav                386          73       en        36      False Where did you first meet? Oh, horse decay, okay. Rhino-stress elephant, monkey, bear, a deer, sheep,...\n",
            "   progression_decline_adrsp318.wav    progression_decline adrsp318.wav               1521         291       en        57      False Ready? I don't have anything to write. Just say it. Oh, say it. Okay. Okay. Cat dog horse. These... ...\n",
            "progression_no_decline_adrsp109.wav progression_no_decline adrsp109.wav                629         126       en        21      False Okay, one minute and you can begin now件 Okay, go ahead. Okay, now I'm going to ask you to think of a...\n",
            "progression_no_decline_adrsp255.wav progression_no_decline adrsp255.wav                486          81       en        44      False Yoke. I was... Cal, dog, bear, bear, y'all and rhinoceros pink. Otter, bear, mask, snake, rhinoceros...\n",
            "progression_no_decline_adrsp306.wav progression_no_decline adrsp306.wav                874         178       en        41      False The name of the animals that you can think of you can start now. I can't think of that. Name all the...\n",
            "progression_no_decline_adrsp157.wav progression_no_decline adrsp157.wav               1046         184       en        22      False And you can begin cat dog mouth rabbit, lion, targou, cellophons, bears, snakes. You consider a span...\n",
            "progression_no_decline_adrsp197.wav progression_no_decline adrsp197.wav                771         156       en        45      False Oh, the Y-O, the Y-O. The Y-O. A Y-O. L-L-L-M's. Okay. Of course it's called L-L-M's. Dolls, cats. O...\n",
            "progression_no_decline_adrsp031.wav progression_no_decline adrsp031.wav                147          32       en        23      False Okay, do. Don't catch snakes. Tails. Dolphins toилась. Postings, 320 Swarovts Okay. Gonna have a ful...\n",
            "progression_no_decline_adrsp368.wav progression_no_decline adrsp368.wav                961         191       en        48      False This is an example for us to try. Can, rabbit, an elephant, zebra, kangaroo, o queens of a lovely, I...\n",
            "progression_no_decline_adrsp032.wav progression_no_decline adrsp032.wav                933         191       en        67      False You can begin now. The cat, mouse, uh, Do you support one of your dolls? Any kind of... No birds or ...\n",
            "progression_no_decline_adrsp091.wav progression_no_decline adrsp091.wav               1143         234       en        37      False As many animals as you can think of and you can begin now. Dogs, horses, no birds. Oh my god. Can yo...\n",
            "progression_no_decline_adrsp124.wav progression_no_decline adrsp124.wav                470          87       en        36      False You can think of it in a minute, starting now. Dog, cat, elephant, horse, kangaroo, or a man. Dog, c...\n",
            "progression_no_decline_adrsp344.wav progression_no_decline adrsp344.wav                684         123       en        27      False Beginning now. Horse, cow, sheep, goats, mules, jyrab, elephant, ipopodermus rhinoceros, rabbits, ra...\n",
            "progression_no_decline_adrsp195.wav progression_no_decline adrsp195.wav                334          65       en        15      False Hey. And you can begin now. Horse, cow, a lamb, a cat, dog, deer. A mouse, a rat, a goat, lamb. I sa...\n",
            "progression_no_decline_adrsp253.wav progression_no_decline adrsp253.wav                343          71       en        21      False God, be careful to chose you & Although there is our God, we can, that without hm, is there anygoing...\n",
            "progression_no_decline_adrsp039.wav progression_no_decline adrsp039.wav                615         109       en        53      False Is there something on your body? I don't know. Shit. Cats, dogs, frogs, that's on the face. Snake. A...\n",
            "progression_no_decline_adrsp251.wav progression_no_decline adrsp251.wav                446          87       en        39      False Okay, nic oops, Cat ? Dog ? Horse? Yeah, spider would do it on that day now Uh Okay. Okay. Okay. Oka...\n",
            "progression_no_decline_adrsp001.wav progression_no_decline adrsp001.wav               1478         283       en        72      False Okay, you can stop now. Elephants. Zebra. That's... A dog. Cat. A rat. That's not a human. I don't k...\n",
            "progression_no_decline_adrsp207.wav progression_no_decline adrsp207.wav                409          72       en        17      False Yeah, yo, yo, how's it you can think of? OK, start now. OK, pig, cow, horse, pig, animals, dog, donk...\n",
            "progression_no_decline_adrsp041.wav progression_no_decline adrsp041.wav                980         188       en        47      False Okay, and you can begin now. Oh, Bear camel. Same as with the cowboys chicken. Oh, cowboys. Have it....\n",
            "progression_no_decline_adrsp324.wav progression_no_decline adrsp324.wav                439          96       en        22      False Any animals at all? Cow. Good. Think of another one? Horse. I'll tell you I'm just all confused. Thi...\n",
            "progression_no_decline_adrsp379.wav progression_no_decline adrsp379.wav                753         147       en        27      False Ready? Go in. Okay. Horses, pigs. Lamb, sheep, cows, chickens. Excuse me. Thank you. Theo. Okay, tha...\n",
            "progression_no_decline_adrsp384.wav progression_no_decline adrsp384.wav                775         150       en        39      False Give me all the animals you can think of. Go ahead. Cap? Dog? Big? Go? Ear? Horse? Baby? Bear? Bear?...\n",
            "progression_no_decline_adrsp177.wav progression_no_decline adrsp177.wav                766         148       en        28      False And you can begin now. Okay, rabbit, dog, cat, let's see, horse, new pig, cow, let's see, there's so...\n",
            "progression_no_decline_adrsp023.wav progression_no_decline adrsp023.wav                383          73       en        32      False And then it's soaking from now. Of course, the cow dog. This lateral dog should it fit in just a few...\n",
            "progression_no_decline_adrsp148.wav progression_no_decline adrsp148.wav                869         165       en        37      False Okay, good. For the fish. Any of the other ones, you can begin now. Dawn, cat, carrot, can I have a ...\n",
            "progression_no_decline_adrsp122.wav progression_no_decline adrsp122.wav                414          68       en        37      False Just use all the animal shooting sinkhole. Off you go. Doug cat, horse cow sheep, Mew, lion tiger, c...\n",
            "progression_no_decline_adrsp359.wav progression_no_decline adrsp359.wav               1282         256       en        62      False Good thing I'll be in a minute's time. Okay, ready? Go ahead. A horse. Right. A cow. A dog. A cat. I...\n",
            "progression_no_decline_adrsp030.wav progression_no_decline adrsp030.wav                338          66       en        23      False I can, I can. You can start now. Dogs, fly in zebra. I'm not a fast enough. A horse. Donkey. Monkeys...\n",
            "progression_no_decline_adrsp319.wav progression_no_decline adrsp319.wav                390          72       en        32      False Yo, it's called Yo, and you can start now. Um, Cat. Rabbit. Mouse. Right. Chicken. Orch. Monkey. Um....\n",
            "progression_no_decline_adrsp200.wav progression_no_decline adrsp200.wav                531          92       en        21      False Oh, yeah, you can think of one minute you can start now everything but fish and birds. Cat dog, elep...\n",
            "progression_no_decline_adrsp193.wav progression_no_decline adrsp193.wav                438          85       en        21      False Now, Doug, a cat and elephant that deer, a goat and a cow, a horse, a monkey, and a donkey and who e...\n",
            "progression_no_decline_adrsp378.wav progression_no_decline adrsp378.wav               1614         325       en        71      False Did you know? My nostrils. What else? Dog. Cat. Or, you don't want no birds, you say? No birds. Um, ...\n",
            "progression_no_decline_adrsp128.wav progression_no_decline adrsp128.wav               1089         191       en        60      False And one minute, and you can begin? No. I do not. There. Camel. Here. Hell. Uh, uh, uh, Fawn and FBWN...\n",
            "progression_no_decline_adrsp161.wav progression_no_decline adrsp161.wav                942         179       en        40      False And you can begin now. Cat dog mouse, cow horse, an ox, elephant, a monkey, a lion. Okay, group. Cat...\n",
            "progression_no_decline_adrsp192.wav progression_no_decline adrsp192.wav                441          80       en        10      False We go with the calf, the dog, the rat, the cow, the chickens, the goats, the horses, the deer, the r...\n",
            "progression_no_decline_adrsp196.wav progression_no_decline adrsp196.wav                658         142       en        33      False And you can start now. Name the animals for me. Oh, I Want you to do it here? No, I want you to know...\n",
            "progression_no_decline_adrsp136.wav progression_no_decline adrsp136.wav                960         182       en        25      False Yeah, off you go. Now you, you don't want anything like the animal, like caliber, anything like that...\n",
            "progression_no_decline_adrsp130.wav progression_no_decline adrsp130.wav                464          86       en        13      False dog rabbit, chipmunk, red squirrel, and horses, cows, horses, cows. How's it going? You want to thin...\n",
            "progression_no_decline_adrsp024.wav progression_no_decline adrsp024.wav                219          34       en         8      False Okay, cat, dog, chicken, rooster, pig, sheep, goat, cow, horse, pony, zebra, lion, tiger, hamper, le...\n",
            "progression_no_decline_adrsp007.wav progression_no_decline adrsp007.wav                517          91       en        29      False Are you ready? Stop now. Dog, cat, horse, cow, kangaroo, lion, tiger, elephant, giraffe, pig, skunk,...\n",
            "progression_no_decline_adrsp382.wav progression_no_decline adrsp382.wav                960         184       en        17      False Elephant, Tider, Bear, Monkey, Giraffe, Elephant, King of the Rube, Camel, Bear, Lion, Elephant, the...\n",
            "progression_no_decline_adrsp349.wav progression_no_decline adrsp349.wav                605          84       en         9      False And now, okay, cat, dog, canary, fish, rhinoceros, tiger, lion, monkey, hippopotamus, zebra, horse, ...\n",
            "progression_no_decline_adrsp321.wav progression_no_decline adrsp321.wav                385          74       en        17      False Begin now animals were horse to cow a sheep a deer a rabbit Dog a cat a mouse A horse I guess I used...\n",
            "progression_no_decline_adrsp043.wav progression_no_decline adrsp043.wav               1263         206       en        15      False Many animals as you can think of in one minute you can begin now. Dog, cat, horse, donkey, chicken, ...\n",
            "progression_no_decline_adrsp198.wav progression_no_decline adrsp198.wav                478          83       en        17      False And you can begin now. Kangaroo, horses, dogs, alligators. Oh, that's a fish. Yeah. Wall versus, oh,...\n",
            "progression_no_decline_adrsp019.wav progression_no_decline adrsp019.wav                819         153       en        33      False Why am I here? Similar idea. But this time, words beginning with the letter S. Words beginning with ...\n",
            "progression_no_decline_adrsp333.wav progression_no_decline adrsp333.wav                558          97       en        38      False can start now. Cow, horse, pony, sheep, hippopotamus, rhinoceros, rabbit, chicken, dog, cat, snake, ...\n",
            "progression_no_decline_adrsp310.wav progression_no_decline adrsp310.wav                198          35       en        20      False So. How prefac- fluff one pin I've tried the ground hog. Maarpe dormitory. W. W. W. W. K-破 B-... Gu ...\n",
            "progression_no_decline_adrsp137.wav progression_no_decline adrsp137.wav               1103         208       en        28      False Now, they can be farm animals, they can be zoo animals, or they can be pet animals, but it can't be ...\n",
            "progression_no_decline_adrsp380.wav progression_no_decline adrsp380.wav                202          40       en        11      False all the animals you can think of. You can start having. Oh, I thought I had to wait till the... No, ...\n",
            "progression_no_decline_adrsp056.wav progression_no_decline adrsp056.wav                532          93       en        40      False Dawn, cat, horse. Any more? Animals. Mm-hmm. Many animals as you can think. Motion. Help. Wild anima...\n",
            "progression_no_decline_adrsp028.wav progression_no_decline adrsp028.wav               1383         264       en        68      False Okay, do you want me to go through that again? Yes. Yeah. Okay. Well, you do tell me as many animals...\n",
            "progression_no_decline_adrsp096.wav progression_no_decline adrsp096.wav               1056         214       en        38      False You can begin now Okay You're about 40 seconds half Do I have boards here okay, you Bridge There Oka...\n",
            "progression_no_decline_adrsp052.wav progression_no_decline adrsp052.wav                671         125       en        45      False can be done. Okay, you start then. Go on. Dog, cat, you say fish, flowers, my mouse. Did I say dog? ...\n",
            "progression_no_decline_adrsp042.wav progression_no_decline adrsp042.wav                398          66       en        17      False That's why I have to get this. Mine, Tiger, elephant, giraffe, monkey, ape, camel, pig, cow, horse, ...\n",
            "progression_no_decline_adrsp377.wav progression_no_decline adrsp377.wav                426          79       en        13      False I think of it and you can start now. Cat dog, mass horse, zebra elephant. I'm gonna get to the zoo. ...\n",
            "progression_no_decline_adrsp350.wav progression_no_decline adrsp350.wav                845         172       en        56      False A yolk. Yeah. Okay. Start now. Yeah, that's dull. Mm-hmm. Cat. What's the heart? An elephant. Okay. ...\n",
            "progression_no_decline_adrsp363.wav progression_no_decline adrsp363.wav                858         171       en        47      False Are you a minute? Maybe all the animals you can put there. Ready? Go ahead. Down. Get. Um. Of course...\n",
            "progression_no_decline_adrsp204.wav progression_no_decline adrsp204.wav               1711         352       en        74      False Animals as you can think of and you can start now. Dog, cat. Dog and cat. Animals. I don't know. Nam...\n",
            "      progression_test_adrspt15.wav       progression_test adrspt15.wav                739         156       en        40      False When you can begin, now. Okay, horse, cow, dog. Horse, um, horse cow, dog. A cat. Can I say a cow? J...\n",
            "      progression_test_adrspt20.wav       progression_test adrspt20.wav                844         170       en        38      False Ready? One minute time for the animals. Go ahead a bit. Drunk, cat, mouse, um... Um... Hey, um... Dr...\n",
            "       progression_test_adrspt4.wav       progression_test  adrspt4.wav                960         183       en        60      False Ready? Go ahead, Tom. Squirrel. Rabbit. Fox. Bear. Tiger. Bear. Bear. Bear. Did I say horse? Bear. B...\n",
            "      progression_test_adrspt27.wav       progression_test adrspt27.wav                877         173       en        25      False You can start now, name some animals for me. Those horses and cows and... The mule and the horses ar...\n",
            "      progression_test_adrspt16.wav       progression_test adrspt16.wav                535         107       en        23      False Dogs Fear Yes How many more years to have them you still have 30 seconds Rabbit fish did I say schoo...\n",
            "      progression_test_adrspt28.wav       progression_test adrspt28.wav                491          79       en        36      False Cat, dog. You say firemanals? Oh, me animals, you can think of. Cow, horse, sheep, lamb. Did I say c...\n",
            "       progression_test_adrspt9.wav       progression_test  adrspt9.wav                550         105       en        16      False All the animals that you can think of in one minute, starting from now. Alright, auction, votes, rac...\n",
            "      progression_test_adrspt10.wav       progression_test adrspt10.wav               1057         217       en        44      False Okay, you can begin now. Many animals. Animals. Um. Um. So on. Okay. So on. Okay. So on. Okay. I don...\n",
            "      progression_test_adrspt26.wav       progression_test adrspt26.wav                968         198       en        32      False In it. So you go ahead now and name for me as many animals as you can think of. Go ahead. Oh. Quite ...\n",
            "      progression_test_adrspt13.wav       progression_test adrspt13.wav                302          54       en        25      False Oh no, look. Robin, Loujade, and the animal you send to the entire community. Lion, zebra, eggplant....\n",
            "      progression_test_adrspt31.wav       progression_test adrspt31.wav                608         110       en        42      False Hmm. I don't know. Okay, sort of with the Y-O sounds like Yo. Not that I'm not doing right here. Yo....\n",
            "      progression_test_adrspt23.wav       progression_test adrspt23.wav                808         157       en        36      False That's fine. Okay, I'll just make a thing and you can start now. Peaks, chickens, horses, cows, mues...\n",
            "      progression_test_adrspt14.wav       progression_test adrspt14.wav                817         156       en        44      False You can begin. No. Raccoon, elephant, cow. Rabbit. Lizard. It's like I'm probably seeing lizard. Hor...\n",
            "      progression_test_adrspt12.wav       progression_test adrspt12.wav                264          49       en        21      False She got it. Yeah. Done. Of course. Okay. Yeah.äänjikейств negotiator to county. Sure. Sick motion. O...\n",
            "      progression_test_adrspt32.wav       progression_test adrspt32.wav                856         159       en        44      False Okay, any animals that you like? Okay. Moodle, horse and cow, elephant and rhinoceros and lion and t...\n",
            "       progression_test_adrspt6.wav       progression_test  adrspt6.wav               1729         343       en        77      False Ready? I'm gonna give you a minute. You start naming the animals for me. Oh. Don't have a... and a.....\n",
            "       progression_test_adrspt1.wav       progression_test  adrspt1.wav                488          97       en        23      False So the name for me animals and you can begin now. Oh, cat, dog, deer, um, fish, is that in good? Oh,...\n",
            "      progression_test_adrspt21.wav       progression_test adrspt21.wav               1140         201       en        32      False Okay, good. You can begin now. Duck cow, bees, squirrels, cows, horses, pigs, lambs, use sheep. Oh, ...\n",
            "      progression_test_adrspt30.wav       progression_test adrspt30.wav                244          52       en        18      False Are you gonna get no dog cat lion elephant giraffe cow horse new donkey and camel lion lion tiger go...\n",
            "      progression_test_adrspt29.wav       progression_test adrspt29.wav                767         132       en        26      False And now. OK, a dog cat, Squirrel, Rabbit, Dear, Bear, Possum, Ratcune, Elephant, Zebrae, Camel, Donk...\n",
            "       progression_test_adrspt8.wav       progression_test  adrspt8.wav                988         187       en        34      False Get ready, go ahead. Cat, dog, mouse, cow, pig, horse, donkey. Is that alright so far? That's fine. ...\n",
            "       progression_test_adrspt3.wav       progression_test  adrspt3.wav                238          40       en        13      False I'm sorry, I'm one minute starting now. You know, I'm the cat. Of course, cow, pig, um, elephant, le...\n",
            "      progression_test_adrspt19.wav       progression_test adrspt19.wav                659         130       en        32      False There's many animals as you can think of. Tony, worse, cow, pig. Chicken, turkey, fox, zebra. Okay. ...\n",
            "      progression_test_adrspt18.wav       progression_test adrspt18.wav                376          78       en        12      False Okay, that's fine. Name as many animals as you can for me, okay? Jeref, Lion, Tiger, Cow, a bull, Je...\n",
            "      progression_test_adrspt24.wav       progression_test adrspt24.wav                642         127       en        34      False Okay, in a minute, some. Wow. Mm-hmm. An alligator, a dog, a cat. Oh, let's see, a bird, that's not ...\n",
            "       progression_test_adrspt2.wav       progression_test  adrspt2.wav                400          70       en        34      False Okay, fine. Yeah. Oh, of course. Tiger, lion. Lofan. Giraffe, monkey. Yeah. Yeah. No fish, no. Yeah,...\n",
            "      progression_test_adrspt25.wav       progression_test adrspt25.wav               1003         197       en        42      False I have to start. I think it is many animals as you can think of and you can begin now. No, look at t...\n",
            "      progression_test_adrspt17.wav       progression_test adrspt17.wav                169          29       en         4      False Okay, all the animals you can think of and you can start now. Cow, horse, rabbit squirrel, chipmunk,...\n",
            "      progression_test_adrspt11.wav       progression_test adrspt11.wav                451          85       en        31      False Oh, okay. And you can begin now. Oh. Name it from morning. Uh, farm animals you've said. As many ani...\n",
            "      progression_test_adrspt22.wav       progression_test adrspt22.wav                804         161       en        36      False Hey, my all the animals you can think of and you can begin now. Chad, dog, animals, lamb, sheep, goa...\n",
            "       progression_test_adrspt7.wav       progression_test  adrspt7.wav               1029         208       en        45      False Already. Right Nostrils. Um, I don't know which. Any animal? Could we have an elephant? An elephant ...\n",
            "       progression_test_adrspt5.wav       progression_test  adrspt5.wav               1202         234       en        67      False Off you go. Well, can we get my surrounding animals? No. I'll say, helophon. Any more? Is it alright...\n",
            "\n",
            "==================================================\n",
            "Step 5: Extracting linguistic features for BERT...\n",
            "Extracting linguistic features...\n",
            "\n",
            "Pipeline completed successfully!\n",
            "Results saved to: /content\n",
            "\n",
            "Output files:\n",
            "  - Transcripts: /content/transcripts/\n",
            "  - Transcript summary: /content/transcript_summary.csv\n",
            "  - Linguistic features: /content/linguistic_features.pkl\n",
            "\n",
            "============================================================\n",
            "EXTRACTING FEATURES WITH CHECKPOINTING\n",
            "============================================================\n",
            "Total files to process: 271\n",
            "Already processed: 0\n",
            "\n",
            "Processing diagnosis_ad (87 files)...\n",
            "  Extracting features for adrso047.wav...\n",
            "Saved features for diagnosis_ad_adrso047.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso047.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso047.wav (1/271)\n",
            "  Extracting features for adrso128.wav...\n",
            "Saved features for diagnosis_ad_adrso128.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso128.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso128.wav (2/271)\n",
            "  Extracting features for adrso110.wav...\n",
            "Saved features for diagnosis_ad_adrso110.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso110.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso110.wav (3/271)\n",
            "  Extracting features for adrso036.wav...\n",
            "Saved features for diagnosis_ad_adrso036.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso036.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso036.wav (4/271)\n",
            "  Extracting features for adrso045.wav...\n",
            "Saved features for diagnosis_ad_adrso045.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso045.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso045.wav (5/271)\n",
            "  Extracting features for adrso093.wav...\n",
            "Saved features for diagnosis_ad_adrso093.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso093.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso093.wav (6/271)\n",
            "  Extracting features for adrso112.wav...\n",
            "Saved features for diagnosis_ad_adrso112.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso112.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso112.wav (7/271)\n",
            "  Extracting features for adrso189.wav...\n",
            "Saved features for diagnosis_ad_adrso189.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso189.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso189.wav (8/271)\n",
            "  Extracting features for adrso089.wav...\n",
            "Saved features for diagnosis_ad_adrso089.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso089.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso089.wav (9/271)\n",
            "  Extracting features for adrso205.wav...\n",
            "Saved features for diagnosis_ad_adrso205.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso205.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso205.wav (10/271)\n",
            "\n",
            "Progress: 10/271 files processed\n",
            "Checkpoint saved at 10 files\n",
            "  Extracting features for adrso060.wav...\n",
            "Saved features for diagnosis_ad_adrso060.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso060.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso060.wav (11/271)\n",
            "  Extracting features for adrso232.wav...\n",
            "Saved features for diagnosis_ad_adrso232.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso232.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso232.wav (12/271)\n",
            "  Extracting features for adrso075.wav...\n",
            "Saved features for diagnosis_ad_adrso075.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso075.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso075.wav (13/271)\n",
            "  Extracting features for adrso106.wav...\n",
            "Saved features for diagnosis_ad_adrso106.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso106.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso106.wav (14/271)\n",
            "  Extracting features for adrso063.wav...\n",
            "Saved features for diagnosis_ad_adrso063.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso063.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso063.wav (15/271)\n",
            "  Extracting features for adrso043.wav...\n",
            "Saved features for diagnosis_ad_adrso043.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso043.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso043.wav (16/271)\n",
            "  Extracting features for adrso206.wav...\n",
            "Saved features for diagnosis_ad_adrso206.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso206.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso206.wav (17/271)\n",
            "  Extracting features for adrso126.wav...\n",
            "Saved features for diagnosis_ad_adrso126.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso126.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso126.wav (18/271)\n",
            "  Extracting features for adrso109.wav...\n",
            "Saved features for diagnosis_ad_adrso109.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso109.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso109.wav (19/271)\n",
            "  Extracting features for adrso202.wav...\n",
            "Saved features for diagnosis_ad_adrso202.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso202.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso202.wav (20/271)\n",
            "\n",
            "Progress: 20/271 files processed\n",
            "Checkpoint saved at 20 files\n",
            "  Extracting features for adrso071.wav...\n",
            "Saved features for diagnosis_ad_adrso071.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso071.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso071.wav (21/271)\n",
            "  Extracting features for adrso039.wav...\n",
            "Saved features for diagnosis_ad_adrso039.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso039.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso039.wav (22/271)\n",
            "  Extracting features for adrso209.wav...\n",
            "Saved features for diagnosis_ad_adrso209.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso209.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso209.wav (23/271)\n",
            "  Extracting features for adrso228.wav...\n",
            "Saved features for diagnosis_ad_adrso228.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso228.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso228.wav (24/271)\n",
            "  Extracting features for adrso122.wav...\n",
            "Saved features for diagnosis_ad_adrso122.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso122.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso122.wav (25/271)\n",
            "  Extracting features for adrso116.wav...\n",
            "Saved features for diagnosis_ad_adrso116.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso116.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso116.wav (26/271)\n",
            "  Extracting features for adrso244.wav...\n",
            "Saved features for diagnosis_ad_adrso244.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso244.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso244.wav (27/271)\n",
            "  Extracting features for adrso141.wav...\n",
            "Saved features for diagnosis_ad_adrso141.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso141.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso141.wav (28/271)\n",
            "  Extracting features for adrso248.wav...\n",
            "Saved features for diagnosis_ad_adrso248.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso248.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso248.wav (29/271)\n",
            "  Extracting features for adrso130.wav...\n",
            "Saved features for diagnosis_ad_adrso130.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso130.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso130.wav (30/271)\n",
            "\n",
            "Progress: 30/271 files processed\n",
            "Checkpoint saved at 30 files\n",
            "  Extracting features for adrso055.wav...\n",
            "Saved features for diagnosis_ad_adrso055.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso055.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso055.wav (31/271)\n",
            "  Extracting features for adrso070.wav...\n",
            "Saved features for diagnosis_ad_adrso070.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso070.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso070.wav (32/271)\n",
            "  Extracting features for adrso222.wav...\n",
            "Saved features for diagnosis_ad_adrso222.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso222.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso222.wav (33/271)\n",
            "  Extracting features for adrso190.wav...\n",
            "Saved features for diagnosis_ad_adrso190.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso190.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso190.wav (34/271)\n",
            "  Extracting features for adrso223.wav...\n",
            "Saved features for diagnosis_ad_adrso223.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso223.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso223.wav (35/271)\n",
            "  Extracting features for adrso215.wav...\n",
            "Saved features for diagnosis_ad_adrso215.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso215.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso215.wav (36/271)\n",
            "  Extracting features for adrso234.wav...\n",
            "Saved features for diagnosis_ad_adrso234.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso234.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso234.wav (37/271)\n",
            "  Extracting features for adrso236.wav...\n",
            "Saved features for diagnosis_ad_adrso236.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso236.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso236.wav (38/271)\n",
            "  Extracting features for adrso059.wav...\n",
            "Saved features for diagnosis_ad_adrso059.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso059.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso059.wav (39/271)\n",
            "  Extracting features for adrso098.wav...\n",
            "Saved features for diagnosis_ad_adrso098.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso098.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso098.wav (40/271)\n",
            "\n",
            "Progress: 40/271 files processed\n",
            "Checkpoint saved at 40 files\n",
            "  Extracting features for adrso192.wav...\n",
            "Saved features for diagnosis_ad_adrso192.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso192.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso192.wav (41/271)\n",
            "  Extracting features for adrso090.wav...\n",
            "Saved features for diagnosis_ad_adrso090.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso090.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso090.wav (42/271)\n",
            "  Extracting features for adrso250.wav...\n",
            "Saved features for diagnosis_ad_adrso250.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso250.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso250.wav (43/271)\n",
            "  Extracting features for adrso025.wav...\n",
            "Saved features for diagnosis_ad_adrso025.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso025.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso025.wav (44/271)\n",
            "  Extracting features for adrso224.wav...\n",
            "Saved features for diagnosis_ad_adrso224.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso224.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso224.wav (45/271)\n",
            "  Extracting features for adrso031.wav...\n",
            "Saved features for diagnosis_ad_adrso031.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso031.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso031.wav (46/271)\n",
            "  Extracting features for adrso074.wav...\n",
            "Saved features for diagnosis_ad_adrso074.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso074.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso074.wav (47/271)\n",
            "  Extracting features for adrso211.wav...\n",
            "Saved features for diagnosis_ad_adrso211.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso211.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso211.wav (48/271)\n",
            "  Extracting features for adrso229.wav...\n",
            "Saved features for diagnosis_ad_adrso229.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso229.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso229.wav (49/271)\n",
            "  Extracting features for adrso197.wav...\n",
            "Saved features for diagnosis_ad_adrso197.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso197.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso197.wav (50/271)\n",
            "\n",
            "Progress: 50/271 files processed\n",
            "Checkpoint saved at 50 files\n",
            "  Extracting features for adrso049.wav...\n",
            "Saved features for diagnosis_ad_adrso049.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso049.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso049.wav (51/271)\n",
            "  Extracting features for adrso138.wav...\n",
            "Saved features for diagnosis_ad_adrso138.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso138.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso138.wav (52/271)\n",
            "  Extracting features for adrso123.wav...\n",
            "Saved features for diagnosis_ad_adrso123.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso123.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso123.wav (53/271)\n",
            "  Extracting features for adrso072.wav...\n",
            "Saved features for diagnosis_ad_adrso072.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso072.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso072.wav (54/271)\n",
            "  Extracting features for adrso027.wav...\n",
            "Saved features for diagnosis_ad_adrso027.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso027.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso027.wav (55/271)\n",
            "  Extracting features for adrso068.wav...\n",
            "Saved features for diagnosis_ad_adrso068.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso068.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso068.wav (56/271)\n",
            "  Extracting features for adrso187.wav...\n",
            "Saved features for diagnosis_ad_adrso187.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso187.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso187.wav (57/271)\n",
            "  Extracting features for adrso054.wav...\n",
            "Saved features for diagnosis_ad_adrso054.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso054.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso054.wav (58/271)\n",
            "  Extracting features for adrso249.wav...\n",
            "Saved features for diagnosis_ad_adrso249.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso249.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso249.wav (59/271)\n",
            "  Extracting features for adrso200.wav...\n",
            "Saved features for diagnosis_ad_adrso200.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso200.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso200.wav (60/271)\n",
            "\n",
            "Progress: 60/271 files processed\n",
            "Checkpoint saved at 60 files\n",
            "  Extracting features for adrso028.wav...\n",
            "Saved features for diagnosis_ad_adrso028.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso028.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso028.wav (61/271)\n",
            "  Extracting features for adrso053.wav...\n",
            "Saved features for diagnosis_ad_adrso053.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso053.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso053.wav (62/271)\n",
            "  Extracting features for adrso078.wav...\n",
            "Saved features for diagnosis_ad_adrso078.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso078.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso078.wav (63/271)\n",
            "  Extracting features for adrso056.wav...\n",
            "Saved features for diagnosis_ad_adrso056.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso056.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso056.wav (64/271)\n",
            "  Extracting features for adrso245.wav...\n",
            "Saved features for diagnosis_ad_adrso245.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso245.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso245.wav (65/271)\n",
            "  Extracting features for adrso092.wav...\n",
            "Saved features for diagnosis_ad_adrso092.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso092.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso092.wav (66/271)\n",
            "  Extracting features for adrso134.wav...\n",
            "Saved features for diagnosis_ad_adrso134.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso134.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso134.wav (67/271)\n",
            "  Extracting features for adrso216.wav...\n",
            "Saved features for diagnosis_ad_adrso216.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso216.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso216.wav (68/271)\n",
            "  Extracting features for adrso142.wav...\n",
            "Saved features for diagnosis_ad_adrso142.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso142.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso142.wav (69/271)\n",
            "  Extracting features for adrso077.wav...\n",
            "Saved features for diagnosis_ad_adrso077.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso077.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso077.wav (70/271)\n",
            "\n",
            "Progress: 70/271 files processed\n",
            "Checkpoint saved at 70 files\n",
            "  Extracting features for adrso198.wav...\n",
            "Saved features for diagnosis_ad_adrso198.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso198.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso198.wav (71/271)\n",
            "  Extracting features for adrso220.wav...\n",
            "Saved features for diagnosis_ad_adrso220.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso220.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso220.wav (72/271)\n",
            "  Extracting features for adrso024.wav...\n",
            "Saved features for diagnosis_ad_adrso024.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso024.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso024.wav (73/271)\n",
            "  Extracting features for adrso212.wav...\n",
            "Saved features for diagnosis_ad_adrso212.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso212.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso212.wav (74/271)\n",
            "  Extracting features for adrso046.wav...\n",
            "Saved features for diagnosis_ad_adrso046.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso046.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso046.wav (75/271)\n",
            "  Extracting features for adrso233.wav...\n",
            "Saved features for diagnosis_ad_adrso233.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso233.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso233.wav (76/271)\n",
            "  Extracting features for adrso247.wav...\n",
            "Saved features for diagnosis_ad_adrso247.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso247.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso247.wav (77/271)\n",
            "  Extracting features for adrso035.wav...\n",
            "Saved features for diagnosis_ad_adrso035.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso035.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso035.wav (78/271)\n",
            "  Extracting features for adrso125.wav...\n",
            "Saved features for diagnosis_ad_adrso125.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso125.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso125.wav (79/271)\n",
            "  Extracting features for adrso188.wav...\n",
            "Saved features for diagnosis_ad_adrso188.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso188.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso188.wav (80/271)\n",
            "\n",
            "Progress: 80/271 files processed\n",
            "Checkpoint saved at 80 files\n",
            "  Extracting features for adrso033.wav...\n",
            "Saved features for diagnosis_ad_adrso033.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso033.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso033.wav (81/271)\n",
            "  Extracting features for adrso237.wav...\n",
            "Saved features for diagnosis_ad_adrso237.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso237.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso237.wav (82/271)\n",
            "  Extracting features for adrso253.wav...\n",
            "Saved features for diagnosis_ad_adrso253.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso253.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso253.wav (83/271)\n",
            "  Extracting features for adrso218.wav...\n",
            "Saved features for diagnosis_ad_adrso218.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso218.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso218.wav (84/271)\n",
            "  Extracting features for adrso144.wav...\n",
            "Saved features for diagnosis_ad_adrso144.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso144.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso144.wav (85/271)\n",
            "  Extracting features for adrso032.wav...\n",
            "Saved features for diagnosis_ad_adrso032.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso032.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso032.wav (86/271)\n",
            "  Extracting features for adrso246.wav...\n",
            "Saved features for diagnosis_ad_adrso246.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_ad_adrso246.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso246.wav (87/271)\n",
            "\n",
            "Processing diagnosis_cn (79 files)...\n",
            "  Extracting features for adrso173.wav...\n",
            "Saved features for diagnosis_cn_adrso173.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso173.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso173.wav (88/271)\n",
            "  Extracting features for adrso015.wav...\n",
            "Saved features for diagnosis_cn_adrso015.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso015.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso015.wav (89/271)\n",
            "  Extracting features for adrso307.wav...\n",
            "Saved features for diagnosis_cn_adrso307.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso307.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso307.wav (90/271)\n",
            "\n",
            "Progress: 90/271 files processed\n",
            "Checkpoint saved at 90 files\n",
            "  Extracting features for adrso283.wav...\n",
            "Saved features for diagnosis_cn_adrso283.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso283.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso283.wav (91/271)\n",
            "  Extracting features for adrso167.wav...\n",
            "Saved features for diagnosis_cn_adrso167.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso167.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso167.wav (92/271)\n",
            "  Extracting features for adrso168.wav...\n",
            "Saved features for diagnosis_cn_adrso168.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso168.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso168.wav (93/271)\n",
            "  Extracting features for adrso172.wav...\n",
            "Saved features for diagnosis_cn_adrso172.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso172.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso172.wav (94/271)\n",
            "  Extracting features for adrso292.wav...\n",
            "Saved features for diagnosis_cn_adrso292.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso292.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso292.wav (95/271)\n",
            "  Extracting features for adrso316.wav...\n",
            "Saved features for diagnosis_cn_adrso316.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso316.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso316.wav (96/271)\n",
            "  Extracting features for adrso162.wav...\n",
            "Saved features for diagnosis_cn_adrso162.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso162.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso162.wav (97/271)\n",
            "  Extracting features for adrso278.wav...\n",
            "Saved features for diagnosis_cn_adrso278.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso278.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso278.wav (98/271)\n",
            "  Extracting features for adrso296.wav...\n",
            "Saved features for diagnosis_cn_adrso296.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso296.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso296.wav (99/271)\n",
            "  Extracting features for adrso300.wav...\n",
            "Saved features for diagnosis_cn_adrso300.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso300.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso300.wav (100/271)\n",
            "\n",
            "Progress: 100/271 files processed\n",
            "Checkpoint saved at 100 files\n",
            "  Extracting features for adrso291.wav...\n",
            "Saved features for diagnosis_cn_adrso291.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso291.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso291.wav (101/271)\n",
            "  Extracting features for adrso169.wav...\n",
            "Saved features for diagnosis_cn_adrso169.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso169.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso169.wav (102/271)\n",
            "  Extracting features for adrso178.wav...\n",
            "Saved features for diagnosis_cn_adrso178.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso178.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso178.wav (103/271)\n",
            "  Extracting features for adrso165.wav...\n",
            "Saved features for diagnosis_cn_adrso165.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso165.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso165.wav (104/271)\n",
            "  Extracting features for adrso177.wav...\n",
            "Saved features for diagnosis_cn_adrso177.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso177.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso177.wav (105/271)\n",
            "  Extracting features for adrso262.wav...\n",
            "Saved features for diagnosis_cn_adrso262.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso262.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso262.wav (106/271)\n",
            "  Extracting features for adrso265.wav...\n",
            "Saved features for diagnosis_cn_adrso265.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso265.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso265.wav (107/271)\n",
            "  Extracting features for adrso014.wav...\n",
            "Saved features for diagnosis_cn_adrso014.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso014.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso014.wav (108/271)\n",
            "  Extracting features for adrso021.wav...\n",
            "Saved features for diagnosis_cn_adrso021.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso021.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso021.wav (109/271)\n",
            "  Extracting features for adrso268.wav...\n",
            "Saved features for diagnosis_cn_adrso268.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso268.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso268.wav (110/271)\n",
            "\n",
            "Progress: 110/271 files processed\n",
            "Checkpoint saved at 110 files\n",
            "  Extracting features for adrso261.wav...\n",
            "Saved features for diagnosis_cn_adrso261.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso261.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso261.wav (111/271)\n",
            "  Extracting features for adrso156.wav...\n",
            "Saved features for diagnosis_cn_adrso156.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso156.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso156.wav (112/271)\n",
            "  Extracting features for adrso148.wav...\n",
            "Saved features for diagnosis_cn_adrso148.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso148.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso148.wav (113/271)\n",
            "  Extracting features for adrso016.wav...\n",
            "Saved features for diagnosis_cn_adrso016.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso016.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso016.wav (114/271)\n",
            "  Extracting features for adrso310.wav...\n",
            "Saved features for diagnosis_cn_adrso310.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso310.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso310.wav (115/271)\n",
            "  Extracting features for adrso302.wav...\n",
            "Saved features for diagnosis_cn_adrso302.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso302.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso302.wav (116/271)\n",
            "  Extracting features for adrso308.wav...\n",
            "Saved features for diagnosis_cn_adrso308.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso308.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso308.wav (117/271)\n",
            "  Extracting features for adrso018.wav...\n",
            "Saved features for diagnosis_cn_adrso018.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso018.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso018.wav (118/271)\n",
            "  Extracting features for adrso309.wav...\n",
            "Saved features for diagnosis_cn_adrso309.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso309.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso309.wav (119/271)\n",
            "  Extracting features for adrso298.wav...\n",
            "Saved features for diagnosis_cn_adrso298.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso298.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso298.wav (120/271)\n",
            "\n",
            "Progress: 120/271 files processed\n",
            "Checkpoint saved at 120 files\n",
            "  Extracting features for adrso180.wav...\n",
            "Saved features for diagnosis_cn_adrso180.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso180.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso180.wav (121/271)\n",
            "  Extracting features for adrso154.wav...\n",
            "Saved features for diagnosis_cn_adrso154.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso154.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso154.wav (122/271)\n",
            "  Extracting features for adrso273.wav...\n",
            "Saved features for diagnosis_cn_adrso273.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso273.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso273.wav (123/271)\n",
            "  Extracting features for adrso159.wav...\n",
            "Saved features for diagnosis_cn_adrso159.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso159.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso159.wav (124/271)\n",
            "  Extracting features for adrso259.wav...\n",
            "Saved features for diagnosis_cn_adrso259.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso259.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso259.wav (125/271)\n",
            "  Extracting features for adrso151.wav...\n",
            "Saved features for diagnosis_cn_adrso151.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso151.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso151.wav (126/271)\n",
            "  Extracting features for adrso267.wav...\n",
            "Saved features for diagnosis_cn_adrso267.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso267.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso267.wav (127/271)\n",
            "  Extracting features for adrso019.wav...\n",
            "Saved features for diagnosis_cn_adrso019.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso019.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso019.wav (128/271)\n",
            "  Extracting features for adrso153.wav...\n",
            "Saved features for diagnosis_cn_adrso153.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso153.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso153.wav (129/271)\n",
            "  Extracting features for adrso274.wav...\n",
            "Saved features for diagnosis_cn_adrso274.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso274.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso274.wav (130/271)\n",
            "\n",
            "Progress: 130/271 files processed\n",
            "Checkpoint saved at 130 files\n",
            "  Extracting features for adrso023.wav...\n",
            "Saved features for diagnosis_cn_adrso023.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso023.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso023.wav (131/271)\n",
            "  Extracting features for adrso012.wav...\n",
            "Saved features for diagnosis_cn_adrso012.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso012.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso012.wav (132/271)\n",
            "  Extracting features for adrso002.wav...\n",
            "Saved features for diagnosis_cn_adrso002.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso002.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso002.wav (133/271)\n",
            "  Extracting features for adrso022.wav...\n",
            "Saved features for diagnosis_cn_adrso022.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso022.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso022.wav (134/271)\n",
            "  Extracting features for adrso266.wav...\n",
            "Saved features for diagnosis_cn_adrso266.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso266.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso266.wav (135/271)\n",
            "  Extracting features for adrso280.wav...\n",
            "Saved features for diagnosis_cn_adrso280.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso280.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso280.wav (136/271)\n",
            "  Extracting features for adrso152.wav...\n",
            "Saved features for diagnosis_cn_adrso152.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso152.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso152.wav (137/271)\n",
            "  Extracting features for adrso007.wav...\n",
            "Saved features for diagnosis_cn_adrso007.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso007.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso007.wav (138/271)\n",
            "  Extracting features for adrso276.wav...\n",
            "Saved features for diagnosis_cn_adrso276.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso276.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso276.wav (139/271)\n",
            "  Extracting features for adrso260.wav...\n",
            "Saved features for diagnosis_cn_adrso260.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso260.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso260.wav (140/271)\n",
            "\n",
            "Progress: 140/271 files processed\n",
            "Checkpoint saved at 140 files\n",
            "  Extracting features for adrso017.wav...\n",
            "Saved features for diagnosis_cn_adrso017.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso017.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso017.wav (141/271)\n",
            "  Extracting features for adrso005.wav...\n",
            "Saved features for diagnosis_cn_adrso005.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso005.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso005.wav (142/271)\n",
            "  Extracting features for adrso299.wav...\n",
            "Saved features for diagnosis_cn_adrso299.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso299.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso299.wav (143/271)\n",
            "  Extracting features for adrso157.wav...\n",
            "Saved features for diagnosis_cn_adrso157.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso157.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso157.wav (144/271)\n",
            "  Extracting features for adrso182.wav...\n",
            "Saved features for diagnosis_cn_adrso182.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso182.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso182.wav (145/271)\n",
            "  Extracting features for adrso008.wav...\n",
            "Saved features for diagnosis_cn_adrso008.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso008.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso008.wav (146/271)\n",
            "  Extracting features for adrso161.wav...\n",
            "Saved features for diagnosis_cn_adrso161.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso161.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso161.wav (147/271)\n",
            "  Extracting features for adrso263.wav...\n",
            "Saved features for diagnosis_cn_adrso263.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso263.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso263.wav (148/271)\n",
            "  Extracting features for adrso257.wav...\n",
            "Saved features for diagnosis_cn_adrso257.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso257.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso257.wav (149/271)\n",
            "  Extracting features for adrso164.wav...\n",
            "Saved features for diagnosis_cn_adrso164.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso164.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso164.wav (150/271)\n",
            "\n",
            "Progress: 150/271 files processed\n",
            "Checkpoint saved at 150 files\n",
            "  Extracting features for adrso289.wav...\n",
            "Saved features for diagnosis_cn_adrso289.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso289.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso289.wav (151/271)\n",
            "  Extracting features for adrso270.wav...\n",
            "Saved features for diagnosis_cn_adrso270.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso270.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso270.wav (152/271)\n",
            "  Extracting features for adrso264.wav...\n",
            "Saved features for diagnosis_cn_adrso264.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso264.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso264.wav (153/271)\n",
            "  Extracting features for adrso277.wav...\n",
            "Saved features for diagnosis_cn_adrso277.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso277.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso277.wav (154/271)\n",
            "  Extracting features for adrso160.wav...\n",
            "Saved features for diagnosis_cn_adrso160.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso160.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso160.wav (155/271)\n",
            "  Extracting features for adrso186.wav...\n",
            "Saved features for diagnosis_cn_adrso186.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso186.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso186.wav (156/271)\n",
            "  Extracting features for adrso003.wav...\n",
            "Saved features for diagnosis_cn_adrso003.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso003.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso003.wav (157/271)\n",
            "  Extracting features for adrso286.wav...\n",
            "Saved features for diagnosis_cn_adrso286.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso286.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso286.wav (158/271)\n",
            "  Extracting features for adrso285.wav...\n",
            "Saved features for diagnosis_cn_adrso285.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso285.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso285.wav (159/271)\n",
            "  Extracting features for adrso170.wav...\n",
            "Saved features for diagnosis_cn_adrso170.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso170.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso170.wav (160/271)\n",
            "\n",
            "Progress: 160/271 files processed\n",
            "Checkpoint saved at 160 files\n",
            "  Extracting features for adrso183.wav...\n",
            "Saved features for diagnosis_cn_adrso183.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso183.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso183.wav (161/271)\n",
            "  Extracting features for adrso281.wav...\n",
            "Saved features for diagnosis_cn_adrso281.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso281.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso281.wav (162/271)\n",
            "  Extracting features for adrso010.wav...\n",
            "Saved features for diagnosis_cn_adrso010.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso010.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso010.wav (163/271)\n",
            "  Extracting features for adrso315.wav...\n",
            "Saved features for diagnosis_cn_adrso315.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso315.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso315.wav (164/271)\n",
            "  Extracting features for adrso312.wav...\n",
            "Saved features for diagnosis_cn_adrso312.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso312.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso312.wav (165/271)\n",
            "  Extracting features for adrso158.wav...\n",
            "Saved features for diagnosis_cn_adrso158.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/diagnosis_cn_adrso158.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrso158.wav (166/271)\n",
            "\n",
            "Processing progression_decline (15 files)...\n",
            "  Extracting features for adrsp055.wav...\n",
            "Saved features for progression_decline_adrsp055.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp055.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp055.wav (167/271)\n",
            "  Extracting features for adrsp300.wav...\n",
            "Saved features for progression_decline_adrsp300.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp300.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp300.wav (168/271)\n",
            "  Extracting features for adrsp003.wav...\n",
            "Saved features for progression_decline_adrsp003.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp003.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp003.wav (169/271)\n",
            "  Extracting features for adrsp266.wav...\n",
            "Saved features for progression_decline_adrsp266.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp266.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp266.wav (170/271)\n",
            "\n",
            "Progress: 170/271 files processed\n",
            "Checkpoint saved at 170 files\n",
            "  Extracting features for adrsp320.wav...\n",
            "Saved features for progression_decline_adrsp320.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp320.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp320.wav (171/271)\n",
            "  Extracting features for adrsp313.wav...\n",
            "Saved features for progression_decline_adrsp313.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp313.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp313.wav (172/271)\n",
            "  Extracting features for adrsp179.wav...\n",
            "Saved features for progression_decline_adrsp179.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp179.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp179.wav (173/271)\n",
            "  Extracting features for adrsp051.wav...\n",
            "Saved features for progression_decline_adrsp051.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp051.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp051.wav (174/271)\n",
            "  Extracting features for adrsp326.wav...\n",
            "Saved features for progression_decline_adrsp326.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp326.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp326.wav (175/271)\n",
            "  Extracting features for adrsp101.wav...\n",
            "Saved features for progression_decline_adrsp101.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp101.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp101.wav (176/271)\n",
            "  Extracting features for adrsp127.wav...\n",
            "Saved features for progression_decline_adrsp127.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp127.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp127.wav (177/271)\n",
            "  Extracting features for adrsp357.wav...\n",
            "Saved features for progression_decline_adrsp357.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp357.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp357.wav (178/271)\n",
            "  Extracting features for adrsp276.wav...\n",
            "Saved features for progression_decline_adrsp276.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp276.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp276.wav (179/271)\n",
            "  Extracting features for adrsp209.wav...\n",
            "Saved features for progression_decline_adrsp209.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp209.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp209.wav (180/271)\n",
            "\n",
            "Progress: 180/271 files processed\n",
            "Checkpoint saved at 180 files\n",
            "  Extracting features for adrsp318.wav...\n",
            "Saved features for progression_decline_adrsp318.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_decline_adrsp318.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp318.wav (181/271)\n",
            "\n",
            "Processing progression_no_decline (58 files)...\n",
            "  Extracting features for adrsp109.wav...\n",
            "Saved features for progression_no_decline_adrsp109.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp109.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp109.wav (182/271)\n",
            "  Extracting features for adrsp255.wav...\n",
            "Saved features for progression_no_decline_adrsp255.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp255.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp255.wav (183/271)\n",
            "  Extracting features for adrsp306.wav...\n",
            "Saved features for progression_no_decline_adrsp306.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp306.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp306.wav (184/271)\n",
            "  Extracting features for adrsp157.wav...\n",
            "Saved features for progression_no_decline_adrsp157.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp157.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp157.wav (185/271)\n",
            "  Extracting features for adrsp197.wav...\n",
            "Saved features for progression_no_decline_adrsp197.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp197.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp197.wav (186/271)\n",
            "  Extracting features for adrsp031.wav...\n",
            "Saved features for progression_no_decline_adrsp031.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp031.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp031.wav (187/271)\n",
            "  Extracting features for adrsp368.wav...\n",
            "Saved features for progression_no_decline_adrsp368.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp368.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp368.wav (188/271)\n",
            "  Extracting features for adrsp032.wav...\n",
            "Saved features for progression_no_decline_adrsp032.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp032.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp032.wav (189/271)\n",
            "  Extracting features for adrsp091.wav...\n",
            "Saved features for progression_no_decline_adrsp091.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp091.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp091.wav (190/271)\n",
            "\n",
            "Progress: 190/271 files processed\n",
            "Checkpoint saved at 190 files\n",
            "  Extracting features for adrsp124.wav...\n",
            "Saved features for progression_no_decline_adrsp124.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp124.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp124.wav (191/271)\n",
            "  Extracting features for adrsp344.wav...\n",
            "Saved features for progression_no_decline_adrsp344.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp344.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp344.wav (192/271)\n",
            "  Extracting features for adrsp195.wav...\n",
            "Saved features for progression_no_decline_adrsp195.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp195.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp195.wav (193/271)\n",
            "  Extracting features for adrsp253.wav...\n",
            "Saved features for progression_no_decline_adrsp253.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp253.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp253.wav (194/271)\n",
            "  Extracting features for adrsp039.wav...\n",
            "Saved features for progression_no_decline_adrsp039.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp039.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp039.wav (195/271)\n",
            "  Extracting features for adrsp251.wav...\n",
            "Saved features for progression_no_decline_adrsp251.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp251.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp251.wav (196/271)\n",
            "  Extracting features for adrsp001.wav...\n",
            "Saved features for progression_no_decline_adrsp001.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp001.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp001.wav (197/271)\n",
            "  Extracting features for adrsp207.wav...\n",
            "Saved features for progression_no_decline_adrsp207.wav to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/features/progression_no_decline_adrsp207.wav_features.pkl\n",
            "Saved checkpoint to /content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints/checkpoints/checkpoint.pkl\n",
            "  Successfully processed adrsp207.wav (198/271)\n",
            "  Extracting features for adrsp041.wav...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from typing import Dict, List\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import the necessary classes from your original file\n",
        "# Adjust the file name if your original code is saved under a different name\n",
        "from adress_analyzer import ADReSSoAnalyzer, extend_analyzer_with_model\n",
        "\n",
        "class FeatureExtractionCheckpointer:\n",
        "    def __init__(self, analyzer, output_dir=\"/content/drive/MyDrive/Voice/extracted/ADReSSo21/checkpoints\"):\n",
        "        \"\"\"\n",
        "        Initialize checkpointer for feature extraction\n",
        "\n",
        "        Args:\n",
        "            analyzer: Instance of ADReSSoAnalyzer or ADReSSoAnalyzerExtended\n",
        "            output_dir: Directory to store checkpoints and features\n",
        "        \"\"\"\n",
        "        self.analyzer = analyzer\n",
        "        self.output_dir = output_dir\n",
        "        self.checkpoint_dir = os.path.join(output_dir, \"checkpoints\")\n",
        "        self.feature_dir = os.path.join(output_dir, \"features\")\n",
        "\n",
        "        # Create directories if they don't exist\n",
        "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
        "        os.makedirs(self.feature_dir, exist_ok=True)\n",
        "\n",
        "        # Initialize checkpoint tracking\n",
        "        self.checkpoint_file = os.path.join(self.checkpoint_dir, \"checkpoint.pkl\")\n",
        "        self.processed_files = set()\n",
        "        self.features_dict = {}\n",
        "\n",
        "        # Load existing checkpoint if available\n",
        "        self.load_checkpoint()\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        \"\"\"Load existing checkpoint if available\"\"\"\n",
        "        if os.path.exists(self.checkpoint_file):\n",
        "            try:\n",
        "                with open(self.checkpoint_file, 'rb') as f:\n",
        "                    checkpoint = pickle.load(f)\n",
        "                    self.processed_files = checkpoint.get('processed_files', set())\n",
        "                    self.features_dict = checkpoint.get('features_dict', {})\n",
        "                    print(f\"Loaded checkpoint with {len(self.processed_files)} processed files\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading checkpoint: {str(e)}\")\n",
        "                self.processed_files = set()\n",
        "                self.features_dict = {}\n",
        "        else:\n",
        "            print(\"No checkpoint found, starting fresh\")\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        \"\"\"Save current state as checkpoint\"\"\"\n",
        "        checkpoint = {\n",
        "            'processed_files': self.processed_files,\n",
        "            'features_dict': self.features_dict\n",
        "        }\n",
        "        try:\n",
        "            with open(self.checkpoint_file, 'wb') as f:\n",
        "                pickle.dump(checkpoint, f)\n",
        "            print(f\"Saved checkpoint to {self.checkpoint_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving checkpoint: {str(e)}\")\n",
        "\n",
        "    def save_individual_feature(self, file_id: str, features: Dict):\n",
        "        \"\"\"Save features for a single file\"\"\"\n",
        "        feature_file = os.path.join(self.feature_dir, f\"{file_id}_features.pkl\")\n",
        "        try:\n",
        "            with open(feature_file, 'wb') as f:\n",
        "                pickle.dump(features, f)\n",
        "            print(f\"Saved features for {file_id} to {feature_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving features for {file_id}: {str(e)}\")\n",
        "\n",
        "    def load_individual_feature(self, file_id: str) -> Dict:\n",
        "        \"\"\"Load features for a single file\"\"\"\n",
        "        feature_file = os.path.join(self.feature_dir, f\"{file_id}_features.pkl\")\n",
        "        if os.path.exists(feature_file):\n",
        "            try:\n",
        "                with open(feature_file, 'rb') as f:\n",
        "                    return pickle.load(f)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading features for {file_id}: {str(e)}\")\n",
        "                return None\n",
        "        return None\n",
        "\n",
        "    def extract_features_with_checkpoints(self, audio_files: Dict[str, List[str]]) -> Dict:\n",
        "        \"\"\"\n",
        "        Extract features with checkpointing and incremental saving\n",
        "\n",
        "        Args:\n",
        "            audio_files: Dictionary of category-wise audio file paths\n",
        "        Returns:\n",
        "            Dictionary of extracted features\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"EXTRACTING FEATURES WITH CHECKPOINTING\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        total_files = sum(len(files) for files in audio_files.values())\n",
        "        processed_count = len(self.processed_files)\n",
        "        print(f\"Total files to process: {total_files}\")\n",
        "        print(f\"Already processed: {processed_count}\")\n",
        "\n",
        "        for category, files in audio_files.items():\n",
        "            print(f\"\\nProcessing {category} ({len(files)} files)...\")\n",
        "\n",
        "            for file_path in files:\n",
        "                filename = os.path.basename(file_path)\n",
        "                file_id = f\"{category}_{filename}\"\n",
        "\n",
        "                # Skip if already processed\n",
        "                if file_id in self.processed_files:\n",
        "                    print(f\"  Skipping {filename} (already processed)\")\n",
        "                    # Load existing features\n",
        "                    features = self.load_individual_feature(file_id)\n",
        "                    if features is not None:\n",
        "                        self.features_dict[file_id] = features\n",
        "                    continue\n",
        "\n",
        "                print(f\"  Extracting features for {filename}...\")\n",
        "\n",
        "                # Extract features\n",
        "                try:\n",
        "                    features = self.analyzer.extract_acoustic_features(file_path)\n",
        "\n",
        "                    if features is not None:\n",
        "                        # Store in memory\n",
        "                        self.features_dict[file_id] = features\n",
        "                        # Save individual feature file\n",
        "                        self.save_individual_feature(file_id, features)\n",
        "                        # Add to processed files\n",
        "                        self.processed_files.add(file_id)\n",
        "                        # Save checkpoint\n",
        "                        self.save_checkpoint()\n",
        "                        processed_count += 1\n",
        "                        print(f\"  Successfully processed {filename} ({processed_count}/{total_files})\")\n",
        "                    else:\n",
        "                        print(f\"  Warning: Failed to extract features for {filename}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  Error processing {filename}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "                # Periodic status update\n",
        "                if processed_count % 10 == 0:\n",
        "                    print(f\"\\nProgress: {processed_count}/{total_files} files processed\")\n",
        "                    print(f\"Checkpoint saved at {processed_count} files\")\n",
        "\n",
        "        print(f\"\\nFeature extraction completed!\")\n",
        "        print(f\"Processed {processed_count}/{total_files} files\")\n",
        "        print(f\"Features saved to: {self.feature_dir}\")\n",
        "        print(f\"Checkpoints saved to: {self.checkpoint_dir}\")\n",
        "\n",
        "        return self.features_dict\n",
        "\n",
        "    def run_pipeline_with_checkpoints(self, num_epochs=30, batch_size=8):\n",
        "        \"\"\"\n",
        "        Run the complete pipeline with checkpointing\n",
        "        \"\"\"\n",
        "        print(\"=\"*80)\n",
        "        print(\"RUNNING ADReSSo PIPELINE WITH CHECKPOINTING\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Run original pipeline up to feature extraction\n",
        "        results = self.analyzer.run_complete_pipeline()\n",
        "\n",
        "        if results is None:\n",
        "            print(\"Error in initial pipeline. Cannot proceed.\")\n",
        "            return None\n",
        "\n",
        "        # Extract features with checkpointing\n",
        "        features_dict = self.extract_features_with_checkpoints(results['audio_files'])\n",
        "\n",
        "        # Continue with model training and evaluation\n",
        "        if isinstance(self.analyzer, ADReSSoAnalyzerExtended):\n",
        "            print(\"\\nContinuing with model training...\")\n",
        "            results = self.analyzer.run_complete_pipeline_with_model(\n",
        "                num_epochs=num_epochs,\n",
        "                batch_size=batch_size\n",
        "            )\n",
        "        else:\n",
        "            print(\"\\nUsing base analyzer, skipping model training\")\n",
        "            results['features_dict'] = features_dict\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PIPELINE WITH CHECKPOINTING COMPLETED!\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        return results\n",
        "\n",
        "# Usage Example\n",
        "if __name__ == \"__main__\":\n",
        "    # Mount Google Drive (required for Colab)\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Install required packages\n",
        "    !pip install librosa soundfile opensmile speechbrain transformers torch openai-whisper\n",
        "    !pip install pandas numpy matplotlib seaborn torch-geometric\n",
        "\n",
        "    # Initialize the extended analyzer\n",
        "    ExtendedAnalyzer = extend_analyzer_with_model()\n",
        "    analyzer = ExtendedAnalyzer(base_path=\"/content/drive/MyDrive/Voice/extracted/ADReSSo21\")\n",
        "\n",
        "    # Create checkpointer with the initialized analyzer\n",
        "    checkpointer = FeatureExtractionCheckpointer(analyzer)\n",
        "\n",
        "    # Run pipeline with checkpointing\n",
        "    results = checkpointer.run_pipeline_with_checkpoints(\n",
        "        num_epochs=5,\n",
        "        batch_size=4\n",
        "    )\n",
        "\n",
        "    if results:\n",
        "        print(\"\\nPipeline with checkpointing completed successfully!\")\n",
        "        print(f\"Check output directories for saved features and checkpoints:\")\n",
        "        print(f\"- Features: {checkpointer.feature_dir}\")\n",
        "        print(f\"- Checkpoints: {checkpointer.checkpoint_dir}\")\n",
        "    else:\n",
        "        print(\"Pipeline encountered errors. Please check the logs.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mei3bwKK3j4n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPVPsXvB0WI1W+t7J87ku+q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "007249e062f1443d889d23932b234557": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_095b431fe1224689973221b42f2169a4",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fc842326d724812bc47a0c2ecec5c4d",
            "value": 48
          }
        },
        "00d2d7c8a32042d59f455db492659fa8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01eb3cb50e0f4d308a83df0db0cec5df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04644ba96db34197a2ecd69763f9786a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd1bb15cc2bf41db8d66a15bc159bcd9",
            "max": 377607901,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab9a6d44e29e4d488701b76a0642e602",
            "value": 377607901
          }
        },
        "085c40ce31074421a5c82ce5de8ff7ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "086dc534062b4474a1f1ae78870ff707": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08de1c36f11840ada3a01fa309033172": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095b431fe1224689973221b42f2169a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c454637e4904ce2b2d8ea22479a2c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01eb3cb50e0f4d308a83df0db0cec5df",
            "placeholder": "​",
            "style": "IPY_MODEL_fbbcf58b18614fe896e6566607e4ecf8",
            "value": " 291/291 [00:00&lt;00:00, 18.0kB/s]"
          }
        },
        "0fc842326d724812bc47a0c2ecec5c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1117e567fc274d14bfa7efc770cb923f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a86b5b5a0e4a2a836e7486dfed3dd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "151ed1673f4e4b7993a7c9211cbf7e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "183d388405ab475ea18004de38ee0227": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eaa0759a6cc4abf8f90c02e241fc5d4",
            "max": 159,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_492acdc324f74447a839c0b4e9ba7204",
            "value": 159
          }
        },
        "1bc67752d48946a994b28cdc0c1c3941": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cd03aa7a27048fd93df2ce4e77908dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28fb02af24ce458a8b2a15a7a52eeaab",
            "placeholder": "​",
            "style": "IPY_MODEL_7c373a821dd64c3fb86d89664f94babe",
            "value": " 159/159 [00:00&lt;00:00, 14.9kB/s]"
          }
        },
        "218a0a92bfbe4b318a4ef81016ddb0c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f80cf032dbb47e9b6cf2bbbcb120270",
            "placeholder": "​",
            "style": "IPY_MODEL_76b98eba0fea4276b4106114459fe8ec",
            "value": "config.json: 100%"
          }
        },
        "259cf80ed17042cf911bdc53b88ed9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "264f958643dc460485a1e70be6e737da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26e7cdd427b84218bc6f6607863560ba",
            "placeholder": "​",
            "style": "IPY_MODEL_fcffb97fb1d44f979241d3e634cd7e3a",
            "value": "model.safetensors: 100%"
          }
        },
        "26e7cdd427b84218bc6f6607863560ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27ad1f752d134db8b72f3522d27d7b62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28fb02af24ce458a8b2a15a7a52eeaab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba66772ade84fab8e0dfab71822a839": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f48abeb78e564a788799ec3dabb77de2",
              "IPY_MODEL_5026be8619184bcba4bcf45f663c7fa3",
              "IPY_MODEL_ddd45d1edcea402ca186f09656ffaa1c"
            ],
            "layout": "IPY_MODEL_511928fea5ab406cadf149e88d3a8ac7"
          }
        },
        "2e51747a456a495bb0fb05df47e5e8ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee149d1cdf947e4b2202136dc7d05a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b502424a9bcb4709a8dfa5adb99ebfa0",
              "IPY_MODEL_ee3936033c5d4d0cbe7a6604fd9537e1",
              "IPY_MODEL_6d3dca3c6a3447659b9704754162fee7"
            ],
            "layout": "IPY_MODEL_ea261aa99df64131b6764a1d45c4f8ab"
          }
        },
        "311a77b3e2394b25aae2d306604a358f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92ae1cdb1a3f4cfbab6d6af0ef8375cf",
            "placeholder": "​",
            "style": "IPY_MODEL_379904d0000b42e2a38a0bf983da0073",
            "value": " 1.60k/1.60k [00:00&lt;00:00, 155kB/s]"
          }
        },
        "319364b2a63d45b3896c9e874aa10c16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "323d1e2fe3b648e1b2c91f7e8412bb77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "328c1d20304948b18bf24fb86aede35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32ce043088a846bab906238f3215e7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36188ba445414141888bd4fbfa992ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "379904d0000b42e2a38a0bf983da0073": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a0d86b39da24a279de885f20e7bee38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fb33603007a4715a5188c876adbd835",
              "IPY_MODEL_9cf28078d4fe4b10bee00ec11249c109",
              "IPY_MODEL_ad2cb552503041709d21b18cf391d2ea"
            ],
            "layout": "IPY_MODEL_27ad1f752d134db8b72f3522d27d7b62"
          }
        },
        "3be28192135d47fcb1b6a729f30a268e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40c65782835742b98d1efbe92891d3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41fe29f4861e4b3e91761b4c68fb1179": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48b901cee33842029fe8be6d5954f9e6",
            "placeholder": "​",
            "style": "IPY_MODEL_151ed1673f4e4b7993a7c9211cbf7e1b",
            "value": " 570/570 [00:00&lt;00:00, 33.3kB/s]"
          }
        },
        "42d827b72aea448d8219ffe7bb921fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f00b685abaf4f89a5a9b451d0e32774",
              "IPY_MODEL_007249e062f1443d889d23932b234557",
              "IPY_MODEL_56557b9ef418434dae91ca177fd78d4b"
            ],
            "layout": "IPY_MODEL_ecca5ac4df0d4302b3f76829857c39de"
          }
        },
        "4463c417d7d144adb4ea048cacd80fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00d2d7c8a32042d59f455db492659fa8",
            "max": 291,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_825e5cc9e6624670a2e68765e9c872ec",
            "value": 291
          }
        },
        "47e04a35e17a4e34817e52faa1d38b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48b901cee33842029fe8be6d5954f9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "492acdc324f74447a839c0b4e9ba7204": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dd14bc5800842c0a02325db07a6828f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be2bc7d280144a0585d46aacfc878e3e",
            "placeholder": "​",
            "style": "IPY_MODEL_a3b9409e86bb4a95bea9758d0d2219b7",
            "value": " 440M/440M [00:07&lt;00:00, 70.4MB/s]"
          }
        },
        "4e85951aecb048688e251c1eb8aa8513": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5026be8619184bcba4bcf45f663c7fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1117e567fc274d14bfa7efc770cb923f",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b08e58c1f3424b87ae1bca7cc0b02918",
            "value": 466062
          }
        },
        "511928fea5ab406cadf149e88d3a8ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525e34fe0cb64b259816596458cd6783": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "526a34ce4884418da30ed8e1ec6c95e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56557b9ef418434dae91ca177fd78d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee765f009b9a4b948b55453dfe7bf29f",
            "placeholder": "​",
            "style": "IPY_MODEL_40c65782835742b98d1efbe92891d3a0",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.00kB/s]"
          }
        },
        "582f0f2655cc4a5996aab903b04575b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85bf0247df4c4dddb3c15b4f51997b9b",
              "IPY_MODEL_d6936089476e40a3b41545600cd657e8",
              "IPY_MODEL_aea5ec73bf134e60bc73beb4c6dac44c"
            ],
            "layout": "IPY_MODEL_6567241487384d88868f8da74ca84e19"
          }
        },
        "5c7a5700240b4c9397d8e0e6cb99db68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f00b685abaf4f89a5a9b451d0e32774": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaed34bc74f8487da826206b1013c8a4",
            "placeholder": "​",
            "style": "IPY_MODEL_259cf80ed17042cf911bdc53b88ed9a6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "5f80cf032dbb47e9b6cf2bbbcb120270": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "626f5fa3d87d49199eb451d089db33c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6567241487384d88868f8da74ca84e19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e6d84399584a4da3ce66bfac7b9d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8eec64c1b96d4050ac8a9b15595ceebc",
              "IPY_MODEL_9223a66867ea4b1686d1a343a516b445",
              "IPY_MODEL_311a77b3e2394b25aae2d306604a358f"
            ],
            "layout": "IPY_MODEL_d3b845da15864ea79be15c429b2149ac"
          }
        },
        "6bc3b947c6424c6e8b93a2a6698cb359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c5c537380c3430bbea71579912fab56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d3dca3c6a3447659b9704754162fee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ad9c3cdd3c49a6b7c3c541c83a47aa",
            "placeholder": "​",
            "style": "IPY_MODEL_6c5c537380c3430bbea71579912fab56",
            "value": " 85.0/85.0 [00:00&lt;00:00, 7.04kB/s]"
          }
        },
        "6eaa0759a6cc4abf8f90c02e241fc5d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71be055d24654f889ef716038c0d7a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75ad9c3cdd3c49a6b7c3c541c83a47aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76b98eba0fea4276b4106114459fe8ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "780649ebbfdd457da4a259304e76b1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79b17702bc1645eca397b3c4d256d86c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c373a821dd64c3fb86d89664f94babe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d0e0ca80dad44c29617f2c77ab22297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "825e5cc9e6624670a2e68765e9c872ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82c2814f62f143f9813a6bddbf275620": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85bf0247df4c4dddb3c15b4f51997b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef85fa48af17473a8dda483e47ebceea",
            "placeholder": "​",
            "style": "IPY_MODEL_86768e90e3544f149d8ab36417ed697c",
            "value": "vocab.txt: 100%"
          }
        },
        "8635cc72523d4f79b562d0c066840f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86768e90e3544f149d8ab36417ed697c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a4cf81841484d39927abf4e3ae2a0d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_264f958643dc460485a1e70be6e737da",
              "IPY_MODEL_04644ba96db34197a2ecd69763f9786a",
              "IPY_MODEL_af76f0c8d9894c5a8a49faefd2917da3"
            ],
            "layout": "IPY_MODEL_319364b2a63d45b3896c9e874aa10c16"
          }
        },
        "8eec64c1b96d4050ac8a9b15595ceebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_085c40ce31074421a5c82ce5de8ff7ae",
            "placeholder": "​",
            "style": "IPY_MODEL_3be28192135d47fcb1b6a729f30a268e",
            "value": "config.json: 100%"
          }
        },
        "8fb33603007a4715a5188c876adbd835": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_323d1e2fe3b648e1b2c91f7e8412bb77",
            "placeholder": "​",
            "style": "IPY_MODEL_780649ebbfdd457da4a259304e76b1e2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "90b26cb3a9e245549f2d7ee725b7199e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "922350dbab764457b66d0bb232379f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b226daa87ede4b45921d01d68303b598",
              "IPY_MODEL_4463c417d7d144adb4ea048cacd80fef",
              "IPY_MODEL_0c454637e4904ce2b2d8ea22479a2c76"
            ],
            "layout": "IPY_MODEL_82c2814f62f143f9813a6bddbf275620"
          }
        },
        "9223a66867ea4b1686d1a343a516b445": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12a86b5b5a0e4a2a836e7486dfed3dd2",
            "max": 1596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bc3b947c6424c6e8b93a2a6698cb359",
            "value": 1596
          }
        },
        "92ae1cdb1a3f4cfbab6d6af0ef8375cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94c51560b35744589e5c4afc484073f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cf28078d4fe4b10bee00ec11249c109": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df43fd5608d84b15907cbae7c1c0b903",
            "max": 163,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32ce043088a846bab906238f3215e7db",
            "value": 163
          }
        },
        "a3b9409e86bb4a95bea9758d0d2219b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9ba4ffe7d914dd2acd3e1dc66c2b3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_526a34ce4884418da30ed8e1ec6c95e5",
            "placeholder": "​",
            "style": "IPY_MODEL_c6ca8f17ba6a42898c6461b2d9de8601",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "ab9a6d44e29e4d488701b76a0642e602": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad2cb552503041709d21b18cf391d2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c993f549273647468ab53d084a72f3d6",
            "placeholder": "​",
            "style": "IPY_MODEL_ec91e010905c40ea89074c6e2109c043",
            "value": " 163/163 [00:00&lt;00:00, 10.6kB/s]"
          }
        },
        "aea5ec73bf134e60bc73beb4c6dac44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08de1c36f11840ada3a01fa309033172",
            "placeholder": "​",
            "style": "IPY_MODEL_c0c929813f87494786da47f737674130",
            "value": " 232k/232k [00:00&lt;00:00, 1.40MB/s]"
          }
        },
        "af76f0c8d9894c5a8a49faefd2917da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8635cc72523d4f79b562d0c066840f3c",
            "placeholder": "​",
            "style": "IPY_MODEL_47e04a35e17a4e34817e52faa1d38b45",
            "value": " 378M/378M [00:06&lt;00:00, 75.5MB/s]"
          }
        },
        "b08e58c1f3424b87ae1bca7cc0b02918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b226daa87ede4b45921d01d68303b598": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c7a5700240b4c9397d8e0e6cb99db68",
            "placeholder": "​",
            "style": "IPY_MODEL_b45ff45a35ec413681987a4961c47007",
            "value": "vocab.json: 100%"
          }
        },
        "b45ff45a35ec413681987a4961c47007": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b502424a9bcb4709a8dfa5adb99ebfa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79b17702bc1645eca397b3c4d256d86c",
            "placeholder": "​",
            "style": "IPY_MODEL_7d0e0ca80dad44c29617f2c77ab22297",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b976ffa9643a43b98f97cf337118a82c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36188ba445414141888bd4fbfa992ac3",
            "placeholder": "​",
            "style": "IPY_MODEL_ceeacc4c5f444c8a814555c934a26148",
            "value": "model.safetensors: 100%"
          }
        },
        "bafc0f56bde94361a55f7356cccff7e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be2bc7d280144a0585d46aacfc878e3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0c929813f87494786da47f737674130": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4c0e4ae6fac4ed181b60ae0676facab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6ca8f17ba6a42898c6461b2d9de8601": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c993f549273647468ab53d084a72f3d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceeacc4c5f444c8a814555c934a26148": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3b845da15864ea79be15c429b2149ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5b48d7520374a8fb2b22dd87a4407f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9ba4ffe7d914dd2acd3e1dc66c2b3d6",
              "IPY_MODEL_183d388405ab475ea18004de38ee0227",
              "IPY_MODEL_1cd03aa7a27048fd93df2ce4e77908dc"
            ],
            "layout": "IPY_MODEL_1bc67752d48946a994b28cdc0c1c3941"
          }
        },
        "d6936089476e40a3b41545600cd657e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dded59f4012e447a82f334d92598cec0",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb66ecf3fe1f40dc90c495baa2079349",
            "value": 231508
          }
        },
        "dd1bb15cc2bf41db8d66a15bc159bcd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd559c6175514656a90a7bf0f932217d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bafc0f56bde94361a55f7356cccff7e7",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71be055d24654f889ef716038c0d7a65",
            "value": 440449768
          }
        },
        "ddd45d1edcea402ca186f09656ffaa1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_626f5fa3d87d49199eb451d089db33c7",
            "placeholder": "​",
            "style": "IPY_MODEL_94c51560b35744589e5c4afc484073f9",
            "value": " 466k/466k [00:00&lt;00:00, 5.90MB/s]"
          }
        },
        "dded59f4012e447a82f334d92598cec0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df43fd5608d84b15907cbae7c1c0b903": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ee293d041944dc9128c1968cbb14b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e51747a456a495bb0fb05df47e5e8ce",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_328c1d20304948b18bf24fb86aede35c",
            "value": 570
          }
        },
        "ea261aa99df64131b6764a1d45c4f8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaed34bc74f8487da826206b1013c8a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb66ecf3fe1f40dc90c495baa2079349": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebf86f2106cb4e33810c83fad03d416c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b976ffa9643a43b98f97cf337118a82c",
              "IPY_MODEL_dd559c6175514656a90a7bf0f932217d",
              "IPY_MODEL_4dd14bc5800842c0a02325db07a6828f"
            ],
            "layout": "IPY_MODEL_086dc534062b4474a1f1ae78870ff707"
          }
        },
        "ec91e010905c40ea89074c6e2109c043": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecca5ac4df0d4302b3f76829857c39de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee3936033c5d4d0cbe7a6604fd9537e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e85951aecb048688e251c1eb8aa8513",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90b26cb3a9e245549f2d7ee725b7199e",
            "value": 85
          }
        },
        "ee765f009b9a4b948b55453dfe7bf29f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef85fa48af17473a8dda483e47ebceea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f379255f4397418caf8704114c864e2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f48abeb78e564a788799ec3dabb77de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_525e34fe0cb64b259816596458cd6783",
            "placeholder": "​",
            "style": "IPY_MODEL_c4c0e4ae6fac4ed181b60ae0676facab",
            "value": "tokenizer.json: 100%"
          }
        },
        "f812dfe6009c48d8b762fcfe642e5cda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_218a0a92bfbe4b318a4ef81016ddb0c4",
              "IPY_MODEL_e4ee293d041944dc9128c1968cbb14b7",
              "IPY_MODEL_41fe29f4861e4b3e91761b4c68fb1179"
            ],
            "layout": "IPY_MODEL_f379255f4397418caf8704114c864e2b"
          }
        },
        "fbbcf58b18614fe896e6566607e4ecf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcffb97fb1d44f979241d3e634cd7e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}