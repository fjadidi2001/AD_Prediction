{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/Feature_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install required libraries"
      ],
      "metadata": {
        "id": "X7cgR7FO3HGX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ADtkg8rxJ9q",
        "outputId": "8e5f9d43-a5b8-4e79-e36b-15b8fde58324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Collecting opensmile\n",
            "  Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
            "Collecting speechbrain\n",
            "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Collecting audobject>=0.6.1 (from opensmile)\n",
            "  Downloading audobject-0.7.11-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting audinterface>=0.7.0 (from opensmile)\n",
            "  Downloading audinterface-1.3.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.32.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Collecting audeer>=2.1.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audeer-2.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audformat-1.3.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting audiofile>=1.3.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audiofile-1.5.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting audmath>=1.4.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audmath-1.4.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (8.7.0)\n",
            "Collecting oyaml (from audobject>=0.6.1->opensmile)\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain) (1.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.12-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting iso639-lang (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso639_lang-2.6.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (18.1.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.22.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.17.0)\n",
            "Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl (996 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.0/996.0 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audinterface-1.3.1-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audobject-0.7.11-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading audeer-2.2.1-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audformat-1.3.2-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audiofile-1.5.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audmath-1.4.1-py3-none-any.whl (23 kB)\n",
            "Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.12-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.4/118.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading iso639_lang-2.6.0-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803404 sha256=e95e6209a758e184bb1480ce18b05f83b3d3cea2c83e509a8c75b5e37ea555f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: ruamel.yaml.clib, oyaml, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, iso639-lang, iso3166, audresample, audmath, audeer, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, audobject, nvidia-cusolver-cu12, hyperpyyaml, audiofile, audformat, openai-whisper, audinterface, speechbrain, opensmile\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed audeer-2.2.1 audformat-1.3.2 audinterface-1.3.1 audiofile-1.5.1 audmath-1.4.1 audobject-0.7.11 audresample-1.3.3 hyperpyyaml-1.2.2 iso3166-2.1.1 iso639-lang-2.6.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 opensmile-2.5.1 oyaml-1.0 ruamel.yaml-0.18.12 ruamel.yaml.clib-0.2.12 speechbrain-1.0.3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa soundfile opensmile speechbrain transformers torch openai-whisper\n",
        "!pip install pandas numpy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount to Google Drive"
      ],
      "metadata": {
        "id": "lTPwrA5i3Wfg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHcrv0EN3muX",
        "outputId": "c8d158e6-4e8a-4814-d79f-ce87e0988e61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADReSSoAnalyzer"
      ],
      "metadata": {
        "id": "WrkxMgd53v8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import json\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import opensmile\n",
        "import torch\n",
        "import whisper\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2Model, BertTokenizer, BertModel\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "pJZObdjoWoEy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s1102hd7BjhZ"
      },
      "outputs": [],
      "source": [
        "class ADReSSoAnalyzer:\n",
        "    def __init__(self, base_path=\"/content/drive/MyDrive/Voice/extracted/ADReSSo21\"):\n",
        "        self.base_path = base_path\n",
        "        self.output_path = \"/content\"\n",
        "        self.features = {}\n",
        "        self.transcripts = {}\n",
        "\n",
        "        # Initialize feature extractors\n",
        "        self.smile = opensmile.Smile(\n",
        "            feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "            feature_level=opensmile.FeatureLevel.Functionals,\n",
        "        )\n",
        "\n",
        "        # Initialize Whisper for transcription\n",
        "        self.whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "        # Initialize Wav2Vec2\n",
        "        self.wav2vec_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "        self.wav2vec_model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "        # Initialize BERT\n",
        "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def get_audio_files(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"Get all audio files from the dataset\"\"\"\n",
        "        audio_files = {\n",
        "            'diagnosis_ad': [],\n",
        "            'diagnosis_cn': [],\n",
        "            'progression_decline': [],\n",
        "            'progression_no_decline': [],\n",
        "            'progression_test': []\n",
        "        }\n",
        "\n",
        "        # Diagnosis files\n",
        "        diag_ad_path = f\"{self.base_path}/diagnosis/train/audio/ad\"\n",
        "        diag_cn_path = f\"{self.base_path}/diagnosis/train/audio/cn\"\n",
        "\n",
        "        if os.path.exists(diag_ad_path):\n",
        "            audio_files['diagnosis_ad'] = [f\"{diag_ad_path}/{f}\" for f in os.listdir(diag_ad_path) if f.endswith('.wav')]\n",
        "        if os.path.exists(diag_cn_path):\n",
        "            audio_files['diagnosis_cn'] = [f\"{diag_cn_path}/{f}\" for f in os.listdir(diag_cn_path) if f.endswith('.wav')]\n",
        "\n",
        "        # Progression files\n",
        "        prog_decline_path = f\"{self.base_path}/progression/train/audio/decline\"\n",
        "        prog_no_decline_path = f\"{self.base_path}/progression/train/audio/no_decline\"\n",
        "        prog_test_path = f\"{self.base_path}/progression/test-dist/audio\"\n",
        "\n",
        "        if os.path.exists(prog_decline_path):\n",
        "            audio_files['progression_decline'] = [f\"{prog_decline_path}/{f}\" for f in os.listdir(prog_decline_path) if f.endswith('.wav')]\n",
        "        if os.path.exists(prog_no_decline_path):\n",
        "            audio_files['progression_no_decline'] = [f\"{prog_no_decline_path}/{f}\" for f in os.listdir(prog_no_decline_path) if f.endswith('.wav')]\n",
        "        if os.path.exists(prog_test_path):\n",
        "            audio_files['progression_test'] = [f\"{prog_test_path}/{f}\" for f in os.listdir(prog_test_path) if f.endswith('.wav')]\n",
        "\n",
        "        return audio_files\n",
        "\n",
        "    def extract_acoustic_features(self, audio_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Extract all acoustic features from audio file\"\"\"\n",
        "        features = {}\n",
        "\n",
        "        try:\n",
        "            # Load audio - resample to 16kHz for Wav2Vec2 compatibility\n",
        "            y, sr = librosa.load(audio_path, sr=16000)  # Force 16kHz sampling rate\n",
        "\n",
        "            # 1. eGeMAPS features using openSMILE\n",
        "            try:\n",
        "                features['egemaps'] = self.smile.process_file(audio_path).values.flatten()\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: eGeMAPS extraction failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['egemaps'] = np.zeros(88)  # Default eGeMAPS feature size\n",
        "\n",
        "            # 2. MFCC features\n",
        "            try:\n",
        "                mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "                features['mfccs'] = {\n",
        "                    'mean': np.mean(mfccs, axis=1),\n",
        "                    'std': np.std(mfccs, axis=1),\n",
        "                    'delta': np.mean(librosa.feature.delta(mfccs), axis=1),\n",
        "                    'delta2': np.mean(librosa.feature.delta(mfccs, order=2), axis=1)\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: MFCC extraction failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['mfccs'] = {\n",
        "                    'mean': np.zeros(13),\n",
        "                    'std': np.zeros(13),\n",
        "                    'delta': np.zeros(13),\n",
        "                    'delta2': np.zeros(13)\n",
        "                }\n",
        "\n",
        "            # 3. Log-mel spectrogram\n",
        "            try:\n",
        "                mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80)\n",
        "                log_mel = librosa.power_to_db(mel_spec)\n",
        "                features['log_mel'] = {\n",
        "                    'mean': np.mean(log_mel, axis=1),\n",
        "                    'std': np.std(log_mel, axis=1)\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: Log-mel extraction failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['log_mel'] = {\n",
        "                    'mean': np.zeros(80),\n",
        "                    'std': np.zeros(80)\n",
        "                }\n",
        "\n",
        "            # 4. Wav2Vec2 features - with proper sampling rate handling\n",
        "            try:\n",
        "                # Ensure sampling rate is exactly 16000 Hz for Wav2Vec2\n",
        "                if len(y) == 0:\n",
        "                    raise ValueError(\"Empty audio signal\")\n",
        "\n",
        "                input_values = self.wav2vec_processor(\n",
        "                    y,\n",
        "                    sampling_rate=16000,  # Explicitly set to 16000\n",
        "                    return_tensors=\"pt\"\n",
        "                ).input_values\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    wav2vec_features = self.wav2vec_model(input_values).last_hidden_state\n",
        "                features['wav2vec2'] = torch.mean(wav2vec_features, dim=1).squeeze().numpy()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: Wav2Vec2 extraction failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['wav2vec2'] = np.zeros(768)  # Default Wav2Vec2 feature size\n",
        "\n",
        "            # 5. Additional prosodic features\n",
        "            try:\n",
        "                # Handle potential issues with F0 extraction\n",
        "                f0 = librosa.yin(y, fmin=50, fmax=300, sr=sr)\n",
        "                f0_clean = f0[f0 > 0]  # Remove unvoiced frames\n",
        "\n",
        "                features['prosodic'] = {\n",
        "                    'f0_mean': np.mean(f0_clean) if len(f0_clean) > 0 else 0.0,\n",
        "                    'f0_std': np.std(f0_clean) if len(f0_clean) > 0 else 0.0,\n",
        "                    'energy_mean': np.mean(librosa.feature.rms(y=y)),\n",
        "                    'energy_std': np.std(librosa.feature.rms(y=y)),\n",
        "                    'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(y)),\n",
        "                    'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
        "                    'spectral_rolloff': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),\n",
        "                    'duration': len(y) / sr\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: Prosodic feature extraction failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['prosodic'] = {\n",
        "                    'f0_mean': 0.0, 'f0_std': 0.0, 'energy_mean': 0.0, 'energy_std': 0.0,\n",
        "                    'zero_crossing_rate': 0.0, 'spectral_centroid': 0.0, 'spectral_rolloff': 0.0,\n",
        "                    'duration': 0.0\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {audio_path}: {str(e)}\")\n",
        "            features = None\n",
        "\n",
        "        return features\n",
        "\n",
        "    def show_acoustic_features(self, sample_file: str):\n",
        "        \"\"\"Display acoustic features for a sample file\"\"\"\n",
        "        features = self.extract_acoustic_features(sample_file)\n",
        "\n",
        "        if features is None:\n",
        "            print(f\"Could not extract features from {sample_file}\")\n",
        "            return\n",
        "\n",
        "        print(f\"=== Acoustic Features for {os.path.basename(sample_file)} ===\\n\")\n",
        "\n",
        "        # eGeMAPS\n",
        "        print(f\"1. eGeMAPS Features: {len(features['egemaps'])} features\")\n",
        "        print(f\"   Shape: {features['egemaps'].shape}\")\n",
        "        print(f\"   Sample values: {features['egemaps'][:5]}\")\n",
        "        print()\n",
        "\n",
        "        # MFCCs\n",
        "        print(\"2. MFCC Features:\")\n",
        "        print(f\"   Mean: {features['mfccs']['mean'].shape} - {features['mfccs']['mean'][:5]}\")\n",
        "        print(f\"   Std: {features['mfccs']['std'].shape} - {features['mfccs']['std'][:5]}\")\n",
        "        print(f\"   Delta: {features['mfccs']['delta'].shape} - {features['mfccs']['delta'][:5]}\")\n",
        "        print(f\"   Delta-Delta: {features['mfccs']['delta2'].shape} - {features['mfccs']['delta2'][:5]}\")\n",
        "        print()\n",
        "\n",
        "        # Log-mel\n",
        "        print(\"3. Log-Mel Spectrogram Features:\")\n",
        "        print(f\"   Mean: {features['log_mel']['mean'].shape} - {features['log_mel']['mean'][:5]}\")\n",
        "        print(f\"   Std: {features['log_mel']['std'].shape} - {features['log_mel']['std'][:5]}\")\n",
        "        print()\n",
        "\n",
        "        # Wav2Vec2\n",
        "        print(f\"4. Wav2Vec2 Features: {features['wav2vec2'].shape}\")\n",
        "        print(f\"   Sample values: {features['wav2vec2'][:5]}\")\n",
        "        print()\n",
        "\n",
        "        # Prosodic\n",
        "        print(\"5. Prosodic Features:\")\n",
        "        for key, value in features['prosodic'].items():\n",
        "            print(f\"   {key}: {value:.4f}\")\n",
        "        print()\n",
        "\n",
        "    def extract_transcripts(self, audio_files: Dict[str, List[str]]) -> Dict[str, str]:\n",
        "        \"\"\"Extract transcripts using Whisper\"\"\"\n",
        "        transcripts = {}\n",
        "\n",
        "        print(\"Extracting transcripts...\")\n",
        "\n",
        "        for category, files in audio_files.items():\n",
        "            print(f\"\\nProcessing {category}...\")\n",
        "            for file_path in files:\n",
        "                try:\n",
        "                    filename = os.path.basename(file_path)\n",
        "                    print(f\"  Transcribing {filename}...\")\n",
        "\n",
        "                    result = self.whisper_model.transcribe(file_path)\n",
        "                    transcript_text = result[\"text\"].strip()\n",
        "\n",
        "                    transcripts[f\"{category}_{filename}\"] = {\n",
        "                        'file_path': file_path,\n",
        "                        'category': category,\n",
        "                        'filename': filename,\n",
        "                        'transcript': transcript_text,\n",
        "                        'language': result.get('language', 'en'),\n",
        "                        'segments': len(result.get('segments', []))\n",
        "                    }\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"    Error transcribing {filename}: {str(e)}\")\n",
        "                    transcripts[f\"{category}_{filename}\"] = {\n",
        "                        'file_path': file_path,\n",
        "                        'category': category,\n",
        "                        'filename': filename,\n",
        "                        'transcript': \"\",\n",
        "                        'error': str(e)\n",
        "                    }\n",
        "\n",
        "        return transcripts\n",
        "\n",
        "    def save_transcripts(self, transcripts: Dict[str, str]):\n",
        "        \"\"\"Save transcripts to files\"\"\"\n",
        "        os.makedirs(f\"{self.output_path}/transcripts\", exist_ok=True)\n",
        "\n",
        "        # Save individual transcript files\n",
        "        for key, data in transcripts.items():\n",
        "            filename = f\"{key}_transcript.txt\"\n",
        "            filepath = f\"{self.output_path}/transcripts/{filename}\"\n",
        "\n",
        "            with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                f.write(data['transcript'])\n",
        "\n",
        "        # Save consolidated JSON\n",
        "        with open(f\"{self.output_path}/transcripts/all_transcripts.json\", 'w', encoding='utf-8') as f:\n",
        "            json.dump(transcripts, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        # Save as pickle for easy loading\n",
        "        with open(f\"{self.output_path}/transcripts/transcripts.pkl\", 'wb') as f:\n",
        "            pickle.dump(transcripts, f)\n",
        "\n",
        "        print(f\"Transcripts saved to {self.output_path}/transcripts/\")\n",
        "\n",
        "    def create_transcript_table(self, transcripts: Dict[str, str]) -> pd.DataFrame:\n",
        "        \"\"\"Create a DataFrame with transcript information\"\"\"\n",
        "        data = []\n",
        "\n",
        "        for key, info in transcripts.items():\n",
        "            data.append({\n",
        "                'File_ID': key,\n",
        "                'Category': info['category'],\n",
        "                'Filename': info['filename'],\n",
        "                'Transcript_Length': len(info['transcript']),\n",
        "                'Word_Count': len(info['transcript'].split()) if info['transcript'] else 0,\n",
        "                'Language': info.get('language', 'N/A'),\n",
        "                'Segments': info.get('segments', 'N/A'),\n",
        "                'Has_Error': 'error' in info,\n",
        "                'Transcript_Preview': info['transcript'][:100] + \"...\" if len(info['transcript']) > 100 else info['transcript']\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # Save the table\n",
        "        df.to_csv(f\"{self.output_path}/transcript_summary.csv\", index=False)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def extract_linguistic_features(self, transcripts: Dict[str, str]) -> Dict[str, Any]:\n",
        "        \"\"\"Extract linguistic features for BERT preparation\"\"\"\n",
        "        linguistic_features = {}\n",
        "\n",
        "        print(\"Extracting linguistic features...\")\n",
        "\n",
        "        for key, data in transcripts.items():\n",
        "            transcript = data['transcript']\n",
        "\n",
        "            if not transcript:\n",
        "                linguistic_features[key] = {\n",
        "                    'raw_text': '',\n",
        "                    'word_count': 0,\n",
        "                    'sentence_count': 0,\n",
        "                    'avg_word_length': 0,\n",
        "                    'bert_tokens': [],\n",
        "                    'bert_input_ids': [],\n",
        "                    'bert_attention_mask': []\n",
        "                }\n",
        "                continue\n",
        "\n",
        "            # Basic linguistic features\n",
        "            words = transcript.split()\n",
        "            sentences = transcript.split('.')\n",
        "\n",
        "            # BERT tokenization\n",
        "            bert_encoding = self.bert_tokenizer(\n",
        "                transcript,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=512,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            linguistic_features[key] = {\n",
        "                'raw_text': transcript,\n",
        "                'word_count': len(words),\n",
        "                'sentence_count': len([s for s in sentences if s.strip()]),\n",
        "                'avg_word_length': np.mean([len(word) for word in words]) if words else 0,\n",
        "                'unique_words': len(set(words)),\n",
        "                'lexical_diversity': len(set(words)) / len(words) if words else 0,\n",
        "                'bert_tokens': self.bert_tokenizer.tokenize(transcript),\n",
        "                'bert_input_ids': bert_encoding['input_ids'].squeeze().tolist(),\n",
        "                'bert_attention_mask': bert_encoding['attention_mask'].squeeze().tolist(),\n",
        "                'bert_encoding': bert_encoding\n",
        "            }\n",
        "\n",
        "        # Save linguistic features\n",
        "        with open(f\"{self.output_path}/linguistic_features.pkl\", 'wb') as f:\n",
        "            pickle.dump(linguistic_features, f)\n",
        "\n",
        "        return linguistic_features\n",
        "\n",
        "    def run_complete_pipeline(self):\n",
        "        \"\"\"Run the complete analysis pipeline\"\"\"\n",
        "        print(\"=== ADReSSo21 Speech Analysis Pipeline ===\\n\")\n",
        "\n",
        "        # Step 0: Get audio files\n",
        "        print(\"Step 0: Getting audio files...\")\n",
        "        audio_files = self.get_audio_files()\n",
        "\n",
        "        total_files = sum(len(files) for files in audio_files.values())\n",
        "        print(f\"Found {total_files} audio files across all categories\")\n",
        "\n",
        "        for category, files in audio_files.items():\n",
        "            print(f\"  {category}: {len(files)} files\")\n",
        "\n",
        "        if total_files == 0:\n",
        "            print(\"No audio files found. Please check the dataset path.\")\n",
        "            return\n",
        "\n",
        "        # Step 1: Show acoustic features for sample files\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Step 1: Demonstrating acoustic features...\")\n",
        "\n",
        "        # Show features for one file from each category that has files\n",
        "        for category, files in audio_files.items():\n",
        "            if files:\n",
        "                print(f\"\\nShowing features for {category}:\")\n",
        "                self.show_acoustic_features(files[0])\n",
        "                break  # Just show one example to avoid too much output\n",
        "\n",
        "        # Step 2: Extract transcripts\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Step 2: Extracting transcripts...\")\n",
        "        transcripts = self.extract_transcripts(audio_files)\n",
        "\n",
        "        # Step 3: Save transcripts\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Step 3: Saving transcripts...\")\n",
        "        self.save_transcripts(transcripts)\n",
        "\n",
        "        # Step 4: Create transcript table\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Step 4: Creating transcript table...\")\n",
        "        transcript_df = self.create_transcript_table(transcripts)\n",
        "\n",
        "        print(\"Transcript Summary Table:\")\n",
        "        print(transcript_df.to_string(index=False))\n",
        "\n",
        "        # Step 5: Extract linguistic features for BERT\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Step 5: Extracting linguistic features for BERT...\")\n",
        "        linguistic_features = self.extract_linguistic_features(transcripts)\n",
        "\n",
        "        print(\"\\nPipeline completed successfully!\")\n",
        "        print(f\"Results saved to: {self.output_path}\")\n",
        "        print(\"\\nOutput files:\")\n",
        "        print(f\"  - Transcripts: {self.output_path}/transcripts/\")\n",
        "        print(f\"  - Transcript summary: {self.output_path}/transcript_summary.csv\")\n",
        "        print(f\"  - Linguistic features: {self.output_path}/linguistic_features.pkl\")\n",
        "\n",
        "        return {\n",
        "            'audio_files': audio_files,\n",
        "            'transcripts': transcripts,\n",
        "            'transcript_df': transcript_df,\n",
        "            'linguistic_features': linguistic_features\n",
        "        }\n",
        "\n",
        "# # Usage example\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Initialize analyzer\n",
        "#     analyzer = ADReSSoAnalyzer()\n",
        "\n",
        "#     # Run complete pipeline\n",
        "#     results = analyzer.run_complete_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6HXS8QyIcym",
        "outputId": "307f69cc-0e5a-4239-c910-3635ccf5c212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture"
      ],
      "metadata": {
        "id": "M_6qNR5k5O8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
        "from torch_geometric.data import Data, Batch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import networkx as nx\n",
        "from transformers import BertModel\n",
        "import pickle\n",
        "import json\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class GraphAttentionModule(nn.Module):\n",
        "    \"\"\"Graph-based attention module for semantic relationships\"\"\"\n",
        "    def __init__(self, input_dim=768, hidden_dim=256, num_heads=8, num_layers=3):\n",
        "        super(GraphAttentionModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # Graph attention layers\n",
        "        self.gat_layers = nn.ModuleList([\n",
        "            GATConv(input_dim if i == 0 else hidden_dim,\n",
        "                   hidden_dim, heads=num_heads, dropout=0.2)\n",
        "            for i in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Final projection\n",
        "        self.projection = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x, edge_index, batch=None):\n",
        "        # Apply GAT layers\n",
        "        for i, gat_layer in enumerate(self.gat_layers):\n",
        "            x = gat_layer(x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        # Global pooling if batch is provided\n",
        "        if batch is not None:\n",
        "            x = global_mean_pool(x, batch)\n",
        "        else:\n",
        "            x = torch.mean(x, dim=0, keepdim=True)\n",
        "\n",
        "        return self.projection(x)\n",
        "\n",
        "class VisionTransformerModule(nn.Module):\n",
        "    \"\"\"Vision Transformer for processing spectrograms\"\"\"\n",
        "    def __init__(self, input_dim=80, patch_size=8, embed_dim=768, num_heads=12, num_layers=6):\n",
        "        super(VisionTransformerModule, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # Patch embedding\n",
        "        self.patch_embed = nn.Conv2d(1, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.pos_embed = nn.Parameter(torch.randn(1, 1000, embed_dim))  # Max patches\n",
        "\n",
        "        # Transformer layers\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim, nhead=num_heads, dim_feedforward=embed_dim*4,\n",
        "            dropout=0.1, activation='gelu'\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Linear(embed_dim, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, channels, height, width)\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        # Create patches\n",
        "        x = self.patch_embed(x)  # (B, embed_dim, H', W')\n",
        "        x = x.flatten(2).transpose(1, 2)  # (B, num_patches, embed_dim)\n",
        "\n",
        "        # Add positional encoding\n",
        "        num_patches = x.shape[1]\n",
        "        x = x + self.pos_embed[:, :num_patches, :]\n",
        "\n",
        "        # Apply transformer\n",
        "        x = x.transpose(0, 1)  # (num_patches, B, embed_dim)\n",
        "        x = self.transformer(x)\n",
        "        x = x.transpose(0, 1)  # (B, num_patches, embed_dim)\n",
        "\n",
        "        # Global average pooling\n",
        "        x = torch.mean(x, dim=1)  # (B, embed_dim)\n",
        "\n",
        "        return self.classifier(x)\n",
        "\n",
        "class UNetModule(nn.Module):\n",
        "    \"\"\"U-Net for audio feature processing\"\"\"\n",
        "    def __init__(self, in_channels=1, out_channels=128):\n",
        "        super(UNetModule, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = self.conv_block(in_channels, 64)\n",
        "        self.enc2 = self.conv_block(64, 128)\n",
        "        self.enc3 = self.conv_block(128, 256)\n",
        "        self.enc4 = self.conv_block(256, 512)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = self.conv_block(512, 1024)\n",
        "\n",
        "        # Decoder\n",
        "        self.dec4 = self.upconv_block(1024, 512)\n",
        "        self.dec3 = self.upconv_block(512, 256)\n",
        "        self.dec2 = self.upconv_block(256, 128)\n",
        "        self.dec1 = self.upconv_block(128, 64)\n",
        "\n",
        "        # Final layer\n",
        "        self.final = nn.Conv1d(64, out_channels, kernel_size=1)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "    def conv_block(self, in_ch, out_ch):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv1d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def upconv_block(self, in_ch, out_ch):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose1d(in_ch, out_ch, kernel_size=2, stride=2),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(F.max_pool1d(e1, 2))\n",
        "        e3 = self.enc3(F.max_pool1d(e2, 2))\n",
        "        e4 = self.enc4(F.max_pool1d(e3, 2))\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(F.max_pool1d(e4, 2))\n",
        "\n",
        "        # Decoder\n",
        "        d4 = self.dec4(b)\n",
        "        d3 = self.dec3(d4)\n",
        "        d2 = self.dec2(d3)\n",
        "        d1 = self.dec1(d2)\n",
        "\n",
        "        # Final\n",
        "        out = self.final(d1)\n",
        "        out = self.pool(out).squeeze(-1)  # Global average pooling\n",
        "\n",
        "        return out\n",
        "\n",
        "class AlexNetModule(nn.Module):\n",
        "    \"\"\"Modified AlexNet for feature extraction\"\"\"\n",
        "    def __init__(self, input_dim=768, num_classes=256):\n",
        "        super(AlexNetModule, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Linear(input_dim, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(2048, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "class MultiModalADReSSoModel(nn.Module):\n",
        "    \"\"\"Complete multi-modal architecture\"\"\"\n",
        "    def __init__(self,\n",
        "                 audio_feature_dim=768,\n",
        "                 text_feature_dim=768,\n",
        "                 spectrogram_height=80,\n",
        "                 num_classes=2):\n",
        "        super(MultiModalADReSSoModel, self).__init__()\n",
        "\n",
        "        # Initialize modules\n",
        "        self.graph_attention = GraphAttentionModule(input_dim=text_feature_dim)\n",
        "        self.vision_transformer = VisionTransformerModule(input_dim=spectrogram_height)\n",
        "        self.unet = UNetModule()\n",
        "        self.alexnet = AlexNetModule(input_dim=audio_feature_dim)\n",
        "\n",
        "        # BERT for text processing\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Fusion layers\n",
        "        self.fusion_layer = nn.Sequential(\n",
        "            nn.Linear(256 + 256 + 128 + 256, 512),  # Graph + ViT + UNet + AlexNet\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # Final classifier\n",
        "        self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "    def create_semantic_graph(self, text_features, audio_features):\n",
        "        \"\"\"Create semantic relationship graph between audio and text\"\"\"\n",
        "        batch_size = text_features.shape[0]\n",
        "        graphs = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            # Compute similarity matrix\n",
        "            text_feat = text_features[i].unsqueeze(0)  # (1, dim)\n",
        "            audio_feat = audio_features[i].unsqueeze(0)  # (1, dim)\n",
        "\n",
        "            # Create nodes (text + audio features)\n",
        "            node_features = torch.cat([text_feat, audio_feat], dim=0)  # (2, dim)\n",
        "\n",
        "            # Create edges based on similarity\n",
        "            similarity = F.cosine_similarity(text_feat, audio_feat, dim=1)\n",
        "\n",
        "            # Create bidirectional edges if similarity > threshold\n",
        "            if similarity.item() > 0.1:\n",
        "                edge_index = torch.tensor([[0, 1], [1, 0]], dtype=torch.long).t()\n",
        "            else:\n",
        "                # Self-loops only\n",
        "                edge_index = torch.tensor([[0, 1], [0, 1]], dtype=torch.long).t()\n",
        "\n",
        "            graph = Data(x=node_features, edge_index=edge_index)\n",
        "            graphs.append(graph)\n",
        "\n",
        "        return Batch.from_data_list(graphs)\n",
        "\n",
        "    def forward(self, audio_features, text_input_ids, text_attention_mask, spectrograms):\n",
        "        batch_size = audio_features.shape[0]\n",
        "\n",
        "        # Process text with BERT\n",
        "        bert_outputs = self.bert(input_ids=text_input_ids, attention_mask=text_attention_mask)\n",
        "        text_features = bert_outputs.last_hidden_state.mean(dim=1)  # (batch_size, 768)\n",
        "\n",
        "        # Create semantic graph\n",
        "        graph_batch = self.create_semantic_graph(text_features, audio_features)\n",
        "\n",
        "        # Process through different modules\n",
        "        graph_out = self.graph_attention(graph_batch.x, graph_batch.edge_index, graph_batch.batch)\n",
        "        vit_out = self.vision_transformer(spectrograms)\n",
        "\n",
        "        # Prepare audio for U-Net (add channel dimension)\n",
        "        audio_1d = audio_features.unsqueeze(1)  # (batch_size, 1, features)\n",
        "        unet_out = self.unet(audio_1d)\n",
        "\n",
        "        alexnet_out = self.alexnet(audio_features)\n",
        "\n",
        "        # Fusion\n",
        "        fused_features = torch.cat([graph_out, vit_out, unet_out, alexnet_out], dim=1)\n",
        "        fused_features = self.fusion_layer(fused_features)\n",
        "\n",
        "        # Final classification\n",
        "        output = self.classifier(fused_features)\n",
        "\n",
        "        return output\n",
        "\n",
        "class ADReSSoDataset(Dataset):\n",
        "    \"\"\"Dataset class for ADReSSo data\"\"\"\n",
        "    def __init__(self, features_dict, linguistic_features, labels, transform=None):\n",
        "        self.features_dict = features_dict\n",
        "        self.linguistic_features = linguistic_features\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.file_ids = list(features_dict.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_id = self.file_ids[idx]\n",
        "\n",
        "        # Get features\n",
        "        features = self.features_dict[file_id]\n",
        "        linguistic = self.linguistic_features[file_id]\n",
        "\n",
        "        # Prepare audio features (Wav2Vec2)\n",
        "        audio_features = torch.FloatTensor(features['wav2vec2'])\n",
        "\n",
        "        # Prepare text features\n",
        "        text_input_ids = torch.LongTensor(linguistic['bert_input_ids'])\n",
        "        text_attention_mask = torch.LongTensor(linguistic['bert_attention_mask'])\n",
        "\n",
        "        # Prepare spectrogram (create from log-mel features)\n",
        "        log_mel_mean = features['log_mel']['mean']\n",
        "        log_mel_std = features['log_mel']['std']\n",
        "        spectrogram = np.stack([log_mel_mean, log_mel_std])  # (2, 80)\n",
        "        spectrogram = np.expand_dims(spectrogram.mean(axis=0), axis=0)  # (1, 80)\n",
        "        spectrogram = np.tile(spectrogram, (1, 1, 80))  # (1, 80, 80) - square image\n",
        "        spectrogram = torch.FloatTensor(spectrogram)\n",
        "\n",
        "        label = torch.LongTensor([self.labels[file_id]])\n",
        "\n",
        "        return {\n",
        "            'audio_features': audio_features,\n",
        "            'text_input_ids': text_input_ids,\n",
        "            'text_attention_mask': text_attention_mask,\n",
        "            'spectrogram': spectrogram,\n",
        "            'label': label,\n",
        "            'file_id': file_id\n",
        "        }\n",
        "\n",
        "class ADReSSoTrainer:\n",
        "    \"\"\"Training and evaluation class\"\"\"\n",
        "    def __init__(self, model, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer, mode='min', factor=0.5, patience=5\n",
        "        )\n",
        "\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.train_accuracies = []\n",
        "        self.val_accuracies = []\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            # Move to device\n",
        "            audio_features = batch['audio_features'].to(self.device)\n",
        "            text_input_ids = batch['text_input_ids'].to(self.device)\n",
        "            text_attention_mask = batch['text_attention_mask'].to(self.device)\n",
        "            spectrograms = batch['spectrogram'].to(self.device)\n",
        "            labels = batch['label'].squeeze().to(self.device)\n",
        "\n",
        "            # Forward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(audio_features, text_input_ids, text_attention_mask, spectrograms)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        accuracy = 100. * correct / total\n",
        "\n",
        "        return avg_loss, accuracy\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                # Move to device\n",
        "                audio_features = batch['audio_features'].to(self.device)\n",
        "                text_input_ids = batch['text_input_ids'].to(self.device)\n",
        "                text_attention_mask = batch['text_attention_mask'].to(self.device)\n",
        "                spectrograms = batch['spectrogram'].to(self.device)\n",
        "                labels = batch['label'].squeeze().to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(audio_features, text_input_ids, text_attention_mask, spectrograms)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "                # Statistics\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                # Store for detailed metrics\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probs.extend(F.softmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "        avg_loss = total_loss / len(val_loader)\n",
        "        accuracy = 100. * correct / total\n",
        "\n",
        "        return avg_loss, accuracy, all_preds, all_labels, all_probs\n",
        "\n",
        "    def train(self, train_loader, val_loader, num_epochs=5):\n",
        "        print(f\"Training on {self.device}\")\n",
        "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
        "\n",
        "        best_val_acc = 0\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "            print('-' * 50)\n",
        "\n",
        "            # Training\n",
        "            train_loss, train_acc = self.train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "            self.train_accuracies.append(train_acc)\n",
        "\n",
        "            # Validation\n",
        "            val_loss, val_acc, val_preds, val_labels, val_probs = self.validate(val_loader)\n",
        "            self.val_losses.append(val_loss)\n",
        "            self.val_accuracies.append(val_acc)\n",
        "\n",
        "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "            # Learning rate scheduling\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping and model saving\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                torch.save(self.model.state_dict(), 'best_adresso_model.pth')\n",
        "                patience_counter = 0\n",
        "                print(f'New best validation accuracy: {best_val_acc:.2f}%')\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= 10:\n",
        "                    print('Early stopping triggered')\n",
        "                    break\n",
        "\n",
        "        print(f'\\nTraining completed. Best validation accuracy: {best_val_acc:.2f}%')\n",
        "\n",
        "    def evaluate_detailed(self, test_loader, class_names=['CN', 'AD']):\n",
        "        \"\"\"Detailed evaluation with metrics and visualizations\"\"\"\n",
        "        self.model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "        all_file_ids = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # Move to device\n",
        "                audio_features = batch['audio_features'].to(self.device)\n",
        "                text_input_ids = batch['text_input_ids'].to(self.device)\n",
        "                text_attention_mask = batch['text_attention_mask'].to(self.device)\n",
        "                spectrograms = batch['spectrogram'].to(self.device)\n",
        "                labels = batch['label'].squeeze().to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(audio_features, text_input_ids, text_attention_mask, spectrograms)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                # Store results\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "                all_file_ids.extend(batch['file_id'])\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "\n",
        "        # ROC AUC (for binary classification)\n",
        "        if len(class_names) == 2:\n",
        "            probs_positive = [prob[1] for prob in all_probs]\n",
        "            auc = roc_auc_score(all_labels, probs_positive)\n",
        "        else:\n",
        "            auc = None\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "        # Print results\n",
        "        print(\"=\"*60)\n",
        "        print(\"DETAILED EVALUATION RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1-Score: {f1:.4f}\")\n",
        "        if auc:\n",
        "            print(f\"ROC AUC: {auc:.4f}\")\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Plot training curves\n",
        "        self.plot_training_curves()\n",
        "\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame({\n",
        "            'file_id': all_file_ids,\n",
        "            'true_label': all_labels,\n",
        "            'predicted_label': all_preds,\n",
        "            'confidence': [max(prob) for prob in all_probs],\n",
        "            'prob_CN': [prob[0] for prob in all_probs],\n",
        "            'prob_AD': [prob[1] for prob in all_probs] if len(all_probs[0]) > 1 else [0] * len(all_probs)\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'auc': auc,\n",
        "            'confusion_matrix': cm,\n",
        "            'results_df': results_df\n",
        "        }\n",
        "\n",
        "    def plot_training_curves(self):\n",
        "        \"\"\"Plot training and validation curves\"\"\"\n",
        "        fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # Loss curves\n",
        "        ax1.plot(self.train_losses, label='Training Loss', color='blue')\n",
        "        ax1.plot(self.val_losses, label='Validation Loss', color='red')\n",
        "        ax1.set_title('Training and Validation Loss')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # Accuracy curves\n",
        "        ax2.plot(self.train_accuracies, label='Training Accuracy', color='blue')\n",
        "        ax2.plot(self.val_accuracies, label='Validation Accuracy', color='red')\n",
        "        ax2.set_title('Training and Validation Accuracy')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Accuracy (%)')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def visualize_semantic_graph(text_features, audio_features, file_id, save_path=None):\n",
        "    \"\"\"Visualize semantic relationships between audio and text\"\"\"\n",
        "    # Compute similarity\n",
        "    similarity = F.cosine_similarity(text_features, audio_features, dim=0).item()\n",
        "\n",
        "    # Create networkx graph\n",
        "    G = nx.Graph()\n",
        "    G.add_node(\"Text\", type=\"text\", features=text_features[:5].tolist())\n",
        "    G.add_node(\"Audio\", type=\"audio\", features=audio_features[:5].tolist())\n",
        "\n",
        "    # Add edge if similarity is significant\n",
        "    if similarity > 0.1:\n",
        "        G.add_edge(\"Text\", \"Audio\", weight=similarity, similarity=similarity)\n",
        "\n",
        "    # Visualize\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    pos = nx.spring_layout(G, k=3, iterations=50)\n",
        "\n",
        "    # Draw nodes\n",
        "    node_colors = ['lightblue' if G.nodes[node]['type'] == 'text' else 'lightcoral'\n",
        "                   for node in G.nodes()]\n",
        "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=3000, alpha=0.7)\n",
        "\n",
        "    # Draw edges\n",
        "    if G.edges():\n",
        "        edge_widths = [G[u][v]['weight'] * 10 for u, v in G.edges()]\n",
        "        nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.6, edge_color='gray')\n",
        "\n",
        "    # Draw labels\n",
        "    nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')\n",
        "\n",
        "    # Add edge labels\n",
        "    if G.edges():\n",
        "        edge_labels = {(u, v): f\"Sim: {G[u][v]['similarity']:.3f}\"\n",
        "                      for u, v in G.edges()}\n",
        "        nx.draw_networkx_edge_labels(G, pos, edge_labels, font_size=10)\n",
        "\n",
        "    plt.title(f'Semantic Relationship Graph - {file_id}\\nSimilarity: {similarity:.3f}')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return G, similarity\n",
        "\n",
        "# Step 6: Model Architecture Extension for ADReSSoAnalyzer\n",
        "def extend_analyzer_with_model():\n",
        "    \"\"\"Extend the ADReSSoAnalyzer class with the new model architecture\"\"\"\n",
        "\n",
        "    class ADReSSoAnalyzerExtended(ADReSSoAnalyzer):\n",
        "        def __init__(self, base_path=\"/content/drive/MyDrive/Voice/extracted/ADReSSo21\"):\n",
        "            super().__init__(base_path)\n",
        "            self.model = None\n",
        "            self.trainer = None\n",
        "            self.scaler = StandardScaler()\n",
        "\n",
        "        def step_6_define_model_architecture(self):\n",
        "            \"\"\"Step 6: Define the multi-modal model architecture\"\"\"\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"STEP 6: DEFINING MODEL ARCHITECTURE\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            print(\"Initializing Multi-Modal Architecture:\")\n",
        "            print(\"- Graph-based Attention Module\")\n",
        "            print(\"- Vision Transformer Module\")\n",
        "            print(\"- U-Net Module\")\n",
        "            print(\"- AlexNet Module\")\n",
        "            print(\"- BERT for text processing\")\n",
        "            print(\"- Fusion and Classification layers\")\n",
        "\n",
        "            # Initialize model\n",
        "            self.model = MultiModalADReSSoModel(\n",
        "                audio_feature_dim=768,  # Wav2Vec2 dimension\n",
        "                text_feature_dim=768,   # BERT dimension\n",
        "                spectrogram_height=80,  # Mel spectrogram bins\n",
        "                num_classes=2           # AD vs CN\n",
        "            )\n",
        "\n",
        "            # Initialize trainer\n",
        "            self.trainer = ADReSSoTrainer(self.model)\n",
        "\n",
        "            print(f\"\\nModel initialized with {sum(p.numel() for p in self.model.parameters()):,} parameters\")\n",
        "            print(\"Architecture components ready for training!\")\n",
        "\n",
        "            return self.model\n",
        "\n",
        "        def step_7_train_model(self, features_dict, linguistic_features, batch_size=8, num_epochs=30):\n",
        "            \"\"\"Step 7: Train the multi-modal model\"\"\"\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"STEP 7: TRAINING MODEL\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            if self.model is None:\n",
        "                print(\"Model not initialized. Running Step 6 first...\")\n",
        "                self.step_6_define_model_architecture()\n",
        "\n",
        "            # Prepare labels based on file categories\n",
        "            labels = {}\n",
        "            for file_id in features_dict.keys():\n",
        "                if 'diagnosis_ad' in file_id or 'progression_decline' in file_id:\n",
        "                    labels[file_id] = 1  # AD/Decline\n",
        "                else:\n",
        "                    labels[file_id] = 0  # CN/No decline\n",
        "\n",
        "            print(f\"Dataset summary:\")\n",
        "            print(f\"- Total files: {len(features_dict)}\")\n",
        "            print(f\"- AD/Decline cases: {sum(labels.values())}\")\n",
        "            print(f\"- CN/No decline cases: {len(labels) - sum(labels.values())}\")\n",
        "\n",
        "            # Split data\n",
        "            file_ids = list(features_dict.keys())\n",
        "            train_ids, test_ids = train_test_split(file_ids, test_size=0.2,\n",
        "                                                 stratify=[labels[f] for f in file_ids],\n",
        "                                                 random_state=42)\n",
        "            train_ids, val_ids = train_test_split(train_ids, test_size=0.2,\n",
        "                                                stratify=[labels[f] for f in train_ids],\n",
        "                                                random_state=42)\n",
        "\n",
        "            print(f\"\\nData split:\")\n",
        "            print(f\"- Training: {len(train_ids)} files\")\n",
        "            print(f\"- Validation: {len(val_ids)} files\")\n",
        "            print(f\"- Testing: {len(test_ids)} files\")\n",
        "\n",
        "            # Create datasets\n",
        "            train_features = {fid: features_dict[fid] for fid in train_ids}\n",
        "            val_features = {fid: features_dict[fid] for fid in val_ids}\n",
        "            test_features = {fid: features_dict[fid] for fid in test_ids}\n",
        "\n",
        "            train_linguistic = {fid: linguistic_features[fid] for fid in train_ids}\n",
        "            val_linguistic = {fid: linguistic_features[fid] for fid in val_ids}\n",
        "            test_linguistic = {fid: linguistic_features[fid] for fid in test_ids}\n",
        "\n",
        "            train_labels = {fid: labels[fid] for fid in train_ids}\n",
        "            val_labels = {fid: labels[fid] for fid in val_ids}\n",
        "            test_labels = {fid: labels[fid] for fid in test_ids}\n",
        "\n",
        "            # Create data loaders\n",
        "            train_dataset = ADReSSoDataset(train_features, train_linguistic, train_labels)\n",
        "            val_dataset = ADReSSoDataset(val_features, val_linguistic, val_labels)\n",
        "            test_dataset = ADReSSoDataset(test_features, test_linguistic, test_labels)\n",
        "\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "            print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
        "\n",
        "            # Train the model\n",
        "            self.trainer.train(train_loader, val_loader, num_epochs=num_epochs)\n",
        "\n",
        "            # Store test loader for evaluation\n",
        "            self.test_loader = test_loader\n",
        "\n",
        "            print(\"Training completed!\")\n",
        "            return self.trainer\n",
        "\n",
        "        def step_8_evaluate_model(self, visualize_graphs=True, num_graph_samples=5):\n",
        "            \"\"\"Step 8: Evaluate model and visualize semantic relationships\"\"\"\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"STEP 8: MODEL EVALUATION AND SEMANTIC ANALYSIS\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            if self.trainer is None:\n",
        "                print(\"Model not trained. Please run Step 7 first.\")\n",
        "                return None\n",
        "\n",
        "            # Load best model\n",
        "            self.model.load_state_dict(torch.load('best_adresso_model.pth'))\n",
        "\n",
        "            # Detailed evaluation\n",
        "            print(\"Performing detailed evaluation...\")\n",
        "            evaluation_results = self.trainer.evaluate_detailed(\n",
        "                self.test_loader, class_names=['CN', 'AD']\n",
        "            )\n",
        "\n",
        "            # Visualize semantic relationships\n",
        "            if visualize_graphs:\n",
        "                print(f\"\\nVisualizing semantic relationships for {num_graph_samples} samples...\")\n",
        "                self.visualize_semantic_relationships(num_samples=num_graph_samples)\n",
        "\n",
        "            # Additional analysis\n",
        "            self.analyze_feature_importance()\n",
        "            self.generate_evaluation_report(evaluation_results)\n",
        "\n",
        "            return evaluation_results\n",
        "\n",
        "        def visualize_semantic_relationships(self, num_samples=5):\n",
        "            \"\"\"Visualize semantic graphs for sample files\"\"\"\n",
        "            self.model.eval()\n",
        "            sample_count = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in self.test_loader:\n",
        "                    if sample_count >= num_samples:\n",
        "                        break\n",
        "\n",
        "                    # Process batch\n",
        "                    audio_features = batch['audio_features'].to(self.trainer.device)\n",
        "                    text_input_ids = batch['text_input_ids'].to(self.trainer.device)\n",
        "                    text_attention_mask = batch['text_attention_mask'].to(self.trainer.device)\n",
        "                    file_ids = batch['file_id']\n",
        "\n",
        "                    # Get BERT features\n",
        "                    bert_outputs = self.model.bert(\n",
        "                        input_ids=text_input_ids,\n",
        "                        attention_mask=text_attention_mask\n",
        "                    )\n",
        "                    text_features = bert_outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "                    # Visualize each sample in batch\n",
        "                    for i in range(min(len(file_ids), num_samples - sample_count)):\n",
        "                        file_id = file_ids[i]\n",
        "                        text_feat = text_features[i]\n",
        "                        audio_feat = audio_features[i]\n",
        "\n",
        "                        print(f\"\\nVisualizing semantic relationships for: {file_id}\")\n",
        "\n",
        "                        # Create and visualize graph\n",
        "                        graph, similarity = visualize_semantic_graph(\n",
        "                            text_feat.cpu(),\n",
        "                            audio_feat.cpu(),\n",
        "                            file_id,\n",
        "                            save_path=f\"semantic_graph_{file_id}.png\"\n",
        "                        )\n",
        "\n",
        "                        # Print relationship analysis\n",
        "                        self.analyze_semantic_relationship(text_feat.cpu(), audio_feat.cpu(), file_id)\n",
        "\n",
        "                        sample_count += 1\n",
        "\n",
        "                        if sample_count >= num_samples:\n",
        "                            break\n",
        "\n",
        "        def analyze_semantic_relationship(self, text_features, audio_features, file_id):\n",
        "            \"\"\"Analyze the semantic relationship between audio and text\"\"\"\n",
        "            # Compute various similarity metrics\n",
        "            cosine_sim = F.cosine_similarity(text_features, audio_features, dim=0).item()\n",
        "\n",
        "            # L2 distance (normalized)\n",
        "            l2_distance = torch.norm(text_features - audio_features).item()\n",
        "            normalized_l2 = l2_distance / (torch.norm(text_features) + torch.norm(audio_features)).item()\n",
        "\n",
        "            # Dot product similarity\n",
        "            dot_product = torch.dot(text_features, audio_features).item()\n",
        "\n",
        "            print(f\"Semantic Relationship Analysis for {file_id}:\")\n",
        "            print(f\"  - Cosine Similarity: {cosine_sim:.4f}\")\n",
        "            print(f\"  - Normalized L2 Distance: {normalized_l2:.4f}\")\n",
        "            print(f\"  - Dot Product: {dot_product:.4f}\")\n",
        "\n",
        "            # Interpretation\n",
        "            if cosine_sim > 0.7:\n",
        "                relationship = \"Strong positive correlation\"\n",
        "            elif cosine_sim > 0.3:\n",
        "                relationship = \"Moderate positive correlation\"\n",
        "            elif cosine_sim > 0.1:\n",
        "                relationship = \"Weak positive correlation\"\n",
        "            elif cosine_sim > -0.1:\n",
        "                relationship = \"No significant correlation\"\n",
        "            else:\n",
        "                relationship = \"Negative correlation\"\n",
        "\n",
        "            print(f\"  - Relationship Interpretation: {relationship}\")\n",
        "\n",
        "            return {\n",
        "                'cosine_similarity': cosine_sim,\n",
        "                'l2_distance': normalized_l2,\n",
        "                'dot_product': dot_product,\n",
        "                'relationship': relationship\n",
        "            }\n",
        "\n",
        "        def analyze_feature_importance(self):\n",
        "            \"\"\"Analyze feature importance across different modalities\"\"\"\n",
        "            print(\"\\nAnalyzing feature importance across modalities...\")\n",
        "\n",
        "            self.model.eval()\n",
        "            modality_contributions = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in self.test_loader:\n",
        "                    # Get features\n",
        "                    audio_features = batch['audio_features'].to(self.trainer.device)\n",
        "                    text_input_ids = batch['text_input_ids'].to(self.trainer.device)\n",
        "                    text_attention_mask = batch['text_attention_mask'].to(self.trainer.device)\n",
        "                    spectrograms = batch['spectrogram'].to(self.trainer.device)\n",
        "\n",
        "                    # Process text with BERT\n",
        "                    bert_outputs = self.model.bert(input_ids=text_input_ids, attention_mask=text_attention_mask)\n",
        "                    text_features = bert_outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "                    # Get individual modality outputs\n",
        "                    graph_batch = self.model.create_semantic_graph(text_features, audio_features)\n",
        "                    graph_out = self.model.graph_attention(graph_batch.x, graph_batch.edge_index, graph_batch.batch)\n",
        "                    vit_out = self.model.vision_transformer(spectrograms)\n",
        "\n",
        "                    audio_1d = audio_features.unsqueeze(1)\n",
        "                    unet_out = self.model.unet(audio_1d)\n",
        "                    alexnet_out = self.model.alexnet(audio_features)\n",
        "\n",
        "                    # Calculate contribution magnitudes\n",
        "                    contributions = {\n",
        "                        'Graph Attention': torch.norm(graph_out, dim=1).mean().item(),\n",
        "                        'Vision Transformer': torch.norm(vit_out, dim=1).mean().item(),\n",
        "                        'U-Net': torch.norm(unet_out, dim=1).mean().item(),\n",
        "                        'AlexNet': torch.norm(alexnet_out, dim=1).mean().item()\n",
        "                    }\n",
        "\n",
        "                    modality_contributions.append(contributions)\n",
        "\n",
        "                    # Only analyze first few batches to save time\n",
        "                    if len(modality_contributions) >= 5:\n",
        "                        break\n",
        "\n",
        "            # Aggregate results\n",
        "            avg_contributions = {}\n",
        "            for modality in modality_contributions[0].keys():\n",
        "                avg_contributions[modality] = np.mean([contrib[modality] for contrib in modality_contributions])\n",
        "\n",
        "            # Visualize feature importance\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            modalities = list(avg_contributions.keys())\n",
        "            contributions = list(avg_contributions.values())\n",
        "\n",
        "            bars = plt.bar(modalities, contributions, color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
        "            plt.title('Average Feature Contribution by Modality')\n",
        "            plt.ylabel('Average L2 Norm')\n",
        "            plt.xlabel('Modality')\n",
        "            plt.xticks(rotation=45)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for bar, value in zip(bars, contributions):\n",
        "                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                        f'{value:.3f}', ha='center', va='bottom')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            print(\"Feature Importance Analysis:\")\n",
        "            for modality, contribution in avg_contributions.items():\n",
        "                print(f\"  - {modality}: {contribution:.4f}\")\n",
        "\n",
        "            return avg_contributions\n",
        "\n",
        "        def generate_evaluation_report(self, evaluation_results):\n",
        "            \"\"\"Generate comprehensive evaluation report\"\"\"\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"COMPREHENSIVE EVALUATION REPORT\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            # Performance metrics\n",
        "            print(\"PERFORMANCE METRICS:\")\n",
        "            print(f\"  - Overall Accuracy: {evaluation_results['accuracy']:.4f}\")\n",
        "            print(f\"  - Precision: {evaluation_results['precision']:.4f}\")\n",
        "            print(f\"  - Recall: {evaluation_results['recall']:.4f}\")\n",
        "            print(f\"  - F1-Score: {evaluation_results['f1']:.4f}\")\n",
        "            if evaluation_results['auc']:\n",
        "                print(f\"  - ROC AUC: {evaluation_results['auc']:.4f}\")\n",
        "\n",
        "            # Results by category\n",
        "            results_df = evaluation_results['results_df']\n",
        "\n",
        "            print(\"\\nRESULTS BY CATEGORY:\")\n",
        "            for category in ['diagnosis_ad', 'diagnosis_cn', 'progression_decline', 'progression_no_decline']:\n",
        "                category_results = results_df[results_df['file_id'].str.contains(category)]\n",
        "                if len(category_results) > 0:\n",
        "                    accuracy = (category_results['true_label'] == category_results['predicted_label']).mean()\n",
        "                    avg_confidence = category_results['confidence'].mean()\n",
        "                    print(f\"  - {category}:\")\n",
        "                    print(f\"    * Accuracy: {accuracy:.4f}\")\n",
        "                    print(f\"    * Average Confidence: {avg_confidence:.4f}\")\n",
        "                    print(f\"    * Sample Count: {len(category_results)}\")\n",
        "\n",
        "            # Misclassification analysis\n",
        "            print(\"\\nMISCLASSIFICATION ANALYSIS:\")\n",
        "            misclassified = results_df[results_df['true_label'] != results_df['predicted_label']]\n",
        "            print(f\"  - Total Misclassified: {len(misclassified)}\")\n",
        "            print(f\"  - Misclassification Rate: {len(misclassified)/len(results_df):.4f}\")\n",
        "\n",
        "            if len(misclassified) > 0:\n",
        "                print(\"  - Misclassified Samples:\")\n",
        "                for _, row in misclassified.head().iterrows():\n",
        "                    print(f\"    * {row['file_id']}: True={row['true_label']}, Pred={row['predicted_label']}, Conf={row['confidence']:.3f}\")\n",
        "\n",
        "            # High confidence predictions\n",
        "            high_conf = results_df[results_df['confidence'] > 0.9]\n",
        "            print(f\"\\nHIGH CONFIDENCE PREDICTIONS (>0.9):\")\n",
        "            print(f\"  - Count: {len(high_conf)}\")\n",
        "            print(f\"  - Accuracy: {(high_conf['true_label'] == high_conf['predicted_label']).mean():.4f}\")\n",
        "\n",
        "            # Save detailed results\n",
        "            results_df.to_csv(f\"{self.output_path}/detailed_evaluation_results.csv\", index=False)\n",
        "\n",
        "            # Save evaluation summary\n",
        "            summary_dict = {\n",
        "                'accuracy': evaluation_results['accuracy'],\n",
        "                'precision': evaluation_results['precision'],\n",
        "                'recall': evaluation_results['recall'],\n",
        "                'f1_score': evaluation_results['f1'],\n",
        "                'roc_auc': evaluation_results['auc'],\n",
        "                'total_samples': len(results_df),\n",
        "                'misclassified_count': len(misclassified),\n",
        "                'high_confidence_count': len(high_conf)\n",
        "            }\n",
        "\n",
        "            with open(f\"{self.output_path}/evaluation_summary.json\", 'w') as f:\n",
        "                json.dump(summary_dict, f, indent=2)\n",
        "\n",
        "            print(f\"\\nDetailed results saved to:\")\n",
        "            print(f\"  - {self.output_path}/detailed_evaluation_results.csv\")\n",
        "            print(f\"  - {self.output_path}/evaluation_summary.json\")\n",
        "\n",
        "            return summary_dict\n",
        "\n",
        "        def run_complete_pipeline_with_model(self, num_epochs=30, batch_size=8):\n",
        "            \"\"\"Run the complete pipeline including model training and evaluation\"\"\"\n",
        "            print(\"=\"*80)\n",
        "            print(\"COMPLETE ADReSSo MULTI-MODAL ANALYSIS PIPELINE\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            # Run original pipeline (Steps 0-5)\n",
        "            results = self.run_complete_pipeline()\n",
        "\n",
        "            if results is None:\n",
        "                print(\"Error in initial pipeline. Cannot proceed with model training.\")\n",
        "                return None\n",
        "\n",
        "            # Extract features and linguistic data\n",
        "            features_dict = {}\n",
        "            audio_files = results['audio_files']\n",
        "\n",
        "            # Extract acoustic features for all files\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"EXTRACTING ACOUSTIC FEATURES FOR MODEL TRAINING\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            for category, files in audio_files.items():\n",
        "                print(f\"\\nProcessing {category}...\")\n",
        "                for file_path in files:\n",
        "                    filename = os.path.basename(file_path)\n",
        "                    file_id = f\"{category}_{filename}\"\n",
        "\n",
        "                    print(f\"  Extracting features for {filename}...\")\n",
        "                    features = self.extract_acoustic_features(file_path)\n",
        "\n",
        "                    if features is not None:\n",
        "                        features_dict[file_id] = features\n",
        "                    else:\n",
        "                        print(f\"  Warning: Could not extract features for {filename}\")\n",
        "\n",
        "            print(f\"\\nSuccessfully extracted features for {len(features_dict)} files\")\n",
        "\n",
        "            # Step 6: Define model architecture\n",
        "            self.step_6_define_model_architecture()\n",
        "\n",
        "            # Step 7: Train model\n",
        "            self.step_7_train_model(\n",
        "                features_dict,\n",
        "                results['linguistic_features'],\n",
        "                batch_size=batch_size,\n",
        "                num_epochs=num_epochs\n",
        "            )\n",
        "\n",
        "            # Step 8: Evaluate model\n",
        "            evaluation_results = self.step_8_evaluate_model()\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "            print(\"=\"*80)\n",
        "            print(\"\\nAll results saved to output directory.\")\n",
        "            print(\"Model training and evaluation completed with semantic relationship analysis.\")\n",
        "\n",
        "            return {\n",
        "                'original_results': results,\n",
        "                'features_dict': features_dict,\n",
        "                'model': self.model,\n",
        "                'trainer': self.trainer,\n",
        "                'evaluation_results': evaluation_results\n",
        "            }\n",
        "\n",
        "    return ADReSSoAnalyzerExtended\n",
        "\n",
        "# Usage Example\n",
        "if __name__ == \"__main__\":\n",
        "    # Create extended analyzer\n",
        "    ExtendedAnalyzer = extend_analyzer_with_model()\n",
        "    analyzer = ExtendedAnalyzer()\n",
        "\n",
        "    # Run complete pipeline\n",
        "    print(\"Starting ADReSSo Multi-Modal Analysis Pipeline...\")\n",
        "    complete_results = analyzer.run_complete_pipeline_with_model(\n",
        "        num_epochs=5,  # Adjust based on your computational resources\n",
        "        batch_size=4    # Adjust based on your GPU memory\n",
        "    )\n",
        "\n",
        "    if complete_results:\n",
        "        print(\"\\nPipeline completed successfully!\")\n",
        "        print(\"Check the output directory for all results and visualizations.\")\n",
        "    else:\n",
        "        print(\"Pipeline encountered errors. Please check the dataset path and requirements.\")"
      ],
      "metadata": {
        "id": "FAQVVECXn9mT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5c1053-9880-43f4-d32e-29b44ed33ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting ADReSSo Multi-Modal Analysis Pipeline...\n",
            "================================================================================\n",
            "COMPLETE ADReSSo MULTI-MODAL ANALYSIS PIPELINE\n",
            "================================================================================\n",
            "=== ADReSSo21 Speech Analysis Pipeline ===\n",
            "\n",
            "Step 0: Getting audio files...\n",
            "Found 271 audio files across all categories\n",
            "  diagnosis_ad: 87 files\n",
            "  diagnosis_cn: 79 files\n",
            "  progression_decline: 15 files\n",
            "  progression_no_decline: 58 files\n",
            "  progression_test: 32 files\n",
            "\n",
            "==================================================\n",
            "Step 1: Demonstrating acoustic features...\n",
            "\n",
            "Showing features for diagnosis_ad:\n",
            "=== Acoustic Features for adrso047.wav ===\n",
            "\n",
            "1. eGeMAPS Features: 88 features\n",
            "   Shape: (88,)\n",
            "   Sample values: [25.866777    0.31971478 16.288124   26.47413    34.226044  ]\n",
            "\n",
            "2. MFCC Features:\n",
            "   Mean: (13,) - [-283.20312     76.72155      4.9237657   23.371506   -11.170574 ]\n",
            "   Std: (13,) - [79.158615 30.192682 25.279158 24.67176  18.788862]\n",
            "   Delta: (13,) - [ 0.3264354  -0.00845834 -0.01544069  0.0086811  -0.01617551]\n",
            "   Delta-Delta: (13,) - [ 0.01663556  0.00127252  0.00217276 -0.00220479  0.00038056]\n",
            "\n",
            "3. Log-Mel Spectrogram Features:\n",
            "   Mean: (80,) - [-23.605774  -18.057337  -11.690929  -10.313613   -7.5411944]\n",
            "   Std: (80,) - [11.996229  9.398558  6.633258  6.546015  8.263119]\n",
            "\n",
            "4. Wav2Vec2 Features: (768,)\n",
            "   Sample values: [-0.02854712 -0.00418562 -0.07545928 -0.05687362  0.00764589]\n",
            "\n",
            "5. Prosodic Features:\n",
            "   f0_mean: 142.0958\n",
            "   f0_std: 67.3784\n",
            "   energy_mean: 0.0243\n",
            "   energy_std: 0.0264\n",
            "   zero_crossing_rate: 0.1436\n",
            "   spectral_centroid: 1989.2703\n",
            "   spectral_rolloff: 4091.9595\n",
            "   duration: 60.3156\n",
            "\n",
            "\n",
            "==================================================\n",
            "Step 2: Extracting transcripts...\n",
            "Extracting transcripts...\n",
            "\n",
            "Processing diagnosis_ad...\n",
            "  Transcribing adrso047.wav...\n",
            "  Transcribing adrso128.wav...\n",
            "  Transcribing adrso110.wav...\n",
            "  Transcribing adrso036.wav...\n",
            "  Transcribing adrso045.wav...\n",
            "  Transcribing adrso093.wav...\n",
            "  Transcribing adrso112.wav...\n",
            "  Transcribing adrso189.wav...\n",
            "  Transcribing adrso089.wav...\n",
            "  Transcribing adrso205.wav...\n",
            "  Transcribing adrso060.wav...\n",
            "  Transcribing adrso232.wav...\n",
            "  Transcribing adrso075.wav...\n",
            "  Transcribing adrso106.wav...\n",
            "  Transcribing adrso063.wav...\n",
            "  Transcribing adrso043.wav...\n",
            "  Transcribing adrso206.wav...\n",
            "  Transcribing adrso126.wav...\n",
            "  Transcribing adrso109.wav...\n",
            "  Transcribing adrso202.wav...\n",
            "  Transcribing adrso071.wav...\n",
            "  Transcribing adrso039.wav...\n",
            "  Transcribing adrso209.wav...\n",
            "  Transcribing adrso228.wav...\n",
            "  Transcribing adrso122.wav...\n",
            "  Transcribing adrso116.wav...\n",
            "  Transcribing adrso244.wav...\n",
            "  Transcribing adrso141.wav...\n",
            "  Transcribing adrso248.wav...\n",
            "  Transcribing adrso130.wav...\n",
            "  Transcribing adrso055.wav...\n",
            "  Transcribing adrso070.wav...\n",
            "  Transcribing adrso222.wav...\n",
            "  Transcribing adrso190.wav...\n",
            "  Transcribing adrso223.wav...\n",
            "  Transcribing adrso215.wav...\n",
            "  Transcribing adrso234.wav...\n",
            "  Transcribing adrso236.wav...\n",
            "  Transcribing adrso059.wav...\n",
            "  Transcribing adrso098.wav...\n",
            "  Transcribing adrso192.wav...\n",
            "  Transcribing adrso090.wav...\n",
            "  Transcribing adrso250.wav...\n",
            "  Transcribing adrso025.wav...\n",
            "  Transcribing adrso224.wav...\n",
            "  Transcribing adrso031.wav...\n",
            "  Transcribing adrso074.wav...\n",
            "  Transcribing adrso211.wav...\n",
            "  Transcribing adrso229.wav...\n",
            "  Transcribing adrso197.wav...\n",
            "  Transcribing adrso049.wav...\n",
            "  Transcribing adrso138.wav...\n",
            "  Transcribing adrso123.wav...\n",
            "  Transcribing adrso072.wav...\n",
            "  Transcribing adrso027.wav...\n",
            "  Transcribing adrso068.wav...\n",
            "  Transcribing adrso187.wav...\n",
            "  Transcribing adrso054.wav...\n",
            "  Transcribing adrso249.wav...\n",
            "  Transcribing adrso200.wav...\n",
            "  Transcribing adrso028.wav...\n",
            "  Transcribing adrso053.wav...\n",
            "  Transcribing adrso078.wav...\n",
            "  Transcribing adrso056.wav...\n",
            "  Transcribing adrso245.wav...\n",
            "  Transcribing adrso092.wav...\n",
            "  Transcribing adrso134.wav...\n",
            "  Transcribing adrso216.wav...\n",
            "  Transcribing adrso142.wav...\n",
            "  Transcribing adrso077.wav...\n",
            "  Transcribing adrso198.wav...\n",
            "  Transcribing adrso220.wav...\n",
            "  Transcribing adrso024.wav...\n",
            "  Transcribing adrso212.wav...\n",
            "  Transcribing adrso046.wav...\n",
            "  Transcribing adrso233.wav...\n",
            "  Transcribing adrso247.wav...\n",
            "  Transcribing adrso035.wav...\n",
            "  Transcribing adrso125.wav...\n",
            "  Transcribing adrso188.wav...\n",
            "  Transcribing adrso033.wav...\n",
            "  Transcribing adrso237.wav...\n",
            "  Transcribing adrso253.wav...\n",
            "  Transcribing adrso218.wav...\n",
            "  Transcribing adrso144.wav...\n",
            "  Transcribing adrso032.wav...\n",
            "  Transcribing adrso246.wav...\n",
            "\n",
            "Processing diagnosis_cn...\n",
            "  Transcribing adrso173.wav...\n",
            "  Transcribing adrso015.wav...\n",
            "  Transcribing adrso307.wav...\n",
            "  Transcribing adrso283.wav...\n",
            "  Transcribing adrso167.wav...\n",
            "  Transcribing adrso168.wav...\n",
            "  Transcribing adrso172.wav...\n",
            "  Transcribing adrso292.wav...\n",
            "  Transcribing adrso316.wav...\n",
            "  Transcribing adrso162.wav...\n",
            "  Transcribing adrso278.wav...\n",
            "  Transcribing adrso296.wav...\n",
            "  Transcribing adrso300.wav...\n",
            "  Transcribing adrso291.wav...\n",
            "  Transcribing adrso169.wav...\n",
            "  Transcribing adrso178.wav...\n",
            "  Transcribing adrso165.wav...\n",
            "  Transcribing adrso177.wav...\n",
            "  Transcribing adrso262.wav...\n",
            "  Transcribing adrso265.wav...\n",
            "  Transcribing adrso014.wav...\n",
            "  Transcribing adrso021.wav...\n",
            "  Transcribing adrso268.wav...\n",
            "  Transcribing adrso261.wav...\n",
            "  Transcribing adrso156.wav...\n",
            "  Transcribing adrso148.wav...\n",
            "  Transcribing adrso016.wav...\n",
            "  Transcribing adrso310.wav...\n",
            "  Transcribing adrso302.wav...\n",
            "  Transcribing adrso308.wav...\n",
            "  Transcribing adrso018.wav...\n",
            "  Transcribing adrso309.wav...\n",
            "  Transcribing adrso298.wav...\n",
            "  Transcribing adrso180.wav...\n",
            "  Transcribing adrso154.wav...\n",
            "  Transcribing adrso273.wav...\n",
            "  Transcribing adrso159.wav...\n",
            "  Transcribing adrso259.wav...\n",
            "  Transcribing adrso151.wav...\n",
            "  Transcribing adrso267.wav...\n",
            "  Transcribing adrso019.wav...\n",
            "  Transcribing adrso153.wav...\n",
            "  Transcribing adrso274.wav...\n",
            "  Transcribing adrso023.wav...\n",
            "  Transcribing adrso012.wav...\n",
            "  Transcribing adrso002.wav...\n",
            "  Transcribing adrso022.wav...\n",
            "  Transcribing adrso266.wav...\n",
            "  Transcribing adrso280.wav...\n",
            "  Transcribing adrso152.wav...\n",
            "  Transcribing adrso007.wav...\n",
            "  Transcribing adrso276.wav...\n",
            "  Transcribing adrso260.wav...\n",
            "  Transcribing adrso017.wav...\n",
            "  Transcribing adrso005.wav...\n",
            "  Transcribing adrso299.wav...\n",
            "  Transcribing adrso157.wav...\n",
            "  Transcribing adrso182.wav...\n",
            "  Transcribing adrso008.wav...\n",
            "  Transcribing adrso161.wav...\n",
            "  Transcribing adrso263.wav...\n",
            "  Transcribing adrso257.wav...\n",
            "  Transcribing adrso164.wav...\n",
            "  Transcribing adrso289.wav...\n",
            "  Transcribing adrso270.wav...\n",
            "  Transcribing adrso264.wav...\n",
            "  Transcribing adrso277.wav...\n",
            "  Transcribing adrso160.wav...\n",
            "  Transcribing adrso186.wav...\n",
            "  Transcribing adrso003.wav...\n",
            "  Transcribing adrso286.wav...\n",
            "  Transcribing adrso285.wav...\n",
            "  Transcribing adrso170.wav...\n",
            "  Transcribing adrso183.wav...\n",
            "  Transcribing adrso281.wav...\n",
            "  Transcribing adrso010.wav...\n",
            "  Transcribing adrso315.wav...\n",
            "  Transcribing adrso312.wav...\n",
            "  Transcribing adrso158.wav...\n",
            "\n",
            "Processing progression_decline...\n",
            "  Transcribing adrsp055.wav...\n",
            "  Transcribing adrsp300.wav...\n",
            "  Transcribing adrsp003.wav...\n",
            "  Transcribing adrsp266.wav...\n",
            "  Transcribing adrsp320.wav...\n",
            "  Transcribing adrsp313.wav...\n",
            "  Transcribing adrsp179.wav...\n",
            "  Transcribing adrsp051.wav...\n",
            "  Transcribing adrsp326.wav...\n",
            "  Transcribing adrsp101.wav...\n",
            "  Transcribing adrsp127.wav...\n",
            "  Transcribing adrsp357.wav...\n",
            "  Transcribing adrsp276.wav...\n",
            "  Transcribing adrsp209.wav...\n",
            "  Transcribing adrsp318.wav...\n",
            "\n",
            "Processing progression_no_decline...\n",
            "  Transcribing adrsp109.wav...\n",
            "  Transcribing adrsp255.wav...\n",
            "  Transcribing adrsp306.wav...\n",
            "  Transcribing adrsp157.wav...\n",
            "  Transcribing adrsp197.wav...\n",
            "  Transcribing adrsp031.wav...\n",
            "  Transcribing adrsp368.wav...\n",
            "  Transcribing adrsp032.wav...\n",
            "  Transcribing adrsp091.wav...\n",
            "  Transcribing adrsp124.wav...\n",
            "  Transcribing adrsp344.wav...\n",
            "  Transcribing adrsp195.wav...\n",
            "  Transcribing adrsp253.wav...\n",
            "  Transcribing adrsp039.wav...\n",
            "  Transcribing adrsp251.wav...\n",
            "  Transcribing adrsp001.wav...\n",
            "  Transcribing adrsp207.wav...\n",
            "  Transcribing adrsp041.wav...\n",
            "  Transcribing adrsp324.wav...\n",
            "  Transcribing adrsp379.wav...\n",
            "  Transcribing adrsp384.wav...\n",
            "  Transcribing adrsp177.wav...\n",
            "  Transcribing adrsp023.wav...\n",
            "  Transcribing adrsp148.wav...\n",
            "  Transcribing adrsp122.wav...\n",
            "  Transcribing adrsp359.wav...\n",
            "  Transcribing adrsp030.wav...\n",
            "  Transcribing adrsp319.wav...\n",
            "  Transcribing adrsp200.wav...\n",
            "  Transcribing adrsp193.wav...\n",
            "  Transcribing adrsp378.wav...\n",
            "  Transcribing adrsp128.wav...\n",
            "  Transcribing adrsp161.wav...\n",
            "  Transcribing adrsp192.wav...\n",
            "  Transcribing adrsp196.wav...\n",
            "  Transcribing adrsp136.wav...\n",
            "  Transcribing adrsp130.wav...\n",
            "  Transcribing adrsp024.wav...\n",
            "  Transcribing adrsp007.wav...\n",
            "  Transcribing adrsp382.wav...\n",
            "  Transcribing adrsp349.wav...\n",
            "  Transcribing adrsp321.wav...\n",
            "  Transcribing adrsp043.wav...\n",
            "  Transcribing adrsp198.wav...\n",
            "  Transcribing adrsp019.wav...\n",
            "  Transcribing adrsp333.wav...\n",
            "  Transcribing adrsp310.wav...\n",
            "  Transcribing adrsp137.wav...\n",
            "  Transcribing adrsp380.wav...\n",
            "  Transcribing adrsp056.wav...\n",
            "  Transcribing adrsp028.wav...\n",
            "  Transcribing adrsp096.wav...\n",
            "  Transcribing adrsp052.wav...\n",
            "  Transcribing adrsp042.wav...\n",
            "  Transcribing adrsp377.wav...\n",
            "  Transcribing adrsp350.wav...\n",
            "  Transcribing adrsp363.wav...\n",
            "  Transcribing adrsp204.wav...\n",
            "\n",
            "Processing progression_test...\n",
            "  Transcribing adrspt15.wav...\n",
            "  Transcribing adrspt20.wav...\n",
            "  Transcribing adrspt4.wav...\n",
            "  Transcribing adrspt27.wav...\n",
            "  Transcribing adrspt16.wav...\n",
            "  Transcribing adrspt28.wav...\n",
            "  Transcribing adrspt9.wav...\n",
            "  Transcribing adrspt10.wav...\n",
            "  Transcribing adrspt26.wav...\n",
            "  Transcribing adrspt13.wav...\n",
            "  Transcribing adrspt31.wav...\n",
            "  Transcribing adrspt23.wav...\n",
            "  Transcribing adrspt14.wav...\n",
            "  Transcribing adrspt12.wav...\n",
            "  Transcribing adrspt32.wav...\n",
            "  Transcribing adrspt6.wav...\n",
            "  Transcribing adrspt1.wav...\n",
            "  Transcribing adrspt21.wav...\n",
            "  Transcribing adrspt30.wav...\n",
            "  Transcribing adrspt29.wav...\n",
            "  Transcribing adrspt8.wav...\n",
            "  Transcribing adrspt3.wav...\n",
            "  Transcribing adrspt19.wav...\n",
            "  Transcribing adrspt18.wav...\n",
            "  Transcribing adrspt24.wav...\n",
            "  Transcribing adrspt2.wav...\n",
            "  Transcribing adrspt25.wav...\n",
            "  Transcribing adrspt17.wav...\n",
            "  Transcribing adrspt11.wav...\n",
            "  Transcribing adrspt22.wav...\n",
            "  Transcribing adrspt7.wav...\n",
            "  Transcribing adrspt5.wav...\n",
            "\n",
            "==================================================\n",
            "Step 3: Saving transcripts...\n",
            "Transcripts saved to /content/transcripts/\n",
            "\n",
            "==================================================\n",
            "Step 4: Creating transcript table...\n",
            "Transcript Summary Table:\n",
            "                            File_ID               Category     Filename  Transcript_Length  Word_Count Language  Segments  Has_Error                                                                                      Transcript_Preview\n",
            "          diagnosis_ad_adrso047.wav           diagnosis_ad adrso047.wav                578          98       en        19      False She was watching this lady right here. She was watching this lady. This man here, he's trying to put...\n",
            "          diagnosis_ad_adrso128.wav           diagnosis_ad adrso128.wav                396          77       en        10      False I just want you to tell me everything that you see happening in that picture. Everything is going on...\n",
            "          diagnosis_ad_adrso110.wav           diagnosis_ad adrso110.wav                623         118       en        12      False Okay, can you tell me everything you see going on in the picture? Over here, standing on the chair, ...\n",
            "          diagnosis_ad_adrso036.wav           diagnosis_ad adrso036.wav                266          54       en         8      False Tell me what's going on all the action what's going on in this picture? Oh the boy is up I And the w...\n",
            "          diagnosis_ad_adrso045.wav           diagnosis_ad adrso045.wav               2157         434       en        48      False This picture and tell me everything that you see going on in that picture. What's happening there? T...\n",
            "          diagnosis_ad_adrso093.wav           diagnosis_ad adrso093.wav                837         165       en        21      False I tell me what's going on in that picture. This little girl is talking to this boy up on this tipper...\n",
            "          diagnosis_ad_adrso112.wav           diagnosis_ad adrso112.wav                523          96       en        16      False Okay, so he's going on in the picture. Ha ha ha. Boys, we've been cooking jaw to take the stools fal...\n",
            "          diagnosis_ad_adrso189.wav           diagnosis_ad adrso189.wav                565         114       en        12      False There it is. Thanks for the light. Yeah. Can I look at it and tell you? Just tell me as you see it d...\n",
            "          diagnosis_ad_adrso089.wav           diagnosis_ad adrso089.wav                591         119       en        11      False Well, they're stealing on the cookies and the little girl is going to take in one tour. He's going t...\n",
            "          diagnosis_ad_adrso205.wav           diagnosis_ad adrso205.wav                647         126       en        22      False The little boys up on this thing here and it's bees up trying to get something out of a garden selec...\n",
            "          diagnosis_ad_adrso060.wav           diagnosis_ad adrso060.wav                329          67       en        13      False This is a side cooking, honey. You just come in and you can do more of this. Oh, cooking your arm. T...\n",
            "          diagnosis_ad_adrso232.wav           diagnosis_ad adrso232.wav                582         114       en        14      False I'd like for you to take a look at this picture. I'd like for you to tell me everything that you see...\n",
            "          diagnosis_ad_adrso075.wav           diagnosis_ad adrso075.wav                432          77       en        16      False What else do you want? All right. He's ready to fall. His problems, the waters coming over the sink....\n",
            "          diagnosis_ad_adrso106.wav           diagnosis_ad adrso106.wav                694         145       en        12      False What's going on in the picture? The water is running out of a sink and all of this. The little boy i...\n",
            "          diagnosis_ad_adrso063.wav           diagnosis_ad adrso063.wav                247          47       en        10      False Can you see the picture here? Tell me what's going on. What happened there? Just tell me what we've ...\n",
            "          diagnosis_ad_adrso043.wav           diagnosis_ad adrso043.wav                524          98       en        42      False Have a look at that picture and tell me everything that you see going on in that picture, all the ac...\n",
            "          diagnosis_ad_adrso206.wav           diagnosis_ad adrso206.wav                627         123       en        18      False Just tell me everything that you see happening in the picture. Hi. A little girl in the little boy i...\n",
            "          diagnosis_ad_adrso126.wav           diagnosis_ad adrso126.wav                501          94       en        16      False Just to take a look at this picture and tell me everything that you see going along in the picture. ...\n",
            "          diagnosis_ad_adrso109.wav           diagnosis_ad adrso109.wav                819         157       en        19      False Take a look at that picture. Take a look at that picture and tell me everything that you see happeni...\n",
            "          diagnosis_ad_adrso202.wav           diagnosis_ad adrso202.wav                643         128       en        23      False Here's the picture. All of the act. Start the other is grinders. And the sink is overflowing. One mo...\n",
            "          diagnosis_ad_adrso071.wav           diagnosis_ad adrso071.wav                465          87       en         7      False Well, the guy was getting in the cookie jar and standing on the stool, that was falling over and his...\n",
            "          diagnosis_ad_adrso039.wav           diagnosis_ad adrso039.wav                259          53       en        11      False I can take a table of the same spot. This thing is running over. I can also make you for a cooking. ...\n",
            "          diagnosis_ad_adrso209.wav           diagnosis_ad adrso209.wav                626         121       en        18      False Tell me all the action going on in that picture. Can you tell me the action that you see going on in...\n",
            "          diagnosis_ad_adrso228.wav           diagnosis_ad adrso228.wav                459          83       en        12      False Tell me. Just start out anywhere. Where every life. A little girl. Falling stool. A young lad that's...\n",
            "          diagnosis_ad_adrso122.wav           diagnosis_ad adrso122.wav                444          82       en        15      False What we need to do is take a good look at this picture. And tell me everything that you see going on...\n",
            "          diagnosis_ad_adrso116.wav           diagnosis_ad adrso116.wav                748         147       en        19      False Now I'm going to give you a picture that has a lot of things going on in it. I want you to tell me e...\n",
            "          diagnosis_ad_adrso244.wav           diagnosis_ad adrso244.wav                566         106       en        30      False I think you see going on in that picture. Well, start from the... The... The... The... The... How ca...\n",
            "          diagnosis_ad_adrso141.wav           diagnosis_ad adrso141.wav                272          49       en         6      False You want me to tell you? Okay, the boy's getting in the cookie jar. His sister's waiting for cookies...\n",
            "          diagnosis_ad_adrso248.wav           diagnosis_ad adrso248.wav                361          68       en         7      False The girl's washing dishes, the water is spilling over onto the floor. The boy is taking some cookies...\n",
            "          diagnosis_ad_adrso130.wav           diagnosis_ad adrso130.wav                353          66       en         7      False picture that has a lot of action going on. There's a lot of things going on in the picture. Tell me ...\n",
            "          diagnosis_ad_adrso055.wav           diagnosis_ad adrso055.wav                608         122       en        16      False What do you see going on in that picture? Oh yeah, kids climbing up on the stone, reaching up in the...\n",
            "          diagnosis_ad_adrso070.wav           diagnosis_ad adrso070.wav                521          98       en        24      False What do you see happening in that picture? Oh, water fell off the sink. Little boy fell off his... W...\n",
            "          diagnosis_ad_adrso222.wav           diagnosis_ad adrso222.wav                600         124       en        15      False All the action you see going on in the picture. Now I think I had it within the kitchen and I was th...\n",
            "          diagnosis_ad_adrso190.wav           diagnosis_ad adrso190.wav               1193         228       en        24      False Here's the patient. Oh boy. We always went up on a cookie jar to get cookie and then he's falling of...\n",
            "          diagnosis_ad_adrso223.wav           diagnosis_ad adrso223.wav                884         157       en        31      False Okay, and I want you to tell me everything that you see going on in that picture. Just tell me every...\n",
            "          diagnosis_ad_adrso215.wav           diagnosis_ad adrso215.wav                480          92       en        17      False I want you to tell me everything that you see going on in the picture. Tell me everything that you s...\n",
            "          diagnosis_ad_adrso234.wav           diagnosis_ad adrso234.wav                533         114       en        13      False What action do you see going on in that picture? I see another washing dishes, I see the water blowi...\n",
            "          diagnosis_ad_adrso236.wav           diagnosis_ad adrso236.wav                325          64       en         7      False Okay, the picture. All you see going on in the picture. All right. Do you tell me? Oh, the boys in t...\n",
            "          diagnosis_ad_adrso059.wav           diagnosis_ad adrso059.wav                361          70       en         4      False in the picture. Oh, oh, oh, well, kind of climatic isn't it? The mother just is, I assume this is th...\n",
            "          diagnosis_ad_adrso098.wav           diagnosis_ad adrso098.wav                840         168       en        27      False I want you to tell me everything that's happening in that picture. I want you to tell me everything'...\n",
            "          diagnosis_ad_adrso192.wav           diagnosis_ad adrso192.wav                624         127       en        10      False You see a guy going on here. Just look at this picture and tell me what you see. Well, well, you see...\n",
            "          diagnosis_ad_adrso090.wav           diagnosis_ad adrso090.wav                390          78       en        17      False I'm on a wheelchair. What? A boy? He's a cookie jar. He has a cookie in his hand. He's like, oh! He'...\n",
            "          diagnosis_ad_adrso250.wav           diagnosis_ad adrso250.wav                791         155       en        20      False What do you mean, the picture? Here's the picture. Tell me everything you see going on in that pictu...\n",
            "          diagnosis_ad_adrso025.wav           diagnosis_ad adrso025.wav               1030         200       en        37      False Tell me everything that's going on. I guess we're going to go on our... Corner. We're great. I think...\n",
            "          diagnosis_ad_adrso224.wav           diagnosis_ad adrso224.wav                659         138       en        15      False in the picture. Cookie jar. And two children. One, the boys up on a stool and a little girl standing...\n",
            "          diagnosis_ad_adrso031.wav           diagnosis_ad adrso031.wav                552         114       en        14      False Where do you see going on? The board is on the ladder and the ladder is to toe and not a ladder to s...\n",
            "          diagnosis_ad_adrso074.wav           diagnosis_ad adrso074.wav                539         110       en        14      False I see two kids up at the roof of the Jart 1 on the stool, out of standing on the floor. The cover do...\n",
            "          diagnosis_ad_adrso211.wav           diagnosis_ad adrso211.wav                819         167       en        18      False Look at that picture and tell me what you see a lot. An average home that looks very much like ours ...\n",
            "          diagnosis_ad_adrso229.wav           diagnosis_ad adrso229.wav               1042         201       en        38      False Okay, let's try something different, okay? Tell me what you see in that picture. Oh, the cookie jar....\n",
            "          diagnosis_ad_adrso197.wav           diagnosis_ad adrso197.wav                572         110       en        26      False The alert is. All right. And then, the girl's nose is cooking. And her voice is getting her one, tha...\n",
            "          diagnosis_ad_adrso049.wav           diagnosis_ad adrso049.wav                990         202       en        24      False And there's the picture all the action that you can see The little boy's having up in some cook cook...\n",
            "          diagnosis_ad_adrso138.wav           diagnosis_ad adrso138.wav                579         114       en        16      False Sure. And tell me everything that you see happening in that picture, everything that's going on in t...\n",
            "          diagnosis_ad_adrso123.wav           diagnosis_ad adrso123.wav                397          73       en        10      False Look at this picture. Tell me everything that you see going on in this picture. Everything that you ...\n",
            "          diagnosis_ad_adrso072.wav           diagnosis_ad adrso072.wav                589         113       en        18      False Tell me what's going on. Well, the kids are taking cookies out of the cookie jar. The other ones are...\n",
            "          diagnosis_ad_adrso027.wav           diagnosis_ad adrso027.wav                468          88       en        13      False Nice depiction. That's a little girl and a little boy standing on top of a stool and it looks like a...\n",
            "          diagnosis_ad_adrso068.wav           diagnosis_ad adrso068.wav                388          70       en        16      False Well, the kid has been falling off the stool. Yeah, these... And the mother's washing dishes, drying...\n",
            "          diagnosis_ad_adrso187.wav           diagnosis_ad adrso187.wav                716         143       en        20      False You see going on in the picture. Tell me all the action. Mm-hmm. Okay. There's a young boy going in ...\n",
            "          diagnosis_ad_adrso054.wav           diagnosis_ad adrso054.wav                787         156       en        29      False What's happening in that picture? What's happening there? Okay What else is going on I don't know if...\n",
            "          diagnosis_ad_adrso249.wav           diagnosis_ad adrso249.wav                462          88       en        14      False Okay. There, she's washing the dishes and there the kids are trying to get cookies out of the cookie...\n",
            "          diagnosis_ad_adrso200.wav           diagnosis_ad adrso200.wav               1187         241       en        42      False I'm going to look at the picture and tell me everything that you see going on in that picture. Tell ...\n",
            "          diagnosis_ad_adrso028.wav           diagnosis_ad adrso028.wav                438          88       en        16      False How she will find her mother who wishes to try the dishes. These tools are set. She's a bit long-giv...\n",
            "          diagnosis_ad_adrso053.wav           diagnosis_ad adrso053.wav               1077         214       en        30      False And there it is. Chair is tilting. Let us off of the cookie jar. Cooking another left arm of the boy...\n",
            "          diagnosis_ad_adrso078.wav           diagnosis_ad adrso078.wav                601         112       en        28      False I'm going to take a shower. Okay. Oh, my God. She's... And still in the water from... from washing t...\n",
            "          diagnosis_ad_adrso056.wav           diagnosis_ad adrso056.wav               1718         335       en        61      False Just tell me what's happening in the picture. We're on our arms, get a grip of the foot. See what I'...\n",
            "          diagnosis_ad_adrso245.wav           diagnosis_ad adrso245.wav                509         104       en        10      False I'm on in that picture. I'm very kind of not on the scene yet but so I was watching clothes I mean w...\n",
            "          diagnosis_ad_adrso092.wav           diagnosis_ad adrso092.wav                490          96       en        12      False I want you to take a look at that picture. Oh boy. I want you to tell me everything you see happenin...\n",
            "          diagnosis_ad_adrso134.wav           diagnosis_ad adrso134.wav                304          57       en         7      False Why don't you take a look at this picture? Tell me everything you see happening that picture everyth...\n",
            "          diagnosis_ad_adrso216.wav           diagnosis_ad adrso216.wav                361          66       en        18      False Oh, good. I want you to look at that picture. Then tell me everything that you see happening in the ...\n",
            "          diagnosis_ad_adrso142.wav           diagnosis_ad adrso142.wav                354          66       en         8      False What's happening in that picture? What do you see going on in there? Oh, here's the child reaching o...\n",
            "          diagnosis_ad_adrso077.wav           diagnosis_ad adrso077.wav                365          72       en        10      False You may like that woman doing the dishes and you know water running out in the sink, little blanket ...\n",
            "          diagnosis_ad_adrso198.wav           diagnosis_ad adrso198.wav                464          80       en        18      False What's going on in the picture? What do you see happening in that picture? I'm lazy. I'm lazy and I'...\n",
            "          diagnosis_ad_adrso220.wav           diagnosis_ad adrso220.wav                542         111       en        25      False Tell me all the action that you can see. Action. What's going on in the picture? It's a kid. I'm loo...\n",
            "          diagnosis_ad_adrso024.wav           diagnosis_ad adrso024.wav                934         195       en        31      False There's a cookie jar and the lid that is off the cookie jar. The boy is about to turn down the floor...\n",
            "          diagnosis_ad_adrso212.wav           diagnosis_ad adrso212.wav                820         168       en        21      False And here's the picture. The boy is taking cookies I'm getting to the ground. Those places put in my ...\n",
            "          diagnosis_ad_adrso046.wav           diagnosis_ad adrso046.wav                744         157       en        30      False But it's not real clear so do what you can with it. You see anything going on? Yeah, I see the woman...\n",
            "          diagnosis_ad_adrso233.wav           diagnosis_ad adrso233.wav                763         142       en        26      False And here's the picture. It's still turning over. She's gonna try to steal cookies out of the cookie ...\n",
            "          diagnosis_ad_adrso247.wav           diagnosis_ad adrso247.wav                884         174       en        23      False Oh, oh, oh, oh. No, boys, they're getting in the cookies. He's climbing up a chair and it's about fa...\n",
            "          diagnosis_ad_adrso035.wav           diagnosis_ad adrso035.wav                631         123       en        15      False Okay, here's the picture. Tell me how I'm going to tell you what's going on in the picture. Oh boy. ...\n",
            "          diagnosis_ad_adrso125.wav           diagnosis_ad adrso125.wav                571         108       en        22      False Take a look at this picture. Just tell me what you see going on in that picture. Tell me everything ...\n",
            "          diagnosis_ad_adrso188.wav           diagnosis_ad adrso188.wav                358          66       en        10      False This is the picture. Just tell me what I'm doing in the picture. The boy is slipping off the stool. ...\n",
            "          diagnosis_ad_adrso033.wav           diagnosis_ad adrso033.wav                570         113       en        26      False What's going on in the picture? In here? This way? Mm-hmm. I'm gonna don't know, because I have gott...\n",
            "          diagnosis_ad_adrso237.wav           diagnosis_ad adrso237.wav                498          96       en        11      False Now, everything that you see going on in that picture. Oh, the ladies drying their dishes. They had ...\n",
            "          diagnosis_ad_adrso253.wav           diagnosis_ad adrso253.wav                504         103       en        11      False Well, my boy is trying to get some cookies. And the girls hold her hand up because he has gotten one...\n",
            "          diagnosis_ad_adrso218.wav           diagnosis_ad adrso218.wav                427          80       en        13      False I wanted to tell me everything that you see going on in that picture. Just tell me everything that y...\n",
            "          diagnosis_ad_adrso144.wav           diagnosis_ad adrso144.wav                586         114       en        18      False Sure. Can you tell me now? Well, this one is in the cookie jar. And this is, she tried to climb the,...\n",
            "          diagnosis_ad_adrso032.wav           diagnosis_ad adrso032.wav                988         201       en        22      False What's going on in the kitchen? Well, the children are planning up and he's about to go out and get ...\n",
            "          diagnosis_ad_adrso246.wav           diagnosis_ad adrso246.wav                424          86       en        14      False Tell me what you see going on the picture. Well, the boy is in the cookie jar and the dog and his si...\n",
            "          diagnosis_cn_adrso173.wav           diagnosis_cn adrso173.wav                757         147       en        18      False And one of what you do is take a look at this picture and tell me everything that you see happening ...\n",
            "          diagnosis_cn_adrso015.wav           diagnosis_cn adrso015.wav                793         150       en        16      False Okay. I'm going to show you some pictures. Okay? Here's a picture. Tell me everything that you see g...\n",
            "          diagnosis_cn_adrso307.wav           diagnosis_cn adrso307.wav                912         179       en        29      False down in the picture. The boys, the girls make a fun of the boys. You may find them so much while he ...\n",
            "          diagnosis_cn_adrso283.wav           diagnosis_cn adrso283.wav                657         124       en        14      False There's a picture. Doesn't matter where you start, you know. Alright, there's a little boy on a step...\n",
            "          diagnosis_cn_adrso167.wav           diagnosis_cn adrso167.wav                874         174       en        10      False I'd like you to do is just look at the picture and tell me anything at all that you see going on. Ch...\n",
            "          diagnosis_cn_adrso168.wav           diagnosis_cn adrso168.wav                722         141       en        15      False Tell me everything that you see happening with that creature. Everything you see going on. Alright, ...\n",
            "          diagnosis_cn_adrso172.wav           diagnosis_cn adrso172.wav                710         132       en        17      False Good, and here's the picture. First of all, the sink is over-floating. Another is washing dishes or ...\n",
            "          diagnosis_cn_adrso292.wav           diagnosis_cn adrso292.wav                280          53       en        10      False Now let's sit. Joven and Dan Cookies. School's going to fall. The sink is overflowing. Another's was...\n",
            "          diagnosis_cn_adrso316.wav           diagnosis_cn adrso316.wav                562         107       en        10      False Sir, I'd like to tell you everything that you see going on in the picture. And that's the picture. A...\n",
            "          diagnosis_cn_adrso162.wav           diagnosis_cn adrso162.wav                710         131       en        23      False Okay, here's the picture. Okay, mother is drying the dishes, but the water is flowing out over the s...\n",
            "          diagnosis_cn_adrso278.wav           diagnosis_cn adrso278.wav                302          55       en         7      False Any action or anything you see? Oh, well, the same server flowing, the lady's washing dishes. The bo...\n",
            "          diagnosis_cn_adrso296.wav           diagnosis_cn adrso296.wav                860         161       en        22      False Ah, the sinks running over. Water's coming all over the floor. Here, the boy, the step ladders, turn...\n",
            "          diagnosis_cn_adrso300.wav           diagnosis_cn adrso300.wav                336          70       en         9      False I'm doing a child each and for a cookie. It's your third. You're all off the way moving there. I'm g...\n",
            "          diagnosis_cn_adrso291.wav           diagnosis_cn adrso291.wav               1020         209       en        17      False What I'd like you to do here is take a look at this picture and tell me everything that you see happ...\n",
            "          diagnosis_cn_adrso169.wav           diagnosis_cn adrso169.wav                294          52       en        11      False There's a kid stealing cookies from the cookie jar. Stools about to topple over. The sisters asking ...\n",
            "          diagnosis_cn_adrso178.wav           diagnosis_cn adrso178.wav                536         102       en        17      False But I want you to do to look at this picture and tell me everything that you see going all the way. ...\n",
            "          diagnosis_cn_adrso165.wav           diagnosis_cn adrso165.wav                447          86       en         9      False in the texture. They're all reaching out. The boy is taking cookies out of the cookie jar. The stool...\n",
            "          diagnosis_cn_adrso177.wav           diagnosis_cn adrso177.wav                691         132       en        16      False I want you to tell me everything that you see going on in this picture. Everything that you see happ...\n",
            "          diagnosis_cn_adrso262.wav           diagnosis_cn adrso262.wav                376          75       en         8      False Okay, you can start then. Okay, the mother is wiping a dish at the sink. The water is overflowing fr...\n",
            "          diagnosis_cn_adrso265.wav           diagnosis_cn adrso265.wav               1380         269       en        43      False Let me just look at the picture and tell her to make galore. Okay? This is going to be like looking ...\n",
            "          diagnosis_cn_adrso014.wav           diagnosis_cn adrso014.wav                697         134       en        16      False I see a woman who has zoned out. She's in the world of her own, obviously. She's not aware of what's...\n",
            "          diagnosis_cn_adrso021.wav           diagnosis_cn adrso021.wav                906         164       en        22      False Everything you see going on in this picture. Ground safety hazards as it referred to as a military. ...\n",
            "          diagnosis_cn_adrso268.wav           diagnosis_cn adrso268.wav                797         158       en        11      False Alright, the action I see is a little girl with her finger up to her mouth and one arm is thened up ...\n",
            "          diagnosis_cn_adrso261.wav           diagnosis_cn adrso261.wav                515         102       en        10      False A boy, a puppy in his one hand in the sand in the cookie jar, standing on a stool which is tipping o...\n",
            "          diagnosis_cn_adrso156.wav           diagnosis_cn adrso156.wav                508          98       en        14      False Just everything that you see happening. Oh, wow. Well, the money must be daydreaming because the wat...\n",
            "          diagnosis_cn_adrso148.wav           diagnosis_cn adrso148.wav               1330         259       en        36      False I wish you make us laugh. Are you ready? Well, the sink is overflowing. Let it was standing in the w...\n",
            "          diagnosis_cn_adrso016.wav           diagnosis_cn adrso016.wav                420          81       en        13      False Hmm, what a fall. Um, and safety problems. So this boy is getting cookies from a cookie jar and to t...\n",
            "          diagnosis_cn_adrso310.wav           diagnosis_cn adrso310.wav                542         107       en        18      False I just want you to tell me what you see going on in that picture. The water is running over. The ste...\n",
            "          diagnosis_cn_adrso302.wav           diagnosis_cn adrso302.wav                948         191       en        21      False We'll start with the girl she's Pointed we see will cookie her brothers her brothers taking cookies ...\n",
            "          diagnosis_cn_adrso308.wav           diagnosis_cn adrso308.wav                504         100       en        11      False It's a kitchen scene and the mother is doing the dishes. The children are trying to get into the coo...\n",
            "          diagnosis_cn_adrso018.wav           diagnosis_cn adrso018.wav                708         148       en        14      False Just look at this one and tell me everything you see going on Oh, mom Mommy having a good day She th...\n",
            "          diagnosis_cn_adrso309.wav           diagnosis_cn adrso309.wav                599         112       en        10      False I mean, picture. Tell me everything is going on in there. Mother is drying the dishes, looking out t...\n",
            "          diagnosis_cn_adrso298.wav           diagnosis_cn adrso298.wav                498          96       en        14      False A little girl is reaching for her brother to give her a cookie. The stool is falling over. The boy h...\n",
            "          diagnosis_cn_adrso180.wav           diagnosis_cn adrso180.wav                620         117       en         7      False Tell me everything you see happening in that picture. Everything that's going on there. I mean right...\n",
            "          diagnosis_cn_adrso154.wav           diagnosis_cn adrso154.wav                356          66       en        10      False That's the picture. Boy is taking cookies from the cookie jar, giving one to his sister, also fallin...\n",
            "          diagnosis_cn_adrso273.wav           diagnosis_cn adrso273.wav                520         102       en         9      False There's the two children are in the process of stealing cookies from the cookie jar. And the little ...\n",
            "          diagnosis_cn_adrso159.wav           diagnosis_cn adrso159.wav                350          68       en         9      False So, the action that you see going on in that picture. Anything that I want. Okay, the boys reaching ...\n",
            "          diagnosis_cn_adrso259.wav           diagnosis_cn adrso259.wav                965         179       en        22      False Okay. Okay. Many, all right. The mother is washing the dishes and the sink is overflowing. She has s...\n",
            "          diagnosis_cn_adrso151.wav           diagnosis_cn adrso151.wav                351          65       en         8      False Okay, here's the picture. All of the action you see going on. Boy, taking cookies out of the cookie ...\n",
            "          diagnosis_cn_adrso267.wav           diagnosis_cn adrso267.wav                460          87       en        10      False going on in the picture. Okay there it is. Yes, kind of. Kids are taking cookies from the cookie jar...\n",
            "          diagnosis_cn_adrso019.wav           diagnosis_cn adrso019.wav                708         139       en        10      False Okay little boy is on a stool that he looks like he's going to fall. He's going to the cookie jar an...\n",
            "          diagnosis_cn_adrso153.wav           diagnosis_cn adrso153.wav                397          66       en        25      False Start whenever you want. Cooked jar, a land standing on a stool, tearing, having other cookies. Sist...\n",
            "          diagnosis_cn_adrso274.wav           diagnosis_cn adrso274.wav               1458         294       en        34      False Alright, the boy is taking a cookie out of the cookie jar. He has one of his left hand to reach down...\n",
            "          diagnosis_cn_adrso023.wav           diagnosis_cn adrso023.wav                572         107       en        18      False Tell me everything you see going on in this picture. This one? Yes, ma'am. Oh, a little boy, six and...\n",
            "          diagnosis_cn_adrso012.wav           diagnosis_cn adrso012.wav                673         134       en        13      False Well, I see a kitchen and a housewife or a homemaker at the sink and her two kids are having a great...\n",
            "          diagnosis_cn_adrso002.wav           diagnosis_cn adrso002.wav                884         172       en        15      False Okay, I see a mom doing the dishes and the water's overflowing from the sink and she seems to be com...\n",
            "          diagnosis_cn_adrso022.wav           diagnosis_cn adrso022.wav                505          95       en         7      False And then here on this one, tell me everything you see going on in this picture. Well, I see the moth...\n",
            "          diagnosis_cn_adrso266.wav           diagnosis_cn adrso266.wav                463          87       en        17      False Tell me everything is the hand. I don't know. The girl was watching the boy going to the cookin' jar...\n",
            "          diagnosis_cn_adrso280.wav           diagnosis_cn adrso280.wav                844         163       en        20      False There's the picture. This little boy has a cookie jar. He has got no one on his stool, which is tipp...\n",
            "          diagnosis_cn_adrso152.wav           diagnosis_cn adrso152.wav                654         129       en        15      False Hello boys on the stool which is tipping over and he's getting into the cooking jar which is up in c...\n",
            "          diagnosis_cn_adrso007.wav           diagnosis_cn adrso007.wav                334          63       en         5      False A mother standing by the sink, kind of looks like lost and thought, wiping a dish. The sink is overf...\n",
            "          diagnosis_cn_adrso276.wav           diagnosis_cn adrso276.wav               2523         492       en        41      False Oh, it's the same picture. It should give you a different one. They're afraid too. Why? It could be ...\n",
            "          diagnosis_cn_adrso260.wav           diagnosis_cn adrso260.wav                498         100       en        17      False And you can begin right there. Well, the little boy is on a step stool trying to reach the cookie ja...\n",
            "          diagnosis_cn_adrso017.wav           diagnosis_cn adrso017.wav                876         175       en        23      False All right, we have a few more tasks to go through before we break for today. Okay. So, here's a pict...\n",
            "          diagnosis_cn_adrso005.wav           diagnosis_cn adrso005.wav                740         139       en        15      False Oh my, I'm such a mess that I think is overflowing. And I don't know why she's not even carrying. Sh...\n",
            "          diagnosis_cn_adrso299.wav           diagnosis_cn adrso299.wav                860         152       en        22      False Why don't you take a look at this picture? And I want you to tell me everything that's happening the...\n",
            "          diagnosis_cn_adrso157.wav           diagnosis_cn adrso157.wav                660         127       en        14      False Okay, and there's the picture. Oh, yes. Just go ahead and tell you. You just say the mother is dryin...\n",
            "          diagnosis_cn_adrso182.wav           diagnosis_cn adrso182.wav                621         119       en        11      False I'd like for you to take a look at this picture and tell me everything that you see happening in the...\n",
            "          diagnosis_cn_adrso008.wav           diagnosis_cn adrso008.wav                708         137       en        10      False Well, I see what seems to be a mother or could be a babysitter with two children, a boy and a girl. ...\n",
            "          diagnosis_cn_adrso161.wav           diagnosis_cn adrso161.wav                421          76       en         8      False Well, this little boy is up on his stool, taking cookies, handing him down to the sister, and she's ...\n",
            "          diagnosis_cn_adrso263.wav           diagnosis_cn adrso263.wav                503          88       en        20      False Okay, there's the fixer. Everything is there. You can miss house or whatever. Yeah. Uh-huh. You want...\n",
            "          diagnosis_cn_adrso257.wav           diagnosis_cn adrso257.wav                575         119       en        12      False Just look at the picture and tell me everything that you see. I'm going to get a copy of the cookie ...\n",
            "          diagnosis_cn_adrso164.wav           diagnosis_cn adrso164.wav                924         176       en        21      False What do you see going on? I see a little boy on the school and he's just falling over taking cookie-...\n",
            "          diagnosis_cn_adrso289.wav           diagnosis_cn adrso289.wav                590         104       en        30      False And that's the picture. Climbing, dishwasher, washing, pointing, stealing cookies, wind is blowing o...\n",
            "          diagnosis_cn_adrso270.wav           diagnosis_cn adrso270.wav                601         115       en        17      False The mother's arm trying to dish and the water's running over. And then the boy is taking cookies out...\n",
            "          diagnosis_cn_adrso264.wav           diagnosis_cn adrso264.wav                539          99       en        16      False And there's the picture. So yeah. Do I get to describe that everything? Yeah, I tell you that. Yeah,...\n",
            "          diagnosis_cn_adrso277.wav           diagnosis_cn adrso277.wav                568         118       en        21      False Don't do so in your research. They have a lot of action going on. What I need you to do is tell me a...\n",
            "          diagnosis_cn_adrso160.wav           diagnosis_cn adrso160.wav                417          80       en        12      False The first thing we're going to do is take a look at that picture and tell me everything you see happ...\n",
            "          diagnosis_cn_adrso186.wav           diagnosis_cn adrso186.wav                490          95       en        12      False Tell me everything you see happening in the bath pressure. Everything is going on there. Okay. On th...\n",
            "          diagnosis_cn_adrso003.wav           diagnosis_cn adrso003.wav                428          81       en         5      False Starting from the left, I see two children standing on a tipping stool, reaching for the cookie jar....\n",
            "          diagnosis_cn_adrso286.wav           diagnosis_cn adrso286.wav                706         134       en        20      False Tell me everything that you see going on in the picture. Just tell me what's happening there. Well, ...\n",
            "          diagnosis_cn_adrso285.wav           diagnosis_cn adrso285.wav                247          37       en         5      False Touching lip, raising arm, zappetune, the end time for cookie, handing cookie down, slipping from st...\n",
            "          diagnosis_cn_adrso170.wav           diagnosis_cn adrso170.wav                519         102       en        10      False I'll just take a lot of this picture and tell me everything you see is going on. Okay, the boy is st...\n",
            "          diagnosis_cn_adrso183.wav           diagnosis_cn adrso183.wav                822         156       en        22      False What should you tell me, everything you see happening in that picture? Everything that's going on th...\n",
            "          diagnosis_cn_adrso281.wav           diagnosis_cn adrso281.wav                634         129       en        17      False There's a cookie jar on the shelf. The old boy's up on a store and the store is about to fall. He's ...\n",
            "          diagnosis_cn_adrso010.wav           diagnosis_cn adrso010.wav                232          42       en         5      False Well, let's see, our mama appears to be busy doing the dishes. Wow, she's had a problem. The sink is...\n",
            "          diagnosis_cn_adrso315.wav           diagnosis_cn adrso315.wav                511          99       en        13      False Just the action. The girl is reaching for a cookie that the boy is trying to get water while he's Th...\n",
            "          diagnosis_cn_adrso312.wav           diagnosis_cn adrso312.wav                684         135       en        20      False What do you see going on in that picture? Oh, I see the sink that's running over. I see the stores t...\n",
            "          diagnosis_cn_adrso158.wav           diagnosis_cn adrso158.wav                574         114       en        14      False So now, yeah. The boy reaching on his own stool, reaching for cookies, and the stool is ready to fol...\n",
            "   progression_decline_adrsp055.wav    progression_decline adrsp055.wav                389          75       en        30      False Okay, I'll take how with the deer, the cat, a dog. That awful. A lion, tiger. A mouse count. Yes. Ye...\n",
            "   progression_decline_adrsp300.wav    progression_decline adrsp300.wav               1308         273       en        26      False And what I want you to do for me is in one minute's time I want you to name as many animals as you c...\n",
            "   progression_decline_adrsp003.wav    progression_decline adrsp003.wav                385          73       en        19      False Spine. Okay, thank you very much for me. Many animals as you can in one minute. Starting now. Just n...\n",
            "   progression_decline_adrsp266.wav    progression_decline adrsp266.wav                926         188       en        46      False You can start now. How's Figs? Chickens? She. I can't even think. You want me animals you can think ...\n",
            "   progression_decline_adrsp320.wav    progression_decline adrsp320.wav                821         156       en        19      False All the animals are Canadian in there. Ready? Go ahead. Camp, dog, drew, ranch, elephant, rhinoceros...\n",
            "   progression_decline_adrsp313.wav    progression_decline adrsp313.wav                681         133       en        38      False And you can start now. Just name them. Well, I can't. Okay. Dog. I think it's a neighbor's what they...\n",
            "   progression_decline_adrsp179.wav    progression_decline adrsp179.wav               1433         302       en        45      False I want you to try and tell me all the animals that you can think of. Or you just think of all the an...\n",
            "   progression_decline_adrsp051.wav    progression_decline adrsp051.wav                216          48       en        12      False Okay, and you can begin now. All of the ingredients. I bought one for you. Can I have three birds? O...\n",
            "   progression_decline_adrsp326.wav    progression_decline adrsp326.wav                522         110       en        19      False Can you name some animals for me? Any animal at all? Can you name some animals? Think of some animal...\n",
            "   progression_decline_adrsp101.wav    progression_decline adrsp101.wav                810         158       en        39      False Another monkey? But her again? Yeah, the sea Can't And forces them And There Got milk900 What colour...\n",
            "   progression_decline_adrsp127.wav    progression_decline adrsp127.wav                421          79       en        26      False Good, animals and you can begin now. That, okay. A goat, a horse, a dove. A bike. Okay, there's some...\n",
            "   progression_decline_adrsp357.wav    progression_decline adrsp357.wav               1303         256       en        59      False In one minute's time, and in that minute, I want to create a name as many animals as you can think o...\n",
            "   progression_decline_adrsp276.wav    progression_decline adrsp276.wav                983         209       en        37      False We're going to ask you if you want to see how many animals you can name for me in one minute. I'll t...\n",
            "   progression_decline_adrsp209.wav    progression_decline adrsp209.wav                386          73       en        36      False Where did you first meet? Oh, horse decay, okay. Rhino-stress elephant, monkey, bear, a deer, sheep,...\n",
            "   progression_decline_adrsp318.wav    progression_decline adrsp318.wav               1421         268       en        40      False Ready? I don't have anything to write. Just say it. Oh, say it. Okay. Okay. Cat dog horse. These... ...\n",
            "progression_no_decline_adrsp109.wav progression_no_decline adrsp109.wav                684         133       en        26      False Okay, one minute and you can begin now here I am Okay, go ahead. Okay, now I'm going to ask you to t...\n",
            "progression_no_decline_adrsp255.wav progression_no_decline adrsp255.wav                265          40       en        38      False Yoke. I was... Cal, dog, bear, bear, y'all and rhinoceros pink. Otter, bear, mask, snake, rhinoceros...\n",
            "progression_no_decline_adrsp306.wav progression_no_decline adrsp306.wav                874         178       en        41      False The name of the animals that you can think of you can start now. I can't think of that. Name all the...\n",
            "progression_no_decline_adrsp157.wav progression_no_decline adrsp157.wav               1066         189       en        24      False You can begin cat dog mouth, rabbit, lion, tarju, cellophons, bears, snakes. You consider a spanky m...\n",
            "progression_no_decline_adrsp197.wav progression_no_decline adrsp197.wav                771         156       en        45      False Oh, the Y-O, the Y-O. The Y-O. A Y-O. L-L-L-M's. Okay. Of course it's called L-L-M's. Dolls, cats. O...\n",
            "progression_no_decline_adrsp031.wav progression_no_decline adrsp031.wav                250          41       en        26      False okay stop There you go. Push those hands. Squirrels. Rabbit. Snikes. Birds. Hey! Let's go. A farm, f...\n",
            "progression_no_decline_adrsp368.wav progression_no_decline adrsp368.wav                973         200       en        43      False This is an example for us to try. Can, rabbit, an elephant, zebra, kangaroo, and a parrot bear. I'm ...\n",
            "progression_no_decline_adrsp032.wav progression_no_decline adrsp032.wav                948         191       en        46      False You can begin now. The cat, mouse, uh, Do you support one of your dolls? Any kind of... No birds or ...\n",
            "progression_no_decline_adrsp091.wav progression_no_decline adrsp091.wav               1143         234       en        37      False As many animals as you can think of and you can begin now. Dogs, horses, no birds. Oh my god. Can yo...\n",
            "progression_no_decline_adrsp124.wav progression_no_decline adrsp124.wav                452          83       en        31      False You can think of it in a minute, starting now. Dog, cat, elephant, horse, kangaroo, or a man. Dog, c...\n",
            "progression_no_decline_adrsp344.wav progression_no_decline adrsp344.wav                684         123       en        27      False Beginning now. Horse, cow, sheep, goats, mules, jyrab, elephant, ipopodermus rhinoceros, rabbits, ra...\n",
            "progression_no_decline_adrsp195.wav progression_no_decline adrsp195.wav                334          65       en        15      False Hey. And you can begin now. Horse, cow, a lamb, a cat, dog, deer. A mouse, a rat, a goat, lamb. I sa...\n",
            "progression_no_decline_adrsp253.wav progression_no_decline adrsp253.wav                325          59       en         9      False Aren't we onions? Ice that is such a thing, you know, bugs. There is so many things you have to do. ...\n",
            "progression_no_decline_adrsp039.wav progression_no_decline adrsp039.wav                624         115       en        53      False Is there something on your body? I don't know. Shit. Cats, dogs, frogs, that's on the face. Snake. A...\n",
            "progression_no_decline_adrsp251.wav progression_no_decline adrsp251.wav                274          50       en        25      False Okay, get dog horse. No, spider one did that, didn't it? Okay. No, it's us. Elephant. You can get on...\n",
            "progression_no_decline_adrsp001.wav progression_no_decline adrsp001.wav               1478         283       en        72      False Okay, you can stop now. Elephants. Zebra. That's... A dog. Cat. A rat. That's not a human. I don't k...\n",
            "progression_no_decline_adrsp207.wav progression_no_decline adrsp207.wav                370          62       en        12      False Yeah, yo, yo, how's it you can think of? OK, start now. OK, pig, cow, horse, pig, animals, dog, donk...\n",
            "progression_no_decline_adrsp041.wav progression_no_decline adrsp041.wav                946         182       en        44      False Okay, and you can begin now. Oh, Bear camel. Same as with the cowboys chicken. Oh, cowboys. Have it....\n",
            "progression_no_decline_adrsp324.wav progression_no_decline adrsp324.wav                439          96       en        22      False Any animals at all? Cow. Good. Think of another one? Horse. I'll tell you I'm just all confused. Thi...\n",
            "progression_no_decline_adrsp379.wav progression_no_decline adrsp379.wav                753         147       en        27      False Ready? Go in. Okay. Horses, pigs. Lamb, sheep, cows, chickens. Excuse me. Thank you. Theo. Okay, tha...\n",
            "progression_no_decline_adrsp384.wav progression_no_decline adrsp384.wav                775         150       en        39      False Give me all the animals you can think of. Go ahead. Cap? Dog? Big? Go? Ear? Horse? Baby? Bear? Bear?...\n",
            "progression_no_decline_adrsp177.wav progression_no_decline adrsp177.wav                766         148       en        28      False And you can begin now. Okay, rabbit, dog, cat, let's see, horse, new pig, cow, let's see, there's so...\n",
            "progression_no_decline_adrsp023.wav progression_no_decline adrsp023.wav                436          84       en        21      False And then it's soaking from now. Of course, the cow dog. She maybe is meant to go. Okay, all right. A...\n",
            "progression_no_decline_adrsp148.wav progression_no_decline adrsp148.wav                868         165       en        37      False Okay, good. For the fish. Any of the other ones, you can begin now. Dawn, cat, carrot, can I have a ...\n",
            "progression_no_decline_adrsp122.wav progression_no_decline adrsp122.wav                409          66       en        37      False Just use all the animal shooting sinkhole. Off you go. Doug cat, horse cow sheep, Mew, lion tiger, c...\n",
            "progression_no_decline_adrsp359.wav progression_no_decline adrsp359.wav               1257         253       en        60      False Good thing I'll be in a minute's time. Okay, ready? Go ahead. A horse. Right. A cow. A dog. A cat. I...\n",
            "progression_no_decline_adrsp030.wav progression_no_decline adrsp030.wav                338          66       en        23      False I can, I can. You can start now. Dogs, fly in zebra. I'm not a fast enough. A horse. Donkey. Monkeys...\n",
            "progression_no_decline_adrsp319.wav progression_no_decline adrsp319.wav                312          54       en        26      False Yo, it's called Yo, and you can start now. Um, Cat. Rabbit. Mouse. Right. Chicken. Orch. Monkey. Um....\n",
            "progression_no_decline_adrsp200.wav progression_no_decline adrsp200.wav                544          94       en        22      False Oh, yeah, you can think of one minute you can start now everything but fish and birds. Cat dog, elep...\n",
            "progression_no_decline_adrsp193.wav progression_no_decline adrsp193.wav                448          88       en        20      False Now, Doug, a cat and elephant that deer, a goat and a cow, a horse, a monkey, and a donkey and a cow...\n",
            "progression_no_decline_adrsp378.wav progression_no_decline adrsp378.wav               1614         325       en        71      False Did you know? My nostrils. What else? Dog. Cat. Or, you don't want no birds, you say? No birds. Um, ...\n",
            "progression_no_decline_adrsp128.wav progression_no_decline adrsp128.wav               1089         191       en        60      False And one minute, and you can begin? No. I do not. There. Camel. Here. Hell. Uh, uh, uh, Fawn and FBWN...\n",
            "progression_no_decline_adrsp161.wav progression_no_decline adrsp161.wav                942         179       en        40      False And you can begin now. Cat dog mouse, cow horse, an ox, elephant, a monkey, a lion. Okay, group. Cat...\n",
            "progression_no_decline_adrsp192.wav progression_no_decline adrsp192.wav                459          84       en         8      False We go with the calf, the dog, the rat, the cow, the chickens, the goats, the horses, the deer, the r...\n",
            "progression_no_decline_adrsp196.wav progression_no_decline adrsp196.wav                658         142       en        33      False And you can start now. Name the animals for me. Oh, I Want you to do it here? No, I want you to know...\n",
            "progression_no_decline_adrsp136.wav progression_no_decline adrsp136.wav                993         188       en        27      False Yeah, off you go. Now you, you don't want anything like the animal, like caliber, anything like that...\n",
            "progression_no_decline_adrsp130.wav progression_no_decline adrsp130.wav                464          86       en        13      False dog rabbit, chipmunk, red squirrel, and horses, cows, horses, cows. How's it going? You want to thin...\n",
            "progression_no_decline_adrsp024.wav progression_no_decline adrsp024.wav                275          43       en         9      False Okay, cat, dog, chicken, rooster, pig, sheep, goat, cow, horse, pony, zebra, lion, tiger, hamper, le...\n",
            "progression_no_decline_adrsp007.wav progression_no_decline adrsp007.wav                575         107       en        24      False Are you ready? Stop now. Dog, cat, horse, cow, kangaroo, lion, tiger, elephant, giraffe, pig, skunk,...\n",
            "progression_no_decline_adrsp382.wav progression_no_decline adrsp382.wav                948         184       en        14      False Elephant, Tider, Bear, Monkey, Giraffe, Elephant, King of the Rube, Camel, Bear, Lion, Elephant, the...\n",
            "progression_no_decline_adrsp349.wav progression_no_decline adrsp349.wav                589         101       en        11      False And now, okay, cat, dog, canary, fish, rhinoceros, tiger, lion, monkey, hippopotamus, zebra, horse, ...\n",
            "progression_no_decline_adrsp321.wav progression_no_decline adrsp321.wav                359          72       en        21      False Begin now animals were horse to cow a sheep a deer a rabbit Dog a cat a mouse A horse I guess I used...\n",
            "progression_no_decline_adrsp043.wav progression_no_decline adrsp043.wav               1263         206       en        15      False Many animals as you can think of in one minute you can begin now. Dog, cat, horse, donkey, chicken, ...\n",
            "progression_no_decline_adrsp198.wav progression_no_decline adrsp198.wav                478          83       en        17      False And you can begin now. Kangaroo, horses, dogs, alligators. Oh, that's a fish. Yeah. Wall versus, oh,...\n",
            "progression_no_decline_adrsp019.wav progression_no_decline adrsp019.wav                819         153       en        33      False Why am I here? Similar idea. But this time, words beginning with the letter S. Words beginning with ...\n",
            "progression_no_decline_adrsp333.wav progression_no_decline adrsp333.wav                565          98       en        39      False can start now. Cow, horse, pony, sheep, hippopotamus, rhinoceros, rabbit, chicken, dog, cat, snake, ...\n",
            "progression_no_decline_adrsp310.wav progression_no_decline adrsp310.wav                334          57       en        20      False Thanks, thank you again, horse-carl, cheese, rug. Buffalo Tell you Is 9 today. You. Not bad enough s...\n",
            "progression_no_decline_adrsp137.wav progression_no_decline adrsp137.wav               1103         208       en        28      False Now, they can be farm animals, they can be zoo animals, or they can be pet animals, but it can't be ...\n",
            "progression_no_decline_adrsp380.wav progression_no_decline adrsp380.wav                202          40       en        11      False all the animals you can think of. You can start having. Oh, I thought I had to wait till the... No, ...\n",
            "progression_no_decline_adrsp056.wav progression_no_decline adrsp056.wav                547          96       en        36      False Dawn, cat, horse. Any more? Animals. Mm-hmm. Many animals as you can think. Motion. Help. Wild anima...\n",
            "progression_no_decline_adrsp028.wav progression_no_decline adrsp028.wav               1383         264       en        68      False Okay, do you want me to go through that again? Yes. Yeah. Okay. Well, you do tell me as many animals...\n",
            "progression_no_decline_adrsp096.wav progression_no_decline adrsp096.wav               1077         219       en        38      False You can begin now Okay You're about 40 seconds Countfelt Have you got to have worse there okay cours...\n",
            "progression_no_decline_adrsp052.wav progression_no_decline adrsp052.wav                656         126       en        41      False can be done. Okay, you start then. Go on. Dog, cat, you say fish, flowers, my mouse. Did I say dog? ...\n",
            "progression_no_decline_adrsp042.wav progression_no_decline adrsp042.wav                708          75       en        25      False That's why I have to get this. Mine, Tiger, elephant, giraffe, monkey, ape, camel, pig, cow, horse, ...\n",
            "progression_no_decline_adrsp377.wav progression_no_decline adrsp377.wav                439          79       en        19      False I think of it and you can start now. Cat dog, mass horse, zebra elephant. I'm gonna get to the zoo. ...\n",
            "progression_no_decline_adrsp350.wav progression_no_decline adrsp350.wav                845         172       en        56      False A yolk. Yeah. Okay. Start now. Yeah, that's dull. Mm-hmm. Cat. What's the heart? An elephant. Okay. ...\n",
            "progression_no_decline_adrsp363.wav progression_no_decline adrsp363.wav               1045         213       en        59      False Are you a minute? Maybe all the animals you can put there. Ready? Go ahead. Down. Get. Um. Of course...\n",
            "progression_no_decline_adrsp204.wav progression_no_decline adrsp204.wav               1697         349       en        73      False Animals as you can think of and you can start now. Dog, cat. Dog and cat. Animals. I don't know. Nam...\n",
            "      progression_test_adrspt15.wav       progression_test adrspt15.wav                739         156       en        40      False When you can begin, now. Okay, horse, cow, dog. Horse, um, horse cow, dog. A cat. Can I say a cow? J...\n",
            "      progression_test_adrspt20.wav       progression_test adrspt20.wav                781         155       en        38      False Ready? One minute time for the animals. Go ahead a bit. Drunk, cat, mouse, um... Um... Hey, um... Dr...\n",
            "       progression_test_adrspt4.wav       progression_test  adrspt4.wav                890         169       en        48      False Ready? Go ahead, Tom. Squirrel. Rabbit. Fox. Bear. Tiger. Bear. Bear. Bear. Did I say horse? Bear. B...\n",
            "      progression_test_adrspt27.wav       progression_test adrspt27.wav                877         173       en        25      False You can start now, name some animals for me. Those horses and cows and... The mule and the horses ar...\n",
            "      progression_test_adrspt16.wav       progression_test adrspt16.wav                545         112       en        21      False Dogs Fear Yes How many more years to have them you still have 30 seconds Rabbit fish did I say schoo...\n",
            "      progression_test_adrspt28.wav       progression_test adrspt28.wav                497          80       en        35      False Cat, dog. You say firemanals? Oh, me animals, you can think of. Cow, horse, sheep, lamb. Did I say c...\n",
            "       progression_test_adrspt9.wav       progression_test  adrspt9.wav                550         105       en        16      False All the animals that you can think of in one minute, starting from now. Alright, auction, votes, rac...\n",
            "      progression_test_adrspt10.wav       progression_test adrspt10.wav               1057         217       en        44      False Okay, you can begin now. Many animals. Animals. Um. Um. So on. Okay. So on. Okay. So on. Okay. I don...\n",
            "      progression_test_adrspt26.wav       progression_test adrspt26.wav                968         198       en        32      False In it. So you go ahead now and name for me as many animals as you can think of. Go ahead. Oh. Quite ...\n",
            "      progression_test_adrspt13.wav       progression_test adrspt13.wav                451          84       en        36      False or really no. Y teaching. For that. Robin. Bluejay. And the animal you send there are lions. Zebra. ...\n",
            "      progression_test_adrspt31.wav       progression_test adrspt31.wav                608         110       en        42      False Hmm. I don't know. Okay, sort of with the Y-O sounds like Yo. Not that I'm not doing right here. Yo....\n",
            "      progression_test_adrspt23.wav       progression_test adrspt23.wav                796         155       en        30      False That's fine. Okay, I'll just make a thing and you can start now. Peaks, chickens, horses, cows, mues...\n",
            "      progression_test_adrspt14.wav       progression_test adrspt14.wav                811         153       en        47      False You can begin. No. Raccoon, elephant, cow. Rabbit. Lizard. It's like I'm probably seeing lizard. Hor...\n",
            "      progression_test_adrspt12.wav       progression_test adrspt12.wav                110          22       en        14      False She got it. Yeah. Done. Of course. Okay. Okay. Yeah. Yes. So. okay I think we can figure Teilik Alix...\n",
            "      progression_test_adrspt32.wav       progression_test adrspt32.wav                891         166       en        41      False Okay, any animals that you like? Okay. Moodle, horse and cow, elephant and rhinoceros and lion and t...\n",
            "       progression_test_adrspt6.wav       progression_test  adrspt6.wav               1730         343       en        77      False Ready? I'm gonna give you a minute. You start naming the animals for me. Oh. Don't have a... and a.....\n",
            "       progression_test_adrspt1.wav       progression_test  adrspt1.wav                487          94       en        21      False So the name for me animals and you can begin now. Oh, cat, dog, deer, um, fish, is that in good? Oh,...\n",
            "      progression_test_adrspt21.wav       progression_test adrspt21.wav               1140         201       en        32      False Okay, good. You can begin now. Duck cow, bees, squirrels, cows, horses, pigs, lambs, use sheep. Oh, ...\n",
            "      progression_test_adrspt30.wav       progression_test adrspt30.wav                249          53       en        19      False Are you gonna get no dog cat lion elephant giraffe cow horse new donkey and camel lion lion tiger go...\n",
            "      progression_test_adrspt29.wav       progression_test adrspt29.wav                767         132       en        26      False And now. OK, a dog cat, Squirrel, Rabbit, Dear, Bear, Possum, Ratcune, Elephant, Zebrae, Camel, Donk...\n",
            "       progression_test_adrspt8.wav       progression_test  adrspt8.wav               1187         223       en        39      False Get ready, go ahead. Cat, dog, mouse, cow, pig, horse, donkey. Is that alright so far? That's fine. ...\n",
            "       progression_test_adrspt3.wav       progression_test  adrspt3.wav                267          50       en        22      False I'm sorry, I'm one minute starting now. You know, I'm the cat. Of course, cow, pig, um, elephant, le...\n",
            "      progression_test_adrspt19.wav       progression_test adrspt19.wav                659         130       en        32      False There's many animals as you can think of. Tony, worse, cow, pig. Chicken, turkey, fox, zebra. Okay. ...\n",
            "      progression_test_adrspt18.wav       progression_test adrspt18.wav                403          83       en        12      False Okay, that's fine. Name as many animals as you can for me, okay? Jeref, Lion, Tiger, Cow, a bull, Je...\n",
            "      progression_test_adrspt24.wav       progression_test adrspt24.wav                642         127       en        34      False Okay, in a minute, some. Wow. Mm-hmm. An alligator, a dog, a cat. Oh, let's see, a bird, that's not ...\n",
            "       progression_test_adrspt2.wav       progression_test  adrspt2.wav                400          70       en        34      False Okay, fine. Yeah. Oh, of course. Tiger, lion. Lofan. Giraffe, monkey. Yeah. Yeah. No fish, no. Yeah,...\n",
            "      progression_test_adrspt25.wav       progression_test adrspt25.wav                974         195       en        46      False I have to start. I think it is many animals as you can think of and you can begin now. No, look at t...\n",
            "      progression_test_adrspt17.wav       progression_test adrspt17.wav                169          29       en         4      False Okay, all the animals you can think of and you can start now. Cow, horse, rabbit squirrel, chipmunk,...\n",
            "      progression_test_adrspt11.wav       progression_test adrspt11.wav                451          85       en        31      False Oh, okay. And you can begin now. Oh. Name it from morning. Uh, farm animals you've said. As many ani...\n",
            "      progression_test_adrspt22.wav       progression_test adrspt22.wav                804         161       en        36      False Hey, my all the animals you can think of and you can begin now. Chad, dog, animals, lamb, sheep, goa...\n",
            "       progression_test_adrspt7.wav       progression_test  adrspt7.wav                918         186       en        42      False Any hair? Could we have an elephant? An elephant goes to do this. Give me all of these animals you c...\n",
            "       progression_test_adrspt5.wav       progression_test  adrspt5.wav               1202         234       en        67      False Off you go. Well, can we get my surrounding animals? No. I'll say, helophon. Any more? Is it alright...\n",
            "\n",
            "==================================================\n",
            "Step 5: Extracting linguistic features for BERT...\n",
            "Extracting linguistic features...\n",
            "\n",
            "Pipeline completed successfully!\n",
            "Results saved to: /content\n",
            "\n",
            "Output files:\n",
            "  - Transcripts: /content/transcripts/\n",
            "  - Transcript summary: /content/transcript_summary.csv\n",
            "  - Linguistic features: /content/linguistic_features.pkl\n",
            "\n",
            "============================================================\n",
            "EXTRACTING ACOUSTIC FEATURES FOR MODEL TRAINING\n",
            "============================================================\n",
            "\n",
            "Processing diagnosis_ad...\n",
            "  Extracting features for adrso047.wav...\n",
            "  Extracting features for adrso128.wav...\n",
            "  Extracting features for adrso110.wav...\n",
            "  Extracting features for adrso036.wav...\n",
            "  Extracting features for adrso045.wav...\n",
            "  Extracting features for adrso093.wav...\n",
            "  Extracting features for adrso112.wav...\n",
            "  Extracting features for adrso189.wav...\n",
            "  Extracting features for adrso089.wav...\n",
            "  Extracting features for adrso205.wav...\n",
            "  Extracting features for adrso060.wav...\n",
            "  Extracting features for adrso232.wav...\n",
            "  Extracting features for adrso075.wav...\n",
            "  Extracting features for adrso106.wav...\n",
            "  Extracting features for adrso063.wav...\n",
            "  Extracting features for adrso043.wav...\n",
            "  Extracting features for adrso206.wav...\n",
            "  Extracting features for adrso126.wav...\n",
            "  Extracting features for adrso109.wav...\n",
            "  Extracting features for adrso202.wav...\n",
            "  Extracting features for adrso071.wav...\n",
            "  Extracting features for adrso039.wav...\n",
            "  Extracting features for adrso209.wav...\n",
            "  Extracting features for adrso228.wav...\n",
            "  Extracting features for adrso122.wav...\n",
            "  Extracting features for adrso116.wav...\n",
            "  Extracting features for adrso244.wav...\n",
            "  Extracting features for adrso141.wav...\n",
            "  Extracting features for adrso248.wav...\n",
            "  Extracting features for adrso130.wav...\n",
            "  Extracting features for adrso055.wav...\n",
            "  Extracting features for adrso070.wav...\n",
            "  Extracting features for adrso222.wav...\n",
            "  Extracting features for adrso190.wav...\n",
            "  Extracting features for adrso223.wav...\n",
            "  Extracting features for adrso215.wav...\n",
            "  Extracting features for adrso234.wav...\n",
            "  Extracting features for adrso236.wav...\n",
            "  Extracting features for adrso059.wav...\n",
            "  Extracting features for adrso098.wav...\n",
            "  Extracting features for adrso192.wav...\n",
            "  Extracting features for adrso090.wav...\n",
            "  Extracting features for adrso250.wav...\n",
            "  Extracting features for adrso025.wav...\n",
            "  Extracting features for adrso224.wav...\n",
            "  Extracting features for adrso031.wav...\n",
            "  Extracting features for adrso074.wav...\n",
            "  Extracting features for adrso211.wav...\n",
            "  Extracting features for adrso229.wav...\n",
            "  Extracting features for adrso197.wav...\n",
            "  Extracting features for adrso049.wav...\n",
            "  Extracting features for adrso138.wav...\n",
            "  Extracting features for adrso123.wav...\n",
            "  Extracting features for adrso072.wav...\n",
            "  Extracting features for adrso027.wav...\n",
            "  Extracting features for adrso068.wav...\n",
            "  Extracting features for adrso187.wav...\n",
            "  Extracting features for adrso054.wav...\n",
            "  Extracting features for adrso249.wav...\n",
            "  Extracting features for adrso200.wav...\n",
            "  Extracting features for adrso028.wav...\n",
            "  Extracting features for adrso053.wav...\n",
            "  Extracting features for adrso078.wav...\n",
            "  Extracting features for adrso056.wav...\n",
            "  Extracting features for adrso245.wav...\n",
            "  Extracting features for adrso092.wav...\n",
            "  Extracting features for adrso134.wav...\n",
            "  Extracting features for adrso216.wav...\n",
            "  Extracting features for adrso142.wav...\n",
            "  Extracting features for adrso077.wav...\n",
            "  Extracting features for adrso198.wav...\n",
            "  Extracting features for adrso220.wav...\n",
            "  Extracting features for adrso024.wav...\n",
            "  Extracting features for adrso212.wav...\n",
            "  Extracting features for adrso046.wav...\n",
            "  Extracting features for adrso233.wav...\n",
            "  Extracting features for adrso247.wav...\n",
            "  Extracting features for adrso035.wav...\n",
            "  Extracting features for adrso125.wav...\n",
            "  Extracting features for adrso188.wav...\n",
            "  Extracting features for adrso033.wav...\n",
            "  Extracting features for adrso237.wav...\n",
            "  Extracting features for adrso253.wav...\n",
            "  Extracting features for adrso218.wav...\n",
            "  Extracting features for adrso144.wav...\n",
            "  Extracting features for adrso032.wav...\n",
            "  Extracting features for adrso246.wav...\n",
            "\n",
            "Processing diagnosis_cn...\n",
            "  Extracting features for adrso173.wav...\n",
            "  Extracting features for adrso015.wav...\n",
            "  Extracting features for adrso307.wav...\n",
            "  Extracting features for adrso283.wav...\n",
            "  Extracting features for adrso167.wav...\n",
            "  Extracting features for adrso168.wav...\n",
            "  Extracting features for adrso172.wav...\n",
            "  Extracting features for adrso292.wav...\n",
            "  Extracting features for adrso316.wav...\n",
            "  Extracting features for adrso162.wav...\n",
            "  Extracting features for adrso278.wav...\n",
            "  Extracting features for adrso296.wav...\n",
            "  Extracting features for adrso300.wav...\n",
            "  Extracting features for adrso291.wav...\n",
            "  Extracting features for adrso169.wav...\n",
            "  Extracting features for adrso178.wav...\n",
            "  Extracting features for adrso165.wav...\n",
            "  Extracting features for adrso177.wav...\n",
            "  Extracting features for adrso262.wav...\n",
            "  Extracting features for adrso265.wav...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cU-HI2DE50DC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMMMQuEBm2//4JaBUR71sZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}