{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMS7b4WLanKzysa1XtTW/BW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/ADReSSo21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4B7Zj3PzRLv",
        "outputId": "2cfa641e-1a59-468a-d566-e0a2456d4367"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.13.2)\n",
            "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.3 pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-by-Step Audio Transcript Extractor for ADReSSo21 Dataset\n",
        "# This script will:\n",
        "# 1. Mount Google Drive\n",
        "# 2. Extract dataset files\n",
        "# 3. Find all WAV files\n",
        "# 4. Extract transcripts from audio using speech recognition\n",
        "# 5. Save organized transcripts\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import librosa\n",
        "import speech_recognition as sr\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ADReSSo21 AUDIO TRANSCRIPT EXTRACTOR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# STEP 1: MOUNT GOOGLE DRIVE\n",
        "print(\"\\nSTEP 1: Mounting Google Drive...\")\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"✓ Google Drive mounted successfully!\")\n",
        "except:\n",
        "    print(\"⚠ Not running in Colab or Drive already mounted\")\n",
        "\n",
        "# STEP 2: INSTALL REQUIRED PACKAGES\n",
        "print(\"\\nSTEP 2: Installing required packages...\")\n",
        "print(\"Installing speech recognition and audio processing libraries...\")\n",
        "\n",
        "# Install packages (run once)\n",
        "!pip install SpeechRecognition\n",
        "!pip install pydub\n",
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "print(\"✓ Packages ready (make sure to install them first)\")\n",
        "\n",
        "# STEP 3: SET UP PATHS AND CONFIGURATION\n",
        "print(\"\\nSTEP 3: Setting up paths and configuration...\")\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/Voice/\"\n",
        "EXTRACT_PATH = \"/content/drive/MyDrive/Voice/extracted/\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/Voice/transcripts/\"\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(EXTRACT_PATH, exist_ok=True)\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "datasets = {\n",
        "    'progression_train': 'ADReSSo21-progression-train.tgz',\n",
        "    'progression_test': 'ADReSSo21-progression-test.tgz',\n",
        "    'diagnosis_train': 'ADReSSo21-diagnosis-train.tgz'\n",
        "}\n",
        "\n",
        "print(f\"✓ Base path: {BASE_PATH}\")\n",
        "print(f\"✓ Extract path: {EXTRACT_PATH}\")\n",
        "print(f\"✓ Output path: {OUTPUT_PATH}\")\n",
        "\n",
        "# STEP 4: EXTRACT DATASET FILES\n",
        "print(\"\\nSTEP 4: Extracting dataset files...\")\n",
        "\n",
        "def extract_datasets():\n",
        "    \"\"\"Extract all tgz files\"\"\"\n",
        "    for dataset_name, filename in datasets.items():\n",
        "        file_path = os.path.join(BASE_PATH, filename)\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"  Extracting {filename}...\")\n",
        "            try:\n",
        "                with tarfile.open(file_path, 'r:gz') as tar:\n",
        "                    tar.extractall(path=EXTRACT_PATH)\n",
        "                print(f\"  ✓ {filename} extracted successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ⚠ Error extracting {filename}: {e}\")\n",
        "        else:\n",
        "            print(f\"  ⚠ {filename} not found at {file_path}\")\n",
        "\n",
        "extract_datasets()\n",
        "\n",
        "# STEP 5: FIND ALL WAV FILES\n",
        "print(\"\\nSTEP 5: Finding all WAV files...\")\n",
        "\n",
        "def find_wav_files():\n",
        "    \"\"\"Find all WAV files and organize by dataset and label\"\"\"\n",
        "    wav_files = {\n",
        "        'progression_train': {'decline': [], 'no_decline': []},\n",
        "        'progression_test': [],\n",
        "        'diagnosis_train': {'ad': [], 'cn': []}\n",
        "    }\n",
        "\n",
        "    # Progression training files\n",
        "    prog_train_base = os.path.join(EXTRACT_PATH, \"ADReSSo21/progression/train/audio/\")\n",
        "\n",
        "    # Decline cases\n",
        "    decline_path = os.path.join(prog_train_base, \"decline/\")\n",
        "    if os.path.exists(decline_path):\n",
        "        decline_wavs = [f for f in os.listdir(decline_path) if f.endswith('.wav')]\n",
        "        wav_files['progression_train']['decline'] = [os.path.join(decline_path, f) for f in decline_wavs]\n",
        "        print(f\"  Found {len(decline_wavs)} decline WAV files\")\n",
        "\n",
        "    # No decline cases\n",
        "    no_decline_path = os.path.join(prog_train_base, \"no_decline/\")\n",
        "    if os.path.exists(no_decline_path):\n",
        "        no_decline_wavs = [f for f in os.listdir(no_decline_path) if f.endswith('.wav')]\n",
        "        wav_files['progression_train']['no_decline'] = [os.path.join(no_decline_path, f) for f in no_decline_wavs]\n",
        "        print(f\"  Found {len(no_decline_wavs)} no_decline WAV files\")\n",
        "\n",
        "    # Progression test files\n",
        "    prog_test_path = os.path.join(EXTRACT_PATH, \"ADReSSo21/progression/test-dist/audio/\")\n",
        "    if os.path.exists(prog_test_path):\n",
        "        test_wavs = [f for f in os.listdir(prog_test_path) if f.endswith('.wav')]\n",
        "        wav_files['progression_test'] = [os.path.join(prog_test_path, f) for f in test_wavs]\n",
        "        print(f\"  Found {len(test_wavs)} test WAV files\")\n",
        "\n",
        "    # Diagnosis training files\n",
        "    diag_train_base = os.path.join(EXTRACT_PATH, \"ADReSSo21/diagnosis/train/audio/\")\n",
        "\n",
        "    # AD cases\n",
        "    ad_path = os.path.join(diag_train_base, \"ad/\")\n",
        "    if os.path.exists(ad_path):\n",
        "        ad_wavs = [f for f in os.listdir(ad_path) if f.endswith('.wav')]\n",
        "        wav_files['diagnosis_train']['ad'] = [os.path.join(ad_path, f) for f in ad_wavs]\n",
        "        print(f\"  Found {len(ad_wavs)} AD WAV files\")\n",
        "\n",
        "    # CN cases\n",
        "    cn_path = os.path.join(diag_train_base, \"cn/\")\n",
        "    if os.path.exists(cn_path):\n",
        "        cn_wavs = [f for f in os.listdir(cn_path) if f.endswith('.wav')]\n",
        "        wav_files['diagnosis_train']['cn'] = [os.path.join(cn_path, f) for f in cn_wavs]\n",
        "        print(f\"  Found {len(cn_wavs)} CN WAV files\")\n",
        "\n",
        "    return wav_files\n",
        "\n",
        "wav_files = find_wav_files()\n",
        "\n",
        "# STEP 6: AUDIO PREPROCESSING FUNCTIONS\n",
        "print(\"\\nSTEP 6: Setting up audio preprocessing...\")\n",
        "\n",
        "def preprocess_audio(audio_path, target_sr=16000):\n",
        "    \"\"\"Preprocess audio file for speech recognition\"\"\"\n",
        "    try:\n",
        "        # Load audio with librosa\n",
        "        audio, sr = librosa.load(audio_path, sr=target_sr)\n",
        "\n",
        "        # Normalize audio\n",
        "        audio = librosa.util.normalize(audio)\n",
        "\n",
        "        # Remove silence\n",
        "        audio_trimmed, _ = librosa.effects.trim(audio, top_db=20)\n",
        "\n",
        "        return audio_trimmed, target_sr\n",
        "    except Exception as e:\n",
        "        print(f\"    Error preprocessing {audio_path}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def convert_to_wav_if_needed(audio_path):\n",
        "    \"\"\"Convert audio to WAV format if needed\"\"\"\n",
        "    try:\n",
        "        if not audio_path.endswith('.wav'):\n",
        "            # Convert using pydub\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "            wav_path = audio_path.rsplit('.', 1)[0] + '_converted.wav'\n",
        "            audio.export(wav_path, format=\"wav\")\n",
        "            return wav_path\n",
        "        return audio_path\n",
        "    except Exception as e:\n",
        "        print(f\"    Error converting {audio_path}: {e}\")\n",
        "        return audio_path\n",
        "\n",
        "# STEP 7: SPEECH RECOGNITION FUNCTION\n",
        "print(\"\\nSTEP 7: Setting up speech recognition...\")\n",
        "\n",
        "def extract_transcript_from_audio(audio_path, method='google'):\n",
        "    \"\"\"Extract transcript from audio file using speech recognition\"\"\"\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    try:\n",
        "        # Convert to WAV if needed\n",
        "        wav_path = convert_to_wav_if_needed(audio_path)\n",
        "\n",
        "        # Preprocess audio\n",
        "        audio_data, sr_rate = preprocess_audio(wav_path, target_sr=16000)\n",
        "\n",
        "        if audio_data is None:\n",
        "            return None, \"Preprocessing failed\"\n",
        "\n",
        "        # Save preprocessed audio temporarily\n",
        "        temp_wav = audio_path.replace('.wav', '_temp.wav')\n",
        "        sf.write(temp_wav, audio_data, sr_rate)\n",
        "\n",
        "        # Use speech recognition\n",
        "        with sr.AudioFile(temp_wav) as source:\n",
        "            # Adjust for ambient noise\n",
        "            recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
        "            audio = recognizer.listen(source)\n",
        "\n",
        "        # Try different recognition methods\n",
        "        transcript = None\n",
        "        error_msg = \"\"\n",
        "\n",
        "        if method == 'google':\n",
        "            try:\n",
        "                transcript = recognizer.recognize_google(audio)\n",
        "            except sr.UnknownValueError:\n",
        "                error_msg = \"Google Speech Recognition could not understand audio\"\n",
        "            except sr.RequestError as e:\n",
        "                error_msg = f\"Google Speech Recognition error: {e}\"\n",
        "\n",
        "        # Fallback to other methods if Google fails\n",
        "        if transcript is None:\n",
        "            try:\n",
        "                transcript = recognizer.recognize_sphinx(audio)\n",
        "                method = 'sphinx'\n",
        "            except sr.UnknownValueError:\n",
        "                error_msg += \"; Sphinx could not understand audio\"\n",
        "            except sr.RequestError as e:\n",
        "                error_msg += f\"; Sphinx error: {e}\"\n",
        "\n",
        "        # Clean up temporary file\n",
        "        if os.path.exists(temp_wav):\n",
        "            os.remove(temp_wav)\n",
        "\n",
        "        if transcript:\n",
        "            return transcript.strip(), method\n",
        "        else:\n",
        "            return None, error_msg\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"Error processing audio: {str(e)}\"\n",
        "\n",
        "# STEP 8: PROCESS ALL AUDIO FILES AND EXTRACT TRANSCRIPTS\n",
        "print(\"\\nSTEP 8: Processing audio files and extracting transcripts...\")\n",
        "print(\"This may take a while depending on the number and length of audio files...\")\n",
        "\n",
        "def process_audio_files(wav_files):\n",
        "    \"\"\"Process all audio files and extract transcripts\"\"\"\n",
        "    all_transcripts = []\n",
        "\n",
        "    # Process progression training data\n",
        "    print(\"\\n  Processing progression training data...\")\n",
        "    for label in ['decline', 'no_decline']:\n",
        "        files = wav_files['progression_train'][label]\n",
        "        print(f\"    Processing {len(files)} {label} files...\")\n",
        "\n",
        "        for i, audio_path in enumerate(files):\n",
        "            print(f\"      Processing {i+1}/{len(files)}: {os.path.basename(audio_path)}\")\n",
        "\n",
        "            transcript, method_or_error = extract_transcript_from_audio(audio_path)\n",
        "\n",
        "            all_transcripts.append({\n",
        "                'file_id': os.path.splitext(os.path.basename(audio_path))[0],\n",
        "                'file_path': audio_path,\n",
        "                'dataset': 'progression_train',\n",
        "                'label': label,\n",
        "                'transcript': transcript,\n",
        "                'recognition_method': method_or_error if transcript else None,\n",
        "                'error': None if transcript else method_or_error,\n",
        "                'success': transcript is not None\n",
        "            })\n",
        "\n",
        "    # Process progression test data\n",
        "    print(\"\\n  Processing progression test data...\")\n",
        "    files = wav_files['progression_test']\n",
        "    print(f\"    Processing {len(files)} test files...\")\n",
        "\n",
        "    for i, audio_path in enumerate(files):\n",
        "        print(f\"      Processing {i+1}/{len(files)}: {os.path.basename(audio_path)}\")\n",
        "\n",
        "        transcript, method_or_error = extract_transcript_from_audio(audio_path)\n",
        "\n",
        "        all_transcripts.append({\n",
        "            'file_id': os.path.splitext(os.path.basename(audio_path))[0],\n",
        "            'file_path': audio_path,\n",
        "            'dataset': 'progression_test',\n",
        "            'label': 'test',\n",
        "            'transcript': transcript,\n",
        "            'recognition_method': method_or_error if transcript else None,\n",
        "            'error': None if transcript else method_or_error,\n",
        "            'success': transcript is not None\n",
        "        })\n",
        "\n",
        "    # Process diagnosis training data\n",
        "    print(\"\\n  Processing diagnosis training data...\")\n",
        "    for label in ['ad', 'cn']:\n",
        "        files = wav_files['diagnosis_train'][label]\n",
        "        print(f\"    Processing {len(files)} {label} files...\")\n",
        "\n",
        "        for i, audio_path in enumerate(files):\n",
        "            print(f\"      Processing {i+1}/{len(files)}: {os.path.basename(audio_path)}\")\n",
        "\n",
        "            transcript, method_or_error = extract_transcript_from_audio(audio_path)\n",
        "\n",
        "            all_transcripts.append({\n",
        "                'file_id': os.path.splitext(os.path.basename(audio_path))[0],\n",
        "                'file_path': audio_path,\n",
        "                'dataset': 'diagnosis_train',\n",
        "                'label': label,\n",
        "                'transcript': transcript,\n",
        "                'recognition_method': method_or_error if transcript else None,\n",
        "                'error': None if transcript else method_or_error,\n",
        "                'success': transcript is not None\n",
        "            })\n",
        "\n",
        "    return all_transcripts\n",
        "\n",
        "# Process all files\n",
        "transcripts = process_audio_files(wav_files)\n",
        "\n",
        "# STEP 9: SAVE RESULTS\n",
        "print(\"\\nSTEP 9: Saving transcription results...\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(transcripts)\n",
        "\n",
        "# Save complete results\n",
        "complete_output = os.path.join(OUTPUT_PATH, \"all_transcripts.csv\")\n",
        "df.to_csv(complete_output, index=False)\n",
        "print(f\"✓ Saved complete results to: {complete_output}\")\n",
        "\n",
        "# Save successful transcripts only\n",
        "successful_df = df[df['success'] == True].copy()\n",
        "success_output = os.path.join(OUTPUT_PATH, \"successful_transcripts.csv\")\n",
        "successful_df.to_csv(success_output, index=False)\n",
        "print(f\"✓ Saved successful transcripts to: {success_output}\")\n",
        "\n",
        "# Save by dataset\n",
        "datasets_to_save = df['dataset'].unique()\n",
        "for dataset in datasets_to_save:\n",
        "    dataset_df = df[df['dataset'] == dataset].copy()\n",
        "    dataset_output = os.path.join(OUTPUT_PATH, f\"{dataset}_transcripts.csv\")\n",
        "    dataset_df.to_csv(dataset_output, index=False)\n",
        "    print(f\"✓ Saved {dataset} transcripts to: {dataset_output}\")\n",
        "\n",
        "# STEP 10: DISPLAY SUMMARY STATISTICS\n",
        "print(\"\\nSTEP 10: Summary Statistics\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "total_files = len(df)\n",
        "successful = len(successful_df)\n",
        "failed = total_files - successful\n",
        "\n",
        "print(f\"Total audio files processed: {total_files}\")\n",
        "print(f\"Successful transcriptions: {successful} ({successful/total_files*100:.1f}%)\")\n",
        "print(f\"Failed transcriptions: {failed} ({failed/total_files*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nDataset breakdown:\")\n",
        "for dataset in df['dataset'].unique():\n",
        "    dataset_total = len(df[df['dataset'] == dataset])\n",
        "    dataset_success = len(df[(df['dataset'] == dataset) & (df['success'] == True)])\n",
        "    print(f\"  {dataset}: {dataset_success}/{dataset_total} successful ({dataset_success/dataset_total*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nLabel distribution (successful transcripts only):\")\n",
        "if not successful_df.empty:\n",
        "    print(successful_df['label'].value_counts())\n",
        "\n",
        "print(f\"\\nRecognition methods used:\")\n",
        "if not successful_df.empty:\n",
        "    print(successful_df['recognition_method'].value_counts())\n",
        "\n",
        "# Show sample transcripts\n",
        "print(f\"\\nSample successful transcripts:\")\n",
        "sample_transcripts = successful_df['transcript'].dropna().head(3)\n",
        "for i, transcript in enumerate(sample_transcripts):\n",
        "    print(f\"  Sample {i+1}: {transcript[:200]}...\")\n",
        "\n",
        "# Show common errors\n",
        "print(f\"\\nMost common errors:\")\n",
        "error_df = df[df['success'] == False]\n",
        "if not error_df.empty:\n",
        "    error_counts = error_df['error'].value_counts().head(5)\n",
        "    for error, count in error_counts.items():\n",
        "        print(f\"  {error}: {count} files\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRANSCRIPT EXTRACTION COMPLETE!\")\n",
        "print(f\"All results saved in: {OUTPUT_PATH}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56RZ8BRdy4pM",
        "outputId": "59419cb2-f3c8-41e2-f915-5a84cd8c4a69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ADReSSo21 AUDIO TRANSCRIPT EXTRACTOR\n",
            "============================================================\n",
            "\n",
            "STEP 1: Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "✓ Google Drive mounted successfully!\n",
            "\n",
            "STEP 2: Installing required packages...\n",
            "Installing speech recognition and audio processing libraries...\n",
            "✓ Packages ready (make sure to install them first)\n",
            "\n",
            "STEP 3: Setting up paths and configuration...\n",
            "✓ Base path: /content/drive/MyDrive/Voice/\n",
            "✓ Extract path: /content/drive/MyDrive/Voice/extracted/\n",
            "✓ Output path: /content/drive/MyDrive/Voice/transcripts/\n",
            "\n",
            "STEP 4: Extracting dataset files...\n",
            "  Extracting ADReSSo21-progression-train.tgz...\n",
            "  ✓ ADReSSo21-progression-train.tgz extracted successfully\n",
            "  Extracting ADReSSo21-progression-test.tgz...\n",
            "  ✓ ADReSSo21-progression-test.tgz extracted successfully\n",
            "  Extracting ADReSSo21-diagnosis-train.tgz...\n",
            "  ✓ ADReSSo21-diagnosis-train.tgz extracted successfully\n",
            "\n",
            "STEP 5: Finding all WAV files...\n",
            "  Found 15 decline WAV files\n",
            "  Found 58 no_decline WAV files\n",
            "  Found 32 test WAV files\n",
            "  Found 87 AD WAV files\n",
            "  Found 79 CN WAV files\n",
            "\n",
            "STEP 6: Setting up audio preprocessing...\n",
            "\n",
            "STEP 7: Setting up speech recognition...\n",
            "\n",
            "STEP 8: Processing audio files and extracting transcripts...\n",
            "This may take a while depending on the number and length of audio files...\n",
            "\n",
            "  Processing progression training data...\n",
            "    Processing 15 decline files...\n",
            "      Processing 1/15: adrsp055.wav\n",
            "      Processing 2/15: adrsp003.wav\n",
            "      Processing 3/15: adrsp266.wav\n",
            "      Processing 4/15: adrsp300.wav\n",
            "      Processing 5/15: adrsp320.wav\n",
            "      Processing 6/15: adrsp313.wav\n",
            "      Processing 7/15: adrsp179.wav\n",
            "      Processing 8/15: adrsp357.wav\n",
            "      Processing 9/15: adrsp051.wav\n",
            "      Processing 10/15: adrsp101.wav\n",
            "      Processing 11/15: adrsp326.wav\n",
            "      Processing 12/15: adrsp127.wav\n",
            "      Processing 13/15: adrsp276.wav\n",
            "      Processing 14/15: adrsp209.wav\n",
            "      Processing 15/15: adrsp318.wav\n",
            "    Processing 58 no_decline files...\n",
            "      Processing 1/58: adrsp196.wav\n",
            "      Processing 2/58: adrsp137.wav\n",
            "      Processing 3/58: adrsp130.wav\n",
            "      Processing 4/58: adrsp349.wav\n",
            "      Processing 5/58: adrsp198.wav\n",
            "      Processing 6/58: adrsp321.wav\n",
            "      Processing 7/58: adrsp136.wav\n",
            "      Processing 8/58: adrsp024.wav\n",
            "      Processing 9/58: adrsp007.wav\n",
            "      Processing 10/58: adrsp382.wav\n",
            "      Processing 11/58: adrsp043.wav\n",
            "      Processing 12/58: adrsp019.wav\n",
            "      Processing 13/58: adrsp333.wav\n",
            "      Processing 14/58: adrsp056.wav\n",
            "      Processing 15/58: adrsp042.wav\n",
            "      Processing 16/58: adrsp310.wav\n",
            "      Processing 17/58: adrsp377.wav\n",
            "      Processing 18/58: adrsp363.wav\n",
            "      Processing 19/58: adrsp028.wav\n",
            "      Processing 20/58: adrsp350.wav\n",
            "      Processing 21/58: adrsp096.wav\n",
            "      Processing 22/58: adrsp052.wav\n",
            "      Processing 23/58: adrsp204.wav\n",
            "      Processing 24/58: adrsp380.wav\n",
            "      Processing 25/58: adrsp109.wav\n",
            "      Processing 26/58: adrsp255.wav\n",
            "      Processing 27/58: adrsp157.wav\n",
            "      Processing 28/58: adrsp306.wav\n",
            "      Processing 29/58: adrsp197.wav\n",
            "      Processing 30/58: adrsp031.wav\n",
            "      Processing 31/58: adrsp368.wav\n",
            "      Processing 32/58: adrsp032.wav\n",
            "      Processing 33/58: adrsp091.wav\n",
            "      Processing 34/58: adrsp344.wav\n",
            "      Processing 35/58: adrsp124.wav\n",
            "      Processing 36/58: adrsp195.wav\n",
            "      Processing 37/58: adrsp253.wav\n",
            "      Processing 38/58: adrsp251.wav\n",
            "      Processing 39/58: adrsp039.wav\n",
            "      Processing 40/58: adrsp001.wav\n",
            "      Processing 41/58: adrsp041.wav\n",
            "      Processing 42/58: adrsp384.wav\n",
            "      Processing 43/58: adrsp207.wav\n",
            "      Processing 44/58: adrsp379.wav\n",
            "      Processing 45/58: adrsp324.wav\n",
            "      Processing 46/58: adrsp177.wav\n",
            "      Processing 47/58: adrsp148.wav\n",
            "      Processing 48/58: adrsp023.wav\n",
            "      Processing 49/58: adrsp359.wav\n",
            "      Processing 50/58: adrsp122.wav\n",
            "      Processing 51/58: adrsp200.wav\n",
            "      Processing 52/58: adrsp030.wav\n",
            "      Processing 53/58: adrsp319.wav\n",
            "      Processing 54/58: adrsp378.wav\n",
            "      Processing 55/58: adrsp193.wav\n",
            "      Processing 56/58: adrsp128.wav\n",
            "      Processing 57/58: adrsp161.wav\n",
            "      Processing 58/58: adrsp192.wav\n",
            "\n",
            "  Processing progression test data...\n",
            "    Processing 32 test files...\n",
            "      Processing 1/32: adrspt20.wav\n",
            "      Processing 2/32: adrspt15.wav\n",
            "      Processing 3/32: adrspt4.wav\n",
            "      Processing 4/32: adrspt28.wav\n",
            "      Processing 5/32: adrspt16.wav\n",
            "      Processing 6/32: adrspt27.wav\n",
            "      Processing 7/32: adrspt9.wav\n",
            "      Processing 8/32: adrspt10.wav\n",
            "      Processing 9/32: adrspt13.wav\n",
            "      Processing 10/32: adrspt26.wav\n",
            "      Processing 11/32: adrspt23.wav\n",
            "      Processing 12/32: adrspt31.wav\n",
            "      Processing 13/32: adrspt14.wav\n",
            "      Processing 14/32: adrspt6.wav\n",
            "      Processing 15/32: adrspt12.wav\n",
            "      Processing 16/32: adrspt32.wav\n",
            "      Processing 17/32: adrspt21.wav\n",
            "      Processing 18/32: adrspt1.wav\n",
            "      Processing 19/32: adrspt29.wav\n",
            "      Processing 20/32: adrspt30.wav\n",
            "      Processing 21/32: adrspt3.wav\n",
            "      Processing 22/32: adrspt8.wav\n",
            "      Processing 23/32: adrspt19.wav\n",
            "      Processing 24/32: adrspt18.wav\n",
            "      Processing 25/32: adrspt25.wav\n",
            "      Processing 26/32: adrspt2.wav\n",
            "      Processing 27/32: adrspt24.wav\n",
            "      Processing 28/32: adrspt11.wav\n",
            "      Processing 29/32: adrspt17.wav\n",
            "      Processing 30/32: adrspt22.wav\n",
            "      Processing 31/32: adrspt7.wav\n",
            "      Processing 32/32: adrspt5.wav\n",
            "\n",
            "  Processing diagnosis training data...\n",
            "    Processing 87 ad files...\n",
            "      Processing 1/87: adrso047.wav\n",
            "      Processing 2/87: adrso128.wav\n",
            "      Processing 3/87: adrso045.wav\n",
            "      Processing 4/87: adrso110.wav\n",
            "      Processing 5/87: adrso036.wav\n",
            "      Processing 6/87: adrso189.wav\n",
            "      Processing 7/87: adrso093.wav\n",
            "      Processing 8/87: adrso112.wav\n",
            "      Processing 9/87: adrso205.wav\n",
            "      Processing 10/87: adrso089.wav\n",
            "      Processing 11/87: adrso060.wav\n",
            "      Processing 12/87: adrso232.wav\n",
            "      Processing 13/87: adrso075.wav\n",
            "      Processing 14/87: adrso063.wav\n",
            "      Processing 15/87: adrso106.wav\n",
            "      Processing 16/87: adrso202.wav\n",
            "      Processing 17/87: adrso043.wav\n",
            "      Processing 18/87: adrso206.wav\n",
            "      Processing 19/87: adrso039.wav\n",
            "      Processing 20/87: adrso109.wav\n",
            "      Processing 21/87: adrso126.wav\n",
            "      Processing 22/87: adrso071.wav\n",
            "      Processing 23/87: adrso209.wav\n",
            "      Processing 24/87: adrso244.wav\n",
            "      Processing 25/87: adrso228.wav\n",
            "      Processing 26/87: adrso122.wav\n",
            "      Processing 27/87: adrso116.wav\n",
            "      Processing 28/87: adrso141.wav\n",
            "      Processing 29/87: adrso130.wav\n",
            "      Processing 30/87: adrso248.wav\n",
            "      Processing 31/87: adrso070.wav\n",
            "      Processing 32/87: adrso055.wav\n",
            "      Processing 33/87: adrso222.wav\n",
            "      Processing 34/87: adrso190.wav\n",
            "      Processing 35/87: adrso215.wav\n",
            "      Processing 36/87: adrso223.wav\n",
            "      Processing 37/87: adrso192.wav\n",
            "      Processing 38/87: adrso236.wav\n",
            "      Processing 39/87: adrso234.wav\n",
            "      Processing 40/87: adrso059.wav\n",
            "      Processing 41/87: adrso098.wav\n",
            "      Processing 42/87: adrso090.wav\n",
            "      Processing 43/87: adrso250.wav\n",
            "      Processing 44/87: adrso025.wav\n",
            "      Processing 45/87: adrso031.wav\n",
            "      Processing 46/87: adrso197.wav\n",
            "      Processing 47/87: adrso224.wav\n",
            "      Processing 48/87: adrso074.wav\n",
            "      Processing 49/87: adrso049.wav\n",
            "      Processing 50/87: adrso211.wav\n",
            "      Processing 51/87: adrso229.wav\n",
            "      Processing 52/87: adrso138.wav\n",
            "      Processing 53/87: adrso123.wav\n",
            "      Processing 54/87: adrso027.wav\n",
            "      Processing 55/87: adrso072.wav\n",
            "      Processing 56/87: adrso056.wav\n",
            "      Processing 57/87: adrso068.wav\n",
            "      Processing 58/87: adrso054.wav\n",
            "      Processing 59/87: adrso187.wav\n",
            "      Processing 60/87: adrso078.wav\n",
            "      Processing 61/87: adrso053.wav\n",
            "      Processing 62/87: adrso200.wav\n",
            "      Processing 63/87: adrso249.wav\n",
            "      Processing 64/87: adrso028.wav\n",
            "      Processing 65/87: adrso245.wav\n",
            "      Processing 66/87: adrso216.wav\n",
            "      Processing 67/87: adrso092.wav\n",
            "      Processing 68/87: adrso220.wav\n",
            "      Processing 69/87: adrso134.wav\n",
            "      Processing 70/87: adrso142.wav\n",
            "      Processing 71/87: adrso198.wav\n",
            "      Processing 72/87: adrso077.wav\n",
            "      Processing 73/87: adrso024.wav\n",
            "      Processing 74/87: adrso212.wav\n",
            "      Processing 75/87: adrso046.wav\n",
            "      Processing 76/87: adrso035.wav\n",
            "      Processing 77/87: adrso233.wav\n",
            "      Processing 78/87: adrso247.wav\n",
            "      Processing 79/87: adrso033.wav\n",
            "      Processing 80/87: adrso125.wav\n",
            "      Processing 81/87: adrso188.wav\n",
            "      Processing 82/87: adrso237.wav\n",
            "      Processing 83/87: adrso032.wav\n",
            "      Processing 84/87: adrso253.wav\n",
            "      Processing 85/87: adrso218.wav\n",
            "      Processing 86/87: adrso144.wav\n",
            "      Processing 87/87: adrso246.wav\n",
            "    Processing 79 cn files...\n",
            "      Processing 1/79: adrso173.wav\n",
            "      Processing 2/79: adrso015.wav\n",
            "      Processing 3/79: adrso307.wav\n",
            "      Processing 4/79: adrso283.wav\n",
            "      Processing 5/79: adrso167.wav\n",
            "      Processing 6/79: adrso168.wav\n",
            "      Processing 7/79: adrso172.wav\n",
            "      Processing 8/79: adrso292.wav\n",
            "      Processing 9/79: adrso316.wav\n",
            "      Processing 10/79: adrso162.wav\n",
            "      Processing 11/79: adrso296.wav\n",
            "      Processing 12/79: adrso278.wav\n",
            "      Processing 13/79: adrso300.wav\n",
            "      Processing 14/79: adrso291.wav\n",
            "      Processing 15/79: adrso169.wav\n",
            "      Processing 16/79: adrso178.wav\n",
            "      Processing 17/79: adrso165.wav\n",
            "      Processing 18/79: adrso262.wav\n",
            "      Processing 19/79: adrso177.wav\n",
            "      Processing 20/79: adrso265.wav\n",
            "      Processing 21/79: adrso014.wav\n",
            "      Processing 22/79: adrso261.wav\n",
            "      Processing 23/79: adrso268.wav\n",
            "      Processing 24/79: adrso021.wav\n",
            "      Processing 25/79: adrso156.wav\n",
            "      Processing 26/79: adrso310.wav\n",
            "      Processing 27/79: adrso016.wav\n",
            "      Processing 28/79: adrso148.wav\n",
            "      Processing 29/79: adrso302.wav\n",
            "      Processing 30/79: adrso308.wav\n",
            "      Processing 31/79: adrso018.wav\n",
            "      Processing 32/79: adrso309.wav\n",
            "      Processing 33/79: adrso180.wav\n",
            "      Processing 34/79: adrso298.wav\n",
            "      Processing 35/79: adrso154.wav\n",
            "      Processing 36/79: adrso273.wav\n",
            "      Processing 37/79: adrso259.wav\n",
            "      Processing 38/79: adrso151.wav\n",
            "      Processing 39/79: adrso159.wav\n",
            "      Processing 40/79: adrso267.wav\n",
            "      Processing 41/79: adrso274.wav\n",
            "      Processing 42/79: adrso019.wav\n",
            "      Processing 43/79: adrso153.wav\n",
            "      Processing 44/79: adrso023.wav\n",
            "      Processing 45/79: adrso012.wav\n",
            "      Processing 46/79: adrso280.wav\n",
            "      Processing 47/79: adrso002.wav\n",
            "      Processing 48/79: adrso266.wav\n",
            "      Processing 49/79: adrso022.wav\n",
            "      Processing 50/79: adrso007.wav\n",
            "      Processing 51/79: adrso152.wav\n",
            "      Processing 52/79: adrso276.wav\n",
            "      Processing 53/79: adrso260.wav\n",
            "      Processing 54/79: adrso005.wav\n",
            "      Processing 55/79: adrso017.wav\n",
            "      Processing 56/79: adrso299.wav\n",
            "      Processing 57/79: adrso157.wav\n",
            "      Processing 58/79: adrso182.wav\n",
            "      Processing 59/79: adrso008.wav\n",
            "      Processing 60/79: adrso161.wav\n",
            "      Processing 61/79: adrso263.wav\n",
            "      Processing 62/79: adrso257.wav\n",
            "      Processing 63/79: adrso164.wav\n",
            "      Processing 64/79: adrso270.wav\n",
            "      Processing 65/79: adrso289.wav\n",
            "      Processing 66/79: adrso264.wav\n",
            "      Processing 67/79: adrso277.wav\n",
            "      Processing 68/79: adrso160.wav\n",
            "      Processing 69/79: adrso286.wav\n",
            "      Processing 70/79: adrso003.wav\n",
            "      Processing 71/79: adrso186.wav\n",
            "      Processing 72/79: adrso285.wav\n",
            "      Processing 73/79: adrso170.wav\n",
            "      Processing 74/79: adrso183.wav\n",
            "      Processing 75/79: adrso281.wav\n",
            "      Processing 76/79: adrso315.wav\n",
            "      Processing 77/79: adrso010.wav\n",
            "      Processing 78/79: adrso312.wav\n",
            "      Processing 79/79: adrso158.wav\n",
            "\n",
            "STEP 9: Saving transcription results...\n",
            "✓ Saved complete results to: /content/drive/MyDrive/Voice/transcripts/all_transcripts.csv\n",
            "✓ Saved successful transcripts to: /content/drive/MyDrive/Voice/transcripts/successful_transcripts.csv\n",
            "✓ Saved progression_train transcripts to: /content/drive/MyDrive/Voice/transcripts/progression_train_transcripts.csv\n",
            "✓ Saved progression_test transcripts to: /content/drive/MyDrive/Voice/transcripts/progression_test_transcripts.csv\n",
            "✓ Saved diagnosis_train transcripts to: /content/drive/MyDrive/Voice/transcripts/diagnosis_train_transcripts.csv\n",
            "\n",
            "STEP 10: Summary Statistics\n",
            "==================================================\n",
            "Total audio files processed: 271\n",
            "Successful transcriptions: 155 (57.2%)\n",
            "Failed transcriptions: 116 (42.8%)\n",
            "\n",
            "Dataset breakdown:\n",
            "  progression_train: 42/73 successful (57.5%)\n",
            "  progression_test: 16/32 successful (50.0%)\n",
            "  diagnosis_train: 97/166 successful (58.4%)\n",
            "\n",
            "Label distribution (successful transcripts only):\n",
            "label\n",
            "ad            51\n",
            "cn            46\n",
            "no_decline    34\n",
            "test          16\n",
            "decline        8\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Recognition methods used:\n",
            "recognition_method\n",
            "google    155\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample successful transcripts:\n",
            "  Sample 1: you can start now...\n",
            "  Sample 2: is in 1 minute time I want you to name as many...\n",
            "  Sample 3: cat dog giraffe...\n",
            "\n",
            "Most common errors:\n",
            "  Google Speech Recognition could not understand audio; Sphinx error: missing PocketSphinx module: ensure that PocketSphinx is set up correctly.: 116 files\n",
            "\n",
            "============================================================\n",
            "TRANSCRIPT EXTRACTION COMPLETE!\n",
            "All results saved in: /content/drive/MyDrive/Voice/transcripts/\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SgZdh7FonhH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}