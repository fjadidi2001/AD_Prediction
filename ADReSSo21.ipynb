{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMS7b4WLanKzysa1XtTW/BW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/ADReSSo21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4B7Zj3PzRLv",
        "outputId": "2cfa641e-1a59-468a-d566-e0a2456d4367"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.13.2)\n",
            "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.3 pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-by-Step Audio Transcript Extractor for ADReSSo21 Dataset\n",
        "# This script will:\n",
        "# 1. Mount Google Drive\n",
        "# 2. Extract dataset files\n",
        "# 3. Find all WAV files\n",
        "# 4. Extract transcripts from audio using speech recognition\n",
        "# 5. Save organized transcripts\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import librosa\n",
        "import speech_recognition as sr\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ADReSSo21 AUDIO TRANSCRIPT EXTRACTOR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# STEP 1: MOUNT GOOGLE DRIVE\n",
        "print(\"\\nSTEP 1: Mounting Google Drive...\")\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"✓ Google Drive mounted successfully!\")\n",
        "except:\n",
        "    print(\"⚠ Not running in Colab or Drive already mounted\")\n",
        "\n",
        "# STEP 2: INSTALL REQUIRED PACKAGES\n",
        "print(\"\\nSTEP 2: Installing required packages...\")\n",
        "print(\"Installing speech recognition and audio processing libraries...\")\n",
        "\n",
        "# Install packages (run once)\n",
        "!pip install SpeechRecognition\n",
        "!pip install pydub\n",
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "print(\"✓ Packages ready (make sure to install them first)\")\n",
        "\n",
        "# STEP 3: SET UP PATHS AND CONFIGURATION\n",
        "print(\"\\nSTEP 3: Setting up paths and configuration...\")\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/Voice/\"\n",
        "EXTRACT_PATH = \"/content/drive/MyDrive/Voice/extracted/\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/Voice/transcripts/\"\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(EXTRACT_PATH, exist_ok=True)\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "datasets = {\n",
        "    'progression_train': 'ADReSSo21-progression-train.tgz',\n",
        "    'progression_test': 'ADReSSo21-progression-test.tgz',\n",
        "    'diagnosis_train': 'ADReSSo21-diagnosis-train.tgz'\n",
        "}\n",
        "\n",
        "print(f\"✓ Base path: {BASE_PATH}\")\n",
        "print(f\"✓ Extract path: {EXTRACT_PATH}\")\n",
        "print(f\"✓ Output path: {OUTPUT_PATH}\")\n",
        "\n",
        "# STEP 4: EXTRACT DATASET FILES\n",
        "print(\"\\nSTEP 4: Extracting dataset files...\")\n",
        "\n",
        "def extract_datasets():\n",
        "    \"\"\"Extract all tgz files\"\"\"\n",
        "    for dataset_name, filename in datasets.items():\n",
        "        file_path = os.path.join(BASE_PATH, filename)\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"  Extracting {filename}...\")\n",
        "            try:\n",
        "                with tarfile.open(file_path, 'r:gz') as tar:\n",
        "                    tar.extractall(path=EXTRACT_PATH)\n",
        "                print(f\"  ✓ {filename} extracted successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ⚠ Error extracting {filename}: {e}\")\n",
        "        else:\n",
        "            print(f\"  ⚠ {filename} not found at {file_path}\")\n",
        "\n",
        "extract_datasets()\n",
        "\n",
        "# STEP 5: FIND ALL WAV FILES\n",
        "print(\"\\nSTEP 5: Finding all WAV files...\")\n",
        "\n",
        "def find_wav_files():\n",
        "    \"\"\"Find all WAV files and organize by dataset and label\"\"\"\n",
        "    wav_files = {\n",
        "        'progression_train': {'decline': [], 'no_decline': []},\n",
        "        'progression_test': [],\n",
        "        'diagnosis_train': {'ad': [], 'cn': []}\n",
        "    }\n",
        "\n",
        "    # Progression training files\n",
        "    prog_train_base = os.path.join(EXTRACT_PATH, \"ADReSSo21/progression/train/audio/\")\n",
        "\n",
        "    # Decline cases\n",
        "    decline_path = os.path.join(prog_train_base, \"decline/\")\n",
        "    if os.path.exists(decline_path):\n",
        "        decline_wavs = [f for f in os.listdir(decline_path) if f.endswith('.wav')]\n",
        "        wav_files['progression_train']['decline'] = [os.path.join(decline_path, f) for f in decline_wavs]\n",
        "        print(f\"  Found {len(decline_wavs)} decline WAV files\")\n",
        "\n",
        "    # No decline cases\n",
        "    no_decline_path = os.path.join(prog_train_base, \"no_decline/\")\n",
        "    if os.path.exists(no_decline_path):\n",
        "        no_decline_wavs = [f for f in os.listdir(no_decline_path) if f.endswith('.wav')]\n",
        "        wav_files['progression_train']['no_decline'] = [os.path.join(no_decline_path, f) for f in no_decline_wavs]\n",
        "        print(f\"  Found {len(no_decline_wavs)} no_decline WAV files\")\n",
        "\n",
        "    # Progression test files\n",
        "    prog_test_path = os.path.join(EXTRACT_PATH, \"ADReSSo21/progression/test-dist/audio/\")\n",
        "    if os.path.exists(prog_test_path):\n",
        "        test_wavs = [f for f in os.listdir(prog_test_path) if f.endswith('.wav')]\n",
        "        wav_files['progression_test'] = [os.path.join(prog_test_path, f) for f in test_wavs]\n",
        "        print(f\"  Found {len(test_wavs)} test WAV files\")\n",
        "\n",
        "    # Diagnosis training files\n",
        "    diag_train_base = os.path.join(EXTRACT_PATH, \"ADReSSo21/diagnosis/train/audio/\")\n",
        "\n",
        "    # AD cases\n",
        "    ad_path = os.path.join(diag_train_base, \"ad/\")\n",
        "    if os.path.exists(ad_path):\n",
        "        ad_wavs = [f for f in os.listdir(ad_path) if f.endswith('.wav')]\n",
        "        wav_files['diagnosis_train']['ad'] = [os.path.join(ad_path, f) for f in ad_wavs]\n",
        "        print(f\"  Found {len(ad_wavs)} AD WAV files\")\n",
        "\n",
        "    # CN cases\n",
        "    cn_path = os.path.join(diag_train_base, \"cn/\")\n",
        "    if os.path.exists(cn_path):\n",
        "        cn_wavs = [f for f in os.listdir(cn_path) if f.endswith('.wav')]\n",
        "        wav_files['diagnosis_train']['cn'] = [os.path.join(cn_path, f) for f in cn_wavs]\n",
        "        print(f\"  Found {len(cn_wavs)} CN WAV files\")\n",
        "\n",
        "    return wav_files\n",
        "\n",
        "wav_files = find_wav_files()\n",
        "\n",
        "# STEP 6: AUDIO PREPROCESSING FUNCTIONS\n",
        "print(\"\\nSTEP 6: Setting up audio preprocessing...\")\n",
        "\n",
        "def preprocess_audio(audio_path, target_sr=16000):\n",
        "    \"\"\"Preprocess audio file for speech recognition\"\"\"\n",
        "    try:\n",
        "        # Load audio with librosa\n",
        "        audio, sr = librosa.load(audio_path, sr=target_sr)\n",
        "\n",
        "        # Normalize audio\n",
        "        audio = librosa.util.normalize(audio)\n",
        "\n",
        "        # Remove silence\n",
        "        audio_trimmed, _ = librosa.effects.trim(audio, top_db=20)\n",
        "\n",
        "        return audio_trimmed, target_sr\n",
        "    except Exception as e:\n",
        "        print(f\"    Error preprocessing {audio_path}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def convert_to_wav_if_needed(audio_path):\n",
        "    \"\"\"Convert audio to WAV format if needed\"\"\"\n",
        "    try:\n",
        "        if not audio_path.endswith('.wav'):\n",
        "            # Convert using pydub\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "            wav_path = audio_path.rsplit('.', 1)[0] + '_converted.wav'\n",
        "            audio.export(wav_path, format=\"wav\")\n",
        "            return wav_path\n",
        "        return audio_path\n",
        "    except Exception as e:\n",
        "        print(f\"    Error converting {audio_path}: {e}\")\n",
        "        return audio_path\n",
        "\n",
        "# STEP 7: SPEECH RECOGNITION FUNCTION\n",
        "print(\"\\nSTEP 7: Setting up speech recognition...\")\n",
        "\n",
        "def extract_transcript_from_audio(audio_path, method='google'):\n",
        "    \"\"\"Extract transcript from audio file using speech recognition\"\"\"\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    try:\n",
        "        # Convert to WAV if needed\n",
        "        wav_path = convert_to_wav_if_needed(audio_path)\n",
        "\n",
        "        # Preprocess audio\n",
        "        audio_data, sr_rate = preprocess_audio(wav_path, target_sr=16000)\n",
        "\n",
        "        if audio_data is None:\n",
        "            return None, \"Preprocessing failed\"\n",
        "\n",
        "        # Save preprocessed audio temporarily\n",
        "        temp_wav = audio_path.replace('.wav', '_temp.wav')\n",
        "        sf.write(temp_wav, audio_data, sr_rate)\n",
        "\n",
        "        # Use speech recognition\n",
        "        with sr.AudioFile(temp_wav) as source:\n",
        "            # Adjust for ambient noise\n",
        "            recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
        "            audio = recognizer.listen(source)\n",
        "\n",
        "        # Try different recognition methods\n",
        "        transcript = None\n",
        "        error_msg = \"\"\n",
        "\n",
        "        if method == 'google':\n",
        "            try:\n",
        "                transcript = recognizer.recognize_google(audio)\n",
        "            except sr.UnknownValueError:\n",
        "                error_msg = \"Google Speech Recognition could not understand audio\"\n",
        "            except sr.RequestError as e:\n",
        "                error_msg = f\"Google Speech Recognition error: {e}\"\n",
        "\n",
        "        # Fallback to other methods if Google fails\n",
        "        if transcript is None:\n",
        "            try:\n",
        "                transcript = recognizer.recognize_sphinx(audio)\n",
        "                method = 'sphinx'\n",
        "            except sr.UnknownValueError:\n",
        "                error_msg += \"; Sphinx could not understand audio\"\n",
        "            except sr.RequestError as e:\n",
        "                error_msg += f\"; Sphinx error: {e}\"\n",
        "\n",
        "        # Clean up temporary file\n",
        "        if os.path.exists(temp_wav):\n",
        "            os.remove(temp_wav)\n",
        "\n",
        "        if transcript:\n",
        "            return transcript.strip(), method\n",
        "        else:\n",
        "            return None, error_msg\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"Error processing audio: {str(e)}\"\n",
        "\n",
        "# STEP 8: PROCESS ALL AUDIO FILES AND EXTRACT TRANSCRIPTS\n",
        "print(\"\\nSTEP 8: Processing audio files and extracting transcripts...\")\n",
        "print(\"This may take a while depending on the number and length of audio files...\")\n",
        "\n",
        "def process_audio_files(wav_files):\n",
        "    \"\"\"Process all audio files and extract transcripts\"\"\"\n",
        "    all_transcripts = []\n",
        "\n",
        "    # Process progression training data\n",
        "    print(\"\\n  Processing progression training data...\")\n",
        "    for label in ['decline', 'no_decline']:\n",
        "        files = wav_files['progression_train'][label]\n",
        "        print(f\"    Processing {len(files)} {label} files...\")\n",
        "\n",
        "        for i, audio_path in enumerate(files):\n",
        "            print(f\"      Processing {i+1}/{len(files)}: {os.path.basename(audio_path)}\")\n",
        "\n",
        "            transcript, method_or_error = extract_transcript_from_audio(audio_path)\n",
        "\n",
        "            all_transcripts.append({\n",
        "                'file_id': os.path.splitext(os.path.basename(audio_path))[0],\n",
        "                'file_path': audio_path,\n",
        "                'dataset': 'progression_train',\n",
        "                'label': label,\n",
        "                'transcript': transcript,\n",
        "                'recognition_method': method_or_error if transcript else None,\n",
        "                'error': None if transcript else method_or_error,\n",
        "                'success': transcript is not None\n",
        "            })\n",
        "\n",
        "    # Process progression test data\n",
        "    print(\"\\n  Processing progression test data...\")\n",
        "    files = wav_files['progression_test']\n",
        "    print(f\"    Processing {len(files)} test files...\")\n",
        "\n",
        "    for i, audio_path in enumerate(files):\n",
        "        print(f\"      Processing {i+1}/{len(files)}: {os.path.basename(audio_path)}\")\n",
        "\n",
        "        transcript, method_or_error = extract_transcript_from_audio(audio_path)\n",
        "\n",
        "        all_transcripts.append({\n",
        "            'file_id': os.path.splitext(os.path.basename(audio_path))[0],\n",
        "            'file_path': audio_path,\n",
        "            'dataset': 'progression_test',\n",
        "            'label': 'test',\n",
        "            'transcript': transcript,\n",
        "            'recognition_method': method_or_error if transcript else None,\n",
        "            'error': None if transcript else method_or_error,\n",
        "            'success': transcript is not None\n",
        "        })\n",
        "\n",
        "    # Process diagnosis training data\n",
        "    print(\"\\n  Processing diagnosis training data...\")\n",
        "    for label in ['ad', 'cn']:\n",
        "        files = wav_files['diagnosis_train'][label]\n",
        "        print(f\"    Processing {len(files)} {label} files...\")\n",
        "\n",
        "        for i, audio_path in enumerate(files):\n",
        "            print(f\"      Processing {i+1}/{len(files)}: {os.path.basename(audio_path)}\")\n",
        "\n",
        "            transcript, method_or_error = extract_transcript_from_audio(audio_path)\n",
        "\n",
        "            all_transcripts.append({\n",
        "                'file_id': os.path.splitext(os.path.basename(audio_path))[0],\n",
        "                'file_path': audio_path,\n",
        "                'dataset': 'diagnosis_train',\n",
        "                'label': label,\n",
        "                'transcript': transcript,\n",
        "                'recognition_method': method_or_error if transcript else None,\n",
        "                'error': None if transcript else method_or_error,\n",
        "                'success': transcript is not None\n",
        "            })\n",
        "\n",
        "    return all_transcripts\n",
        "\n",
        "# Process all files\n",
        "transcripts = process_audio_files(wav_files)\n",
        "\n",
        "# STEP 9: SAVE RESULTS\n",
        "print(\"\\nSTEP 9: Saving transcription results...\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(transcripts)\n",
        "\n",
        "# Save complete results\n",
        "complete_output = os.path.join(OUTPUT_PATH, \"all_transcripts.csv\")\n",
        "df.to_csv(complete_output, index=False)\n",
        "print(f\"✓ Saved complete results to: {complete_output}\")\n",
        "\n",
        "# Save successful transcripts only\n",
        "successful_df = df[df['success'] == True].copy()\n",
        "success_output = os.path.join(OUTPUT_PATH, \"successful_transcripts.csv\")\n",
        "successful_df.to_csv(success_output, index=False)\n",
        "print(f\"✓ Saved successful transcripts to: {success_output}\")\n",
        "\n",
        "# Save by dataset\n",
        "datasets_to_save = df['dataset'].unique()\n",
        "for dataset in datasets_to_save:\n",
        "    dataset_df = df[df['dataset'] == dataset].copy()\n",
        "    dataset_output = os.path.join(OUTPUT_PATH, f\"{dataset}_transcripts.csv\")\n",
        "    dataset_df.to_csv(dataset_output, index=False)\n",
        "    print(f\"✓ Saved {dataset} transcripts to: {dataset_output}\")\n",
        "\n",
        "# STEP 10: DISPLAY SUMMARY STATISTICS\n",
        "print(\"\\nSTEP 10: Summary Statistics\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "total_files = len(df)\n",
        "successful = len(successful_df)\n",
        "failed = total_files - successful\n",
        "\n",
        "print(f\"Total audio files processed: {total_files}\")\n",
        "print(f\"Successful transcriptions: {successful} ({successful/total_files*100:.1f}%)\")\n",
        "print(f\"Failed transcriptions: {failed} ({failed/total_files*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nDataset breakdown:\")\n",
        "for dataset in df['dataset'].unique():\n",
        "    dataset_total = len(df[df['dataset'] == dataset])\n",
        "    dataset_success = len(df[(df['dataset'] == dataset) & (df['success'] == True)])\n",
        "    print(f\"  {dataset}: {dataset_success}/{dataset_total} successful ({dataset_success/dataset_total*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nLabel distribution (successful transcripts only):\")\n",
        "if not successful_df.empty:\n",
        "    print(successful_df['label'].value_counts())\n",
        "\n",
        "print(f\"\\nRecognition methods used:\")\n",
        "if not successful_df.empty:\n",
        "    print(successful_df['recognition_method'].value_counts())\n",
        "\n",
        "# Show sample transcripts\n",
        "print(f\"\\nSample successful transcripts:\")\n",
        "sample_transcripts = successful_df['transcript'].dropna().head(3)\n",
        "for i, transcript in enumerate(sample_transcripts):\n",
        "    print(f\"  Sample {i+1}: {transcript[:200]}...\")\n",
        "\n",
        "# Show common errors\n",
        "print(f\"\\nMost common errors:\")\n",
        "error_df = df[df['success'] == False]\n",
        "if not error_df.empty:\n",
        "    error_counts = error_df['error'].value_counts().head(5)\n",
        "    for error, count in error_counts.items():\n",
        "        print(f\"  {error}: {count} files\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRANSCRIPT EXTRACTION COMPLETE!\")\n",
        "print(f\"All results saved in: {OUTPUT_PATH}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56RZ8BRdy4pM",
        "outputId": "59419cb2-f3c8-41e2-f915-5a84cd8c4a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ADReSSo21 AUDIO TRANSCRIPT EXTRACTOR\n",
            "============================================================\n",
            "\n",
            "STEP 1: Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "✓ Google Drive mounted successfully!\n",
            "\n",
            "STEP 2: Installing required packages...\n",
            "Installing speech recognition and audio processing libraries...\n",
            "✓ Packages ready (make sure to install them first)\n",
            "\n",
            "STEP 3: Setting up paths and configuration...\n",
            "✓ Base path: /content/drive/MyDrive/Voice/\n",
            "✓ Extract path: /content/drive/MyDrive/Voice/extracted/\n",
            "✓ Output path: /content/drive/MyDrive/Voice/transcripts/\n",
            "\n",
            "STEP 4: Extracting dataset files...\n",
            "  Extracting ADReSSo21-progression-train.tgz...\n",
            "  ✓ ADReSSo21-progression-train.tgz extracted successfully\n",
            "  Extracting ADReSSo21-progression-test.tgz...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SgZdh7FonhH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}