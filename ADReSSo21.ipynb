{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwsS3IIdlf9+JyyahODAWy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/ADReSSo21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBXVhfF-wLZg",
        "outputId": "56caccd4-d10d-4749-a4a7-dc4426e477f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting ADReSSo21 transcript extraction...\n",
            "Extracting datasets...\n",
            "⚠ Warning: ADReSSo21-progression-train.tgz not found at /drive/MyDrive/Voice/ADReSSo21-progression-train.tgz\n",
            "⚠ Warning: ADReSSo21-progression-test.tgz not found at /drive/MyDrive/Voice/ADReSSo21-progression-test.tgz\n",
            "⚠ Warning: ADReSSo21-diagnosis-train.tgz not found at /drive/MyDrive/Voice/ADReSSo21-diagnosis-train.tgz\n",
            "\n",
            "==================================================\n",
            "EXTRACTING PROGRESSION TRANSCRIPTS\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "EXTRACTING DIAGNOSIS TRANSCRIPTS\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "EXTRACTION COMPLETE!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "class ADReSSo21TranscriptExtractor:\n",
        "    def __init__(self, base_path=\"/drive/MyDrive/Voice/\"):\n",
        "        self.base_path = base_path\n",
        "        self.datasets = {\n",
        "            'progression_train': 'ADReSSo21-progression-train.tgz',\n",
        "            'progression_test': 'ADReSSo21-progression-test.tgz',\n",
        "            'diagnosis_train': 'ADReSSo21-diagnosis-train.tgz'\n",
        "        }\n",
        "        self.extracted_path = os.path.join(base_path, \"extracted\")\n",
        "\n",
        "    def extract_datasets(self):\n",
        "        \"\"\"Extract all tgz files to the extracted directory\"\"\"\n",
        "        print(\"Extracting datasets...\")\n",
        "\n",
        "        # Create extraction directory\n",
        "        os.makedirs(self.extracted_path, exist_ok=True)\n",
        "\n",
        "        for dataset_name, filename in self.datasets.items():\n",
        "            file_path = os.path.join(self.base_path, filename)\n",
        "\n",
        "            if os.path.exists(file_path):\n",
        "                print(f\"Extracting {filename}...\")\n",
        "                with tarfile.open(file_path, 'r:gz') as tar:\n",
        "                    tar.extractall(path=self.extracted_path)\n",
        "                print(f\"✓ {filename} extracted successfully\")\n",
        "            else:\n",
        "                print(f\"⚠ Warning: {filename} not found at {file_path}\")\n",
        "\n",
        "    def find_csv_files(self, directory):\n",
        "        \"\"\"Recursively find all CSV files in a directory\"\"\"\n",
        "        csv_files = []\n",
        "        for root, dirs, files in os.walk(directory):\n",
        "            for file in files:\n",
        "                if file.endswith('.csv'):\n",
        "                    csv_files.append(os.path.join(root, file))\n",
        "        return csv_files\n",
        "\n",
        "    def read_transcript_csv(self, csv_path):\n",
        "        \"\"\"Read and process a single CSV transcript file\"\"\"\n",
        "        try:\n",
        "            # Try different encodings as CSV files might have different encodings\n",
        "            encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
        "\n",
        "            for encoding in encodings:\n",
        "                try:\n",
        "                    df = pd.read_csv(csv_path, encoding=encoding)\n",
        "                    break\n",
        "                except UnicodeDecodeError:\n",
        "                    continue\n",
        "            else:\n",
        "                print(f\"⚠ Could not read {csv_path} with any encoding\")\n",
        "                return None\n",
        "\n",
        "            # Get filename without extension for ID\n",
        "            file_id = os.path.splitext(os.path.basename(csv_path))[0]\n",
        "\n",
        "            # Add file info\n",
        "            df['file_id'] = file_id\n",
        "            df['file_path'] = csv_path\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {csv_path}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def extract_progression_transcripts(self):\n",
        "        \"\"\"Extract transcripts from progression datasets\"\"\"\n",
        "        transcripts = {\n",
        "            'train': {'decline': [], 'no_decline': []},\n",
        "            'test': []\n",
        "        }\n",
        "\n",
        "        # Process training data\n",
        "        train_path = os.path.join(self.extracted_path, \"ADReSSo21/progression/train/segmentation\")\n",
        "\n",
        "        if os.path.exists(train_path):\n",
        "            # Decline cases\n",
        "            decline_path = os.path.join(train_path, \"decline\")\n",
        "            if os.path.exists(decline_path):\n",
        "                csv_files = self.find_csv_files(decline_path)\n",
        "                print(f\"Found {len(csv_files)} CSV files in decline directory\")\n",
        "\n",
        "                for csv_file in csv_files:\n",
        "                    df = self.read_transcript_csv(csv_file)\n",
        "                    if df is not None:\n",
        "                        df['label'] = 'decline'\n",
        "                        transcripts['train']['decline'].append(df)\n",
        "\n",
        "            # No decline cases\n",
        "            no_decline_path = os.path.join(train_path, \"no_decline\")\n",
        "            if os.path.exists(no_decline_path):\n",
        "                csv_files = self.find_csv_files(no_decline_path)\n",
        "                print(f\"Found {len(csv_files)} CSV files in no_decline directory\")\n",
        "\n",
        "                for csv_file in csv_files:\n",
        "                    df = self.read_transcript_csv(csv_file)\n",
        "                    if df is not None:\n",
        "                        df['label'] = 'no_decline'\n",
        "                        transcripts['train']['no_decline'].append(df)\n",
        "\n",
        "        # Process test data\n",
        "        test_path = os.path.join(self.extracted_path, \"ADReSSo21/progression/test-dist/segmentation\")\n",
        "\n",
        "        if os.path.exists(test_path):\n",
        "            csv_files = self.find_csv_files(test_path)\n",
        "            print(f\"Found {len(csv_files)} CSV files in test directory\")\n",
        "\n",
        "            for csv_file in csv_files:\n",
        "                df = self.read_transcript_csv(csv_file)\n",
        "                if df is not None:\n",
        "                    df['label'] = 'test'\n",
        "                    transcripts['test'].append(df)\n",
        "\n",
        "        return transcripts\n",
        "\n",
        "    def extract_diagnosis_transcripts(self):\n",
        "        \"\"\"Extract transcripts from diagnosis dataset\"\"\"\n",
        "        transcripts = {'ad': [], 'cn': []}\n",
        "\n",
        "        base_path = os.path.join(self.extracted_path, \"ADReSSo21/diagnosis/train/segmentation\")\n",
        "\n",
        "        if os.path.exists(base_path):\n",
        "            # AD (Alzheimer's Disease) cases\n",
        "            ad_path = os.path.join(base_path, \"ad\")\n",
        "            if os.path.exists(ad_path):\n",
        "                csv_files = self.find_csv_files(ad_path)\n",
        "                print(f\"Found {len(csv_files)} CSV files in AD directory\")\n",
        "\n",
        "                for csv_file in csv_files:\n",
        "                    df = self.read_transcript_csv(csv_file)\n",
        "                    if df is not None:\n",
        "                        df['label'] = 'ad'\n",
        "                        transcripts['ad'].append(df)\n",
        "\n",
        "            # CN (Cognitive Normal) cases\n",
        "            cn_path = os.path.join(base_path, \"cn\")\n",
        "            if os.path.exists(cn_path):\n",
        "                csv_files = self.find_csv_files(cn_path)\n",
        "                print(f\"Found {len(csv_files)} CSV files in CN directory\")\n",
        "\n",
        "                for csv_file in csv_files:\n",
        "                    df = self.read_transcript_csv(csv_file)\n",
        "                    if df is not None:\n",
        "                        df['label'] = 'cn'\n",
        "                        transcripts['cn'].append(df)\n",
        "\n",
        "        return transcripts\n",
        "\n",
        "    def combine_and_save_transcripts(self, transcripts, dataset_name):\n",
        "        \"\"\"Combine transcript dataframes and save to CSV\"\"\"\n",
        "        all_transcripts = []\n",
        "\n",
        "        if dataset_name == 'progression':\n",
        "            # Combine training data\n",
        "            for label in ['decline', 'no_decline']:\n",
        "                if transcripts['train'][label]:\n",
        "                    combined = pd.concat(transcripts['train'][label], ignore_index=True)\n",
        "                    all_transcripts.append(combined)\n",
        "\n",
        "            # Combine test data\n",
        "            if transcripts['test']:\n",
        "                combined_test = pd.concat(transcripts['test'], ignore_index=True)\n",
        "                all_transcripts.append(combined_test)\n",
        "\n",
        "        elif dataset_name == 'diagnosis':\n",
        "            # Combine AD and CN data\n",
        "            for label in ['ad', 'cn']:\n",
        "                if transcripts[label]:\n",
        "                    combined = pd.concat(transcripts[label], ignore_index=True)\n",
        "                    all_transcripts.append(combined)\n",
        "\n",
        "        if all_transcripts:\n",
        "            final_df = pd.concat(all_transcripts, ignore_index=True)\n",
        "\n",
        "            # Save to CSV\n",
        "            output_path = os.path.join(self.base_path, f\"{dataset_name}_transcripts.csv\")\n",
        "            final_df.to_csv(output_path, index=False)\n",
        "            print(f\"✓ Saved {len(final_df)} transcript records to {output_path}\")\n",
        "\n",
        "            return final_df\n",
        "\n",
        "        return None\n",
        "\n",
        "    def display_sample_data(self, df, dataset_name):\n",
        "        \"\"\"Display sample data and statistics\"\"\"\n",
        "        print(f\"\\n=== {dataset_name.upper()} DATASET SUMMARY ===\")\n",
        "        print(f\"Total records: {len(df)}\")\n",
        "\n",
        "        if 'label' in df.columns:\n",
        "            print(\"\\nLabel distribution:\")\n",
        "            print(df['label'].value_counts())\n",
        "\n",
        "        print(f\"\\nColumns: {list(df.columns)}\")\n",
        "\n",
        "        print(f\"\\nSample data:\")\n",
        "        print(df.head())\n",
        "\n",
        "        # Show some transcript samples if available\n",
        "        text_columns = [col for col in df.columns if 'text' in col.lower() or 'transcript' in col.lower() or 'word' in col.lower()]\n",
        "        if text_columns:\n",
        "            print(f\"\\nSample transcript content from column '{text_columns[0]}':\")\n",
        "            for i, text in enumerate(df[text_columns[0]].dropna().head(3)):\n",
        "                print(f\"Sample {i+1}: {str(text)[:200]}...\")\n",
        "\n",
        "    def run_extraction(self):\n",
        "        \"\"\"Main method to run the complete extraction process\"\"\"\n",
        "        print(\"Starting ADReSSo21 transcript extraction...\")\n",
        "\n",
        "        # Extract datasets\n",
        "        self.extract_datasets()\n",
        "\n",
        "        # Extract progression transcripts\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"EXTRACTING PROGRESSION TRANSCRIPTS\")\n",
        "        print(\"=\"*50)\n",
        "        progression_transcripts = self.extract_progression_transcripts()\n",
        "        progression_df = self.combine_and_save_transcripts(progression_transcripts, 'progression')\n",
        "\n",
        "        if progression_df is not None:\n",
        "            self.display_sample_data(progression_df, 'progression')\n",
        "\n",
        "        # Extract diagnosis transcripts\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"EXTRACTING DIAGNOSIS TRANSCRIPTS\")\n",
        "        print(\"=\"*50)\n",
        "        diagnosis_transcripts = self.extract_diagnosis_transcripts()\n",
        "        diagnosis_df = self.combine_and_save_transcripts(diagnosis_transcripts, 'diagnosis')\n",
        "\n",
        "        if diagnosis_df is not None:\n",
        "            self.display_sample_data(diagnosis_df, 'diagnosis')\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"EXTRACTION COMPLETE!\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        return progression_df, diagnosis_df\n",
        "\n",
        "# Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize extractor\n",
        "    extractor = ADReSSo21TranscriptExtractor()\n",
        "\n",
        "    # Run extraction\n",
        "    progression_df, diagnosis_df = extractor.run_extraction()\n",
        "\n",
        "    # Optional: Access individual datasets\n",
        "    # You can also use these methods individually:\n",
        "    # extractor.extract_datasets()\n",
        "    # progression_transcripts = extractor.extract_progression_transcripts()\n",
        "    # diagnosis_transcripts = extractor.extract_diagnosis_transcripts()"
      ]
    }
  ]
}