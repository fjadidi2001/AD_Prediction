{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6v+ecLiCPoBufHcWx+Q4K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/hippocampus_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y7Rnz7jM6FGD",
        "outputId": "458e8591-5575-4d13-cde6-2a8322de6247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting montage\n",
            "  Downloading montage-0.3.6.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decoupage>=0.8 (from montage)\n",
            "  Downloading decoupage-0.16.0.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cropresize (from montage)\n",
            "  Downloading cropresize-0.2.0.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting WebOb (from decoupage>=0.8->montage)\n",
            "  Downloading WebOb-1.8.9-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting Paste (from decoupage>=0.8->montage)\n",
            "  Downloading Paste-3.10.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting PasteScript (from decoupage>=0.8->montage)\n",
            "  Downloading PasteScript-3.7.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting genshi (from decoupage>=0.8->montage)\n",
            "  Downloading Genshi-0.7.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting martINI>=0.4.2 (from decoupage>=0.8->montage)\n",
            "  Downloading martINI-0.7.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting contenttransformer>=0.3.3 (from decoupage>=0.8->montage)\n",
            "  Downloading contenttransformer-0.3.5.tar.gz (3.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyRSS2Gen (from decoupage>=0.8->montage)\n",
            "  Downloading PyRSS2Gen-1.1.tar.gz (6.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from cropresize->montage) (11.1.0)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.11/dist-packages (from contenttransformer>=0.3.3->decoupage>=0.8->montage) (0.21.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from genshi->decoupage>=0.8->montage) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from Paste->decoupage>=0.8->montage) (75.2.0)\n",
            "Collecting PasteDeploy (from PasteScript->decoupage>=0.8->montage)\n",
            "  Downloading PasteDeploy-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading Genshi-0.7.9-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.8/177.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Paste-3.10.1-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PasteScript-3.7.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading WebOb-1.8.9-py2.py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PasteDeploy-3.1.0-py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: montage, decoupage, cropresize, contenttransformer, martINI, PyRSS2Gen\n",
            "  Building wheel for montage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for montage: filename=montage-0.3.6-py3-none-any.whl size=2735 sha256=5e99e21273aa05ea83ea47d7fede0e6a23489f8a9b27c6dacbf0259b2d7346d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/60/be/32c2c515edfb6abfd460be9ab3841a6dfbda1bd872bb410a72\n",
            "  Building wheel for decoupage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for decoupage: filename=decoupage-0.16.0-py3-none-any.whl size=16959 sha256=561e3c6459ec5c87ac6ca926af75728fa8a84845e2649de57243403bc9d20dd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/d9/23/17f6b015cac5a9984050b26db55b20c0c828d57efbeaaa3e28\n",
            "  Building wheel for cropresize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cropresize: filename=cropresize-0.2.0-py3-none-any.whl size=2803 sha256=cb47343ba54d8876845e7247ba31c1650c93542ad11da6c3eccf798d9828e519\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/b5/8e/5015b9e37c3b6984f8fa266440e15ea46ee1587d6df4adaba1\n",
            "  Building wheel for contenttransformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contenttransformer: filename=contenttransformer-0.3.5-py3-none-any.whl size=5116 sha256=7d2763e4a8ef4c1dcd7c9e9fceb348fd50dda26676ddb256c7700c3325c97919\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/e5/7a/de2950e0c019ff641af0edde5a46e63c36c6954f0d63910597\n",
            "  Building wheel for martINI (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for martINI: filename=martINI-0.7-py3-none-any.whl size=16474 sha256=664307f700c87696fc9b0a47318c3ada50a99aeea88e1155d715d09a525ad001\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/9e/2d/1b0f3dace509809e6ff0d6678a5bceef35363688557e3e086d\n",
            "  Building wheel for PyRSS2Gen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyRSS2Gen: filename=PyRSS2Gen-1.1-py3-none-any.whl size=4968 sha256=1a4b61ba7e4b1e3706031813651261f70a2ba732b064507dc89853f5d0bccbef\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/5d/bc/a9bebae789186d3597b203923025fccb1d9bec4269db02d48b\n",
            "Successfully built montage decoupage cropresize contenttransformer martINI PyRSS2Gen\n",
            "Installing collected packages: PyRSS2Gen, WebOb, PasteDeploy, Paste, genshi, cropresize, PasteScript, martINI, contenttransformer, decoupage, montage\n",
            "Successfully installed Paste-3.10.1 PasteDeploy-3.1.0 PasteScript-3.7.0 PyRSS2Gen-1.1 WebOb-1.8.9 contenttransformer-0.3.5 cropresize-0.2.0 decoupage-0.16.0 genshi-0.7.9 martINI-0.7 montage-0.3.6\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'skimage.util.montage'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3a9f127af00b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmontage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmontage2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage.util.montage'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install montage\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "from skimage.util.montage import montage2d\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip -q \"/content/hippocampus segmentation dataset.zip\" -d \"/content/hippocampus_dataset\"\n",
        "\n",
        "# Constants\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "# Seeding\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Define dataset paths (adjust based on unzipped structure)\n",
        "data = \"/content/hippocampus_dataset/seghipp0/images\"\n",
        "data_left = \"/content/hippocampus_dataset/seghipp0/masks/left\"\n",
        "data_right = \"/content/hippocampus_dataset/seghipp0/masks/right\"\n",
        "\n",
        "# Load image and mask file paths\n",
        "train_data = []\n",
        "for dirName, _, fileList in sorted(os.walk(data)):\n",
        "    for filename in fileList:\n",
        "        if \".jpg\" in filename.lower():\n",
        "            train_data.append(os.path.join(dirName, filename))\n",
        "\n",
        "mask_left = []\n",
        "for dirName, _, fileList in sorted(os.walk(data_left)):\n",
        "    for filename in fileList:\n",
        "        if \".jpg\" in filename.lower():\n",
        "            mask_left.append(os.path.join(dirName, filename))\n",
        "\n",
        "mask_right = []\n",
        "for dirName, _, fileList in sorted(os.walk(data_right)):\n",
        "    for filename in fileList:\n",
        "        if \".jpg\" in filename.lower():\n",
        "            mask_right.append(os.path.join(dirName, filename))\n",
        "\n",
        "# Initialize arrays for training data\n",
        "X_train = np.zeros((len(train_data), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
        "Y_train = np.zeros((len(train_data), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
        "\n",
        "# Load and preprocess images\n",
        "for file_index in tqdm(range(len(train_data)), desc=\"Loading images\"):\n",
        "    img = imread(train_data[file_index])\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), mode='constant', preserve_range=True)\n",
        "    img = img / 255.0\n",
        "    X_train[file_index] = img\n",
        "\n",
        "# Load and preprocess masks\n",
        "for n in tqdm(range(len(mask_right)), desc=\"Loading masks\"):\n",
        "    maskl = imread(mask_left[n], as_gray=True)\n",
        "    maskr = imread(mask_right[n], as_gray=True)\n",
        "    mask = np.maximum(maskl, maskr)\n",
        "    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH, 1), mode='constant', preserve_range=True)\n",
        "    mask = mask / 255.0\n",
        "    Y_train[n] = mask\n",
        "\n",
        "# Visualize a sample\n",
        "id = 10\n",
        "print(X_train[id].shape)\n",
        "plt.figure()\n",
        "imshow(X_train[id])\n",
        "plt.title(\"Sample Image\")\n",
        "plt.show()\n",
        "plt.figure()\n",
        "imshow(Y_train[id][:, :, 0], cmap='gray')\n",
        "plt.title(\"Sample Mask\")\n",
        "plt.show()\n",
        "\n",
        "# Shuffle and split data\n",
        "X_train, Y_train = shuffle(X_train, Y_train, random_state=42)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "# Visualize random sample\n",
        "image_x = random.randint(0, len(X_train) - 1)\n",
        "fig, ax = plt.subplots(1, 3, figsize=(16, 12))\n",
        "ax[0].imshow(X_train[image_x], cmap='gray')\n",
        "ax[0].set_title(\"Image\")\n",
        "ax[1].imshow(np.squeeze(Y_train[image_x]), cmap='gray')\n",
        "ax[1].set_title(\"Mask\")\n",
        "ax[2].imshow(X_train[image_x], cmap='gray', interpolation='none')\n",
        "ax[2].imshow(np.squeeze(Y_train[image_x]), cmap='jet', interpolation='none', alpha=0.7)\n",
        "ax[2].set_title(\"Overlay\")\n",
        "plt.show()\n",
        "\n",
        "# Montage visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "ax1.imshow(montage2d(X_train[:, :, :, 0]), cmap='gray')\n",
        "ax1.set_title('MRI Input Images Samples')\n",
        "ax2.imshow(montage2d(Y_train[:, :, :, 0]), cmap='gray')\n",
        "ax2.set_title('Ground Truth Masks Samples')\n",
        "plt.show()\n",
        "\n",
        "# Define Dice coefficient and loss\n",
        "smooth = 1.\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "# Build U-Net model\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "# Contraction path\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "# Expansive path\n",
        "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "# Compile model\n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss=dice_coef_loss, metrics=[dice_coef])\n",
        "model.summary()\n",
        "\n",
        "# Callbacks\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.h5', verbose=1, save_best_only=True)\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
        "    checkpointer\n",
        "]\n",
        "\n",
        "# Train model\n",
        "results = model.fit(X_train, Y_train, validation_split=0.1, shuffle=True, batch_size=16, epochs=10, callbacks=callbacks)\n",
        "\n",
        "# Predictions\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0] * 0.9)], verbose=1)\n",
        "preds_val = model.predict(X_train[int(X_train.shape[0] * 0.9):], verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "# Threshold predictions\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
        "\n",
        "# Visualize test sample\n",
        "id = random.randint(0, len(preds_test_t) - 1)\n",
        "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "ax[0].imshow(X_test[id], cmap='gray')\n",
        "ax[0].set_title(\"X_test\")\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(np.squeeze(Y_test[id]), cmap='gray')\n",
        "ax[1].set_title(\"Y_test\")\n",
        "ax[1].axis('off')\n",
        "ax[2].imshow(np.squeeze(preds_test_t[id]), cmap='gray')\n",
        "ax[2].set_title(\"Prediction\")\n",
        "ax[2].axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Visualize overlay\n",
        "fig, ax = plt.subplots(1, 4, figsize=(16, 12))\n",
        "ax[0].imshow(X_test[id], cmap='gray')\n",
        "ax[0].set_title(\"Image\")\n",
        "ax[1].imshow(np.squeeze(preds_test_t[id]), cmap='gray')\n",
        "ax[1].set_title(\"Predicted Mask\")\n",
        "ax[2].imshow(np.squeeze(Y_test[id]), cmap='gray')\n",
        "ax[2].set_title(\"Ground Truth Mask\")\n",
        "ax[3].imshow(X_test[id], cmap='gray', interpolation='none')\n",
        "ax[3].imshow(np.squeeze(preds_test_t[id]), cmap='jet', interpolation='none', alpha=0.7)\n",
        "ax[3].set_title(\"Overlay\")\n",
        "plt.show()\n",
        "\n",
        "# Montage of test data\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "ax1.imshow(montage2d(X_test[:, :, :, 0]), cmap='gray')\n",
        "ax1.set_title('MRI Input Images Samples')\n",
        "ax2.imshow(montage2d(Y_test[:, :, :, 0]), cmap='gray')\n",
        "ax2.set_title('Ground Truth Masks Samples')\n",
        "plt.show()\n",
        "\n",
        "# Plot predictions function\n",
        "def plotPredictions(a, b, c, d, e):\n",
        "    model = e\n",
        "    preds_train = model.predict(a[:int(a.shape[0] * 0.9)], verbose=1)\n",
        "    preds_val = model.predict(a[int(a.shape[0] * 0.9):], verbose=1)\n",
        "    preds_test = model.predict(c, verbose=1)\n",
        "    preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "    preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "    preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
        "\n",
        "    # Training sample\n",
        "    ix = random.randint(0, len(preds_train_t) - 1)\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    ax[0].imshow(a[ix], cmap='gray')\n",
        "    ax[0].set_title(\"X_train\")\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(np.squeeze(b[ix]), cmap='gray')\n",
        "    ax[1].set_title(\"Y_train\")\n",
        "    ax[1].axis('off')\n",
        "    ax[2].imshow(np.squeeze(preds_train_t[ix]), cmap='gray')\n",
        "    ax[2].set_title(\"Prediction\")\n",
        "    ax[2].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Validation sample\n",
        "    ix = random.randint(0, len(preds_val_t) - 1)\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    ax[0].imshow(a[int(a.shape[0] * 0.9):][ix], cmap='gray')\n",
        "    ax[0].set_title(\"X_val\")\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(np.squeeze(b[int(b.shape[0] * 0.9):][ix]), cmap='gray')\n",
        "    ax[1].set_title(\"Y_val\")\n",
        "    ax[1].axis('off')\n",
        "    ax[2].imshow(np.squeeze(preds_val_t[ix]), cmap='gray')\n",
        "    ax[2].set_title(\"Prediction\")\n",
        "    ax[2].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "plotPredictions(X_train, Y_train, X_test, Y_test, model)\n",
        "\n",
        "# Plot training history\n",
        "acc = results.history.get('dice_coef', results.history.get('acc'))\n",
        "val_acc = results.history.get('val_dice_coef', results.history.get('val_acc'))\n",
        "loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, acc, 'r', label='Training Dice Coef')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Dice Coef')\n",
        "plt.title('Training and Validation Dice Coefficient')\n",
        "plt.ylabel('Dice Coefficient')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ]
}