{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfb5HJMVPeCRBxq6ohIZqb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/Graph_Attention_and_Feature_Fusion_for_Robust_Alzheimer%E2%80%99s_Disease_Diagnosis_from_the_ADReSSo21_Speech_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Final_output Folder, Install Dependencies, and Mount Google Drive"
      ],
      "metadata": {
        "id": "cDekvCObykj8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fwYEXVvv7FS"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Create Final_output directory and subdirectories\n",
        "try:\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/Final_output\"\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, \"visualizations\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, \"models\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, \"logs\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, \"transcripts\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, \"features\"), exist_ok=True)\n",
        "    print(f\"Created output directories at {OUTPUT_DIR}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating directories: {str(e)}\")\n",
        "\n",
        "# Install required packages\n",
        "try:\n",
        "    packages = [\n",
        "        \"librosa\", \"soundfile\", \"opensmile\", \"speechbrain\",\n",
        "        \"transformers\", \"torch\", \"openai-whisper\",\n",
        "        \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\", \"torch-geometric\"\n",
        "    ]\n",
        "    for pkg in packages:\n",
        "        subprocess.check_call([\"pip\", \"install\", pkg])\n",
        "    print(\"All required packages installed successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error installing packages: {str(e)}\")\n",
        "\n",
        "# Mount Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and Define Error Logging"
      ],
      "metadata": {
        "id": "vhBfVvJF1LPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import json\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import warnings\n",
        "import opensmile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
        "from torch_geometric.data import Data, Batch\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2Model, BertTokenizer, BertModel\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import networkx as nx\n",
        "import whisper\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "\n",
        "# Error logging function\n",
        "def log_error(message: str):\n",
        "    log_file = os.path.join(\"/content/drive/MyDrive/Final_output\", \"logs\", \"pipeline_errors.log\")\n",
        "    with open(log_file, 'a') as f:\n",
        "        f.write(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} - {message}\\n\")\n",
        "    print(f\"Error logged: {message}\")"
      ],
      "metadata": {
        "id": "HgQHjFBr1HkT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}