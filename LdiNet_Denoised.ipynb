{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/LdiNet_Denoised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsYNpJhavKlU"
      },
      "source": [
        "# A Novel Approach to Noise Reduction in Images Utilizing a Decomposition Technique"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install Dependencies\n",
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install opencv-python-headless\n",
        "!pip install pandas seaborn matplotlib\n",
        "!pip install scikit-image\n",
        "!pip install denoising-diffusion-pytorch\n",
        "\n",
        "# Cell 2: Import Libraries and Setup Environment\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, datasets\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Cell 3: Visualize Package Versions\n",
        "import pkg_resources\n",
        "packages = ['torch', 'torchvision', 'opencv-python-headless', 'pandas', 'seaborn', 'matplotlib', 'denoising-diffusion-pytorch']\n",
        "versions = {pkg: pkg_resources.get_distribution(pkg).version for pkg in packages}\n",
        "df_versions = pd.DataFrame(list(versions.items()), columns=['Package', 'Version'])\n",
        "\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.table(cellText=df_versions.values, colLabels=df_versions.columns, loc='center', cellLoc='center')\n",
        "plt.axis('off')\n",
        "plt.title(\"Installed Package Versions\")\n",
        "plt.savefig('package_versions.png')\n",
        "plt.show()\n",
        "\n",
        "# Cell 4: Download and Extract BSR Dataset\n",
        "try:\n",
        "    if not os.path.exists('BSR_bsds500.tgz'):\n",
        "        !wget https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\n",
        "    if not os.path.exists('BSR'):\n",
        "        !tar xzf BSR_bsds500.tgz\n",
        "    print(\"Dataset loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "\n",
        "# Cell 5: Create Custom Dataset Class\n",
        "import glob\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class BSRDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.image_paths = glob.glob(os.path.join(root_dir, '*.jpg'))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('L')  # Grayscale\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, 0  # Dummy label\n",
        "\n",
        "# Cell 6: Define Transforms and Create DataLoader\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load BSR dataset (train folder)\n",
        "bsr_train_path = 'BSR/BSDS500/data/images/train'\n",
        "dataset = BSRDataset(bsr_train_path, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Cell 7: Prepare Sample Image for Visualization\n",
        "# Load a sample image\n",
        "image_path = 'BSR/BSDS500/data/images/train/100075.jpg'\n",
        "original_image = Image.open(image_path).convert('L')\n",
        "np_image = np.array(original_image)\n",
        "\n",
        "# Add Gaussian noise\n",
        "sigma = 25\n",
        "noisy_image = np_image + np.random.normal(0, sigma, np_image.shape)\n",
        "noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
        "noisy_image_pil = Image.fromarray(noisy_image)\n",
        "\n",
        "# Convert to tensor\n",
        "noisy_tensor = transform(noisy_image_pil).to(device)\n",
        "\n",
        "# Cell 8: Compute Initial Metrics\n",
        "psnr_noisy = psnr(np_image, noisy_image, data_range=255)\n",
        "ssim_noisy = ssim(np_image, noisy_image, data_range=255)\n",
        "metrics = pd.DataFrame({\n",
        "    'Stage': ['Noisy'],\n",
        "    'PSNR': [psnr_noisy],\n",
        "    'SSIM': [ssim_noisy]\n",
        "})\n",
        "\n",
        "# Visualization: Original, Noisy, and Metrics\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(original_image, cmap='gray')\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(noisy_image, cmap='gray')\n",
        "plt.title(f'Noisy Image (σ={sigma})')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.table(cellText=metrics.values, colLabels=metrics.columns, loc='center', cellLoc='center')\n",
        "plt.axis('off')\n",
        "plt.title(\"Initial Metrics (Noisy vs Original)\")\n",
        "plt.savefig('initial_comparison.png')\n",
        "plt.show()\n",
        "\n",
        "# Cell 9: Define Enhanced LDINet Model\n",
        "class EnhancedLDINet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EnhancedLDINet, self).__init__()\n",
        "        # Encoder\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.enc3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256)\n",
        "        )\n",
        "        # Texture branch\n",
        "        self.texture_branch = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 1, 3, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        # Structure branch\n",
        "        self.structure_branch = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 1, 3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(e1)\n",
        "        e3 = self.enc3(e2)\n",
        "        texture = self.texture_branch(e3)\n",
        "        structure = self.structure_branch(e3)\n",
        "        return texture, structure\n",
        "\n",
        "# Cell 10: Initialize and Train EnhancedLDINet\n",
        "ldinet = EnhancedLDINet().to(device)\n",
        "optimizer = optim.Adam(ldinet.parameters(), lr=0.0005)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "losses = []\n",
        "ldinet.train()\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    for batch, _ in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        noisy_batch = batch + torch.randn_like(batch) * (25 / 255.0)\n",
        "        noisy_batch = torch.clamp(noisy_batch, 0, 1)\n",
        "\n",
        "        texture, structure = ldinet(noisy_batch)\n",
        "        recon = texture + structure\n",
        "        loss = criterion(recon, batch)\n",
        "        reg_loss = criterion(structure, batch)\n",
        "        total_loss = loss + 0.01 * reg_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += total_loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    losses.append(avg_loss)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Cell 11: Save the Trained Model\n",
        "torch.save(ldinet.state_dict(), 'enhanced_ldinet_100_epochs.pth')\n",
        "print(\"Model saved to 'enhanced_ldinet_100_epochs.pth'\")\n",
        "\n",
        "# Cell 12: Apply LDINet to Sample Noisy Image\n",
        "ldinet.eval()\n",
        "with torch.no_grad():\n",
        "    texture_tensor, structure_tensor = ldinet(noisy_tensor.unsqueeze(0))\n",
        "texture_np = texture_tensor.squeeze().cpu().numpy()\n",
        "structure_np = structure_tensor.squeeze().cpu().numpy()\n",
        "texture_np = (texture_np + 1) / 2  # Normalize Tanh output\n",
        "structure_np = np.clip(structure_np, 0, 1)\n",
        "texture_pil = Image.fromarray((texture_np * 255).astype(np.uint8))\n",
        "structure_pil = Image.fromarray((structure_np * 255).astype(np.uint8))\n",
        "\n",
        "# Cell 13: Visualize Decomposition and Training Loss\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(noisy_image, cmap='gray')\n",
        "plt.title('Noisy Image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(texture_pil, cmap='gray')\n",
        "plt.title('Texture Component')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(structure_pil, cmap='gray')\n",
        "plt.title('Structure Component')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.plot(range(1, num_epochs+1), losses, marker='o')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid()\n",
        "plt.savefig('decomposition_output.png')\n",
        "plt.show()\n",
        "\n",
        "# Cell 14: Define WLS Filter Function\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage import color, filters\n",
        "from scipy import sparse\n",
        "from scipy.sparse.linalg import spsolve\n",
        "\n",
        "def wls_filter(img_in, lambda_=1.0, alpha=1.2, L=None):\n",
        "    \"\"\"Edge-preserving smoothing using weighted least squares (WLS).\"\"\"\n",
        "    if L is None:\n",
        "        L = np.log(img_in + np.finfo(float).eps)\n",
        "\n",
        "    small_num = 0.0001\n",
        "    r, c = img_in.shape\n",
        "    k = r * c\n",
        "\n",
        "    dy = np.diff(L, axis=0)\n",
        "    dy = -lambda_ / (np.abs(dy) ** alpha + small_num)\n",
        "    dy = np.pad(dy, ((0, 1), (0, 0)), mode='constant')\n",
        "    dy = dy.flatten()\n",
        "\n",
        "    dx = np.diff(L, axis=1)\n",
        "    dx = -lambda_ / (np.abs(dx) ** alpha + small_num)\n",
        "    dx = np.pad(dx, ((0, 0), (0, 1)), mode='constant')\n",
        "    dx = dx.flatten()\n",
        "\n",
        "    B = np.vstack((dx, dy)).T\n",
        "    d = [-r, -1]\n",
        "    A = sparse.spdiags(B.T, d, k, k)\n",
        "\n",
        "    e = dx\n",
        "    w = np.pad(dx, (r, 0), mode='constant')[:-r]\n",
        "    s = dy\n",
        "    n = np.pad(dy, (1, 0), mode='constant')[:-1]\n",
        "\n",
        "    D = 1 - (e + w + s + n)\n",
        "    A = A + A.T + sparse.diags(D, 0, shape=(k, k))\n",
        "\n",
        "    img_out = spsolve(A, img_in.flatten())\n",
        "    return img_out.reshape(r, c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MAsQ3Z8hN_63",
        "outputId": "b469bc9f-2525-4803-c0b3-7141ee0b4b32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.5.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Collecting denoising-diffusion-pytorch\n",
            "  Downloading denoising_diffusion_pytorch-2.1.1-py3-none-any.whl.metadata (888 bytes)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from denoising-diffusion-pytorch) (1.6.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from denoising-diffusion-pytorch) (0.8.1)\n",
            "Collecting ema-pytorch>=0.4.2 (from denoising-diffusion-pytorch)\n",
            "  Downloading ema_pytorch-0.7.7-py3-none-any.whl.metadata (689 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from denoising-diffusion-pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from denoising-diffusion-pytorch) (11.2.1)\n",
            "Collecting pytorch-fid (from denoising-diffusion-pytorch)\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from denoising-diffusion-pytorch) (1.15.3)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from denoising-diffusion-pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from denoising-diffusion-pytorch) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from denoising-diffusion-pytorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->denoising-diffusion-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->denoising-diffusion-pytorch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->denoising-diffusion-pytorch) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->denoising-diffusion-pytorch) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate->denoising-diffusion-pytorch) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->denoising-diffusion-pytorch) (0.31.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate->denoising-diffusion-pytorch) (0.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate->denoising-diffusion-pytorch) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->denoising-diffusion-pytorch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising-diffusion-pytorch) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising-diffusion-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising-diffusion-pytorch) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising-diffusion-pytorch) (2025.4.26)\n",
            "Downloading denoising_diffusion_pytorch-2.1.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ema_pytorch-0.7.7-py3-none-any.whl (9.8 kB)\n",
            "Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: ema-pytorch, pytorch-fid, denoising-diffusion-pytorch\n",
            "Successfully installed denoising-diffusion-pytorch-2.1.1 ema-pytorch-0.7.7 pytorch-fid-0.3.0\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ContextualVersionConflict",
          "evalue": "(nvidia-nvjitlink-cu12 12.5.82 (/usr/local/lib/python3.11/dist-packages), Requirement.parse('nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\"'), {'torch'})",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mContextualVersionConflict\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f33ea9196b75>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'torch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'torchvision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opencv-python-headless'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pandas'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seaborn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'denoising-diffusion-pytorch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mversions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mdf_versions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Package'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-f33ea9196b75>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'torch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'torchvision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opencv-python-headless'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pandas'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seaborn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'denoising-diffusion-pytorch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mversions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mdf_versions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Package'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_distribution\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_provider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected str, Requirement, or Distribution\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;34m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mworking_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mrequire\u001b[0;34m(self, *requirements)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mincluded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meven\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mwere\u001b[0m \u001b[0malready\u001b[0m \u001b[0mactivated\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mworking\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \"\"\"\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0mneeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneeded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             dist = self._resolve_dist(\n\u001b[0m\u001b[1;32m    898\u001b[0m                 \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_conflicting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstaller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequired_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_activate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_resolve_dist\u001b[0;34m(self, req, best, replace_conflicting, env, installer, required_by, to_activate)\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;31m# Oops, the \"best\" so far conflicts with a dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mdependent_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequired_by\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mVersionConflict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdependent_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mContextualVersionConflict\u001b[0m: (nvidia-nvjitlink-cu12 12.5.82 (/usr/local/lib/python3.11/dist-packages), Requirement.parse('nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\"'), {'torch'})"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 15: Define Weight Calculation Functions\n",
        "def weight_saturation(imgs):\n",
        "    \"\"\"Compute saturation weight as standard deviation of color channels.\"\"\"\n",
        "    N = imgs.shape[3]\n",
        "    C = np.zeros((imgs.shape[0], imgs.shape[1], N))\n",
        "    for i in range(N):\n",
        "        R = imgs[:, :, 0, i]\n",
        "        G = imgs[:, :, 1, i]\n",
        "        B = imgs[:, :, 2, i]\n",
        "        mu = (R + G + B) / 3\n",
        "        C[:, :, i] = np.sqrt(((R - mu) ** 2 + (G - mu) ** 2 + (B - mu) ** 2) / 3)\n",
        "    return C\n",
        "\n",
        "def weight_saliency(imgs):\n",
        "    \"\"\"Compute saliency weight based on Lab color space.\"\"\"\n",
        "    N = imgs.shape[3]\n",
        "    C = np.zeros((imgs.shape[0], imgs.shape[1], N))\n",
        "    for i in range(N):\n",
        "        img = imgs[:, :, :, i]\n",
        "        gfrgb = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "        lab = color.rgb2lab(gfrgb)\n",
        "        l = lab[:, :, 0]\n",
        "        a = lab[:, :, 1]\n",
        "        b = lab[:, :, 2]\n",
        "        lm, am, bm = np.mean(l), np.mean(a), np.mean(b)\n",
        "        sm = (l - lm) ** 2 + (a - am) ** 2 + (b - bm) ** 2\n",
        "        C[:, :, i] = sm\n",
        "    return C\n",
        "\n",
        "def weight_contrast(imgs):\n",
        "    \"\"\"Compute contrast weight using Laplacian filter.\"\"\"\n",
        "    N = imgs.shape[3]\n",
        "    C = np.zeros((imgs.shape[0], imgs.shape[1], N))\n",
        "    for i in range(N):\n",
        "        mono = color.rgb2gray(imgs[:, :, :, i])\n",
        "        C[:, :, i] = np.abs(filters.laplace(mono))\n",
        "    return C\n",
        "\n",
        "def weight_luminance(imgs):\n",
        "    \"\"\"Compute luminance weight to prioritize well-exposed regions.\"\"\"\n",
        "    N = imgs.shape[3]\n",
        "    C = np.zeros((imgs.shape[0], imgs.shape[1], N))\n",
        "    for i in range(N):\n",
        "        lum = color.rgb2gray(imgs[:, :, :, i])\n",
        "        # Well-exposed regions are close to 0.5 (mid-gray)\n",
        "        C[:, :, i] = np.exp(-((lum - 0.5) ** 2) / (2 * 0.2 ** 2))\n",
        "    return C\n",
        "\n",
        "# Cell 16: Define Utility Functions for Fusion\n",
        "def rgb2lum(imgs):\n",
        "    \"\"\"Convert RGB image sequence to luminance (Y channel in YCbCr).\"\"\"\n",
        "    H, W, C, N = imgs.shape\n",
        "    if C != 3:\n",
        "        raise ValueError(\"Image sequence must be 3-channel\")\n",
        "    img_seq_lum = np.zeros((H, W, N))\n",
        "    for n in range(N):\n",
        "        ycbcr = color.rgb2ycbcr(imgs[:, :, :, n])\n",
        "        img_seq_lum[:, :, n] = ycbcr[:, :, 0]\n",
        "    return img_seq_lum\n",
        "\n",
        "def refine_weight(weight_in):\n",
        "    \"\"\"Refine weights using Gaussian filter.\"\"\"\n",
        "    H, W, N = weight_in.shape\n",
        "    weight_out = np.zeros((H, W, N))\n",
        "    for n in range(N):\n",
        "        weight_out[:, :, n] = cv2.GaussianBlur(weight_in[:, :, n], (0, 0), sigmaX=5)\n",
        "    return weight_out\n",
        "\n",
        "def normalize_weights(W):\n",
        "    \"\"\"Normalize weights to sum to 1 and ensure [0,1] range.\"\"\"\n",
        "    N = W.shape[2]\n",
        "    Wn = W + 1e-12\n",
        "    Wn = Wn / np.sum(Wn, axis=2, keepdims=True)\n",
        "    return Wn\n",
        "\n",
        "def generate_exosured_imgs(img):\n",
        "    \"\"\"Generate simulated exposure variations using gamma correction.\"\"\"\n",
        "    imgs = np.zeros((img.shape[0], img.shape[1], img.shape[2], 3))\n",
        "    # Normal exposure (gamma=1.0)\n",
        "    imgs[:, :, :, 0] = img\n",
        "    # Underexposed (gamma=2.0, darker)\n",
        "    imgs[:, :, :, 1] = np.clip(img ** 2.0, 0, 1)\n",
        "    # Overexposed (gamma=0.5, brighter)\n",
        "    imgs[:, :, :, 2] = np.clip(img ** 0.5, 0, 1)\n",
        "    return imgs\n",
        "\n",
        "# Cell 17: Define Pyramid Functions for Multi-scale Fusion\n",
        "def gaussian_pyramid(img, levels):\n",
        "    \"\"\"Construct Gaussian pyramid using cv2.pyrDown.\"\"\"\n",
        "    pyramid = [img]\n",
        "    current = img\n",
        "    for _ in range(levels - 1):\n",
        "        h, w = current.shape[:2]\n",
        "        if h < 2 or w < 2:\n",
        "            break\n",
        "        current = cv2.pyrDown(current)\n",
        "        if len(current.shape) == 3 and current.shape[2] == 1:\n",
        "            current = current.squeeze(-1)\n",
        "        pyramid.append(current)\n",
        "    return pyramid\n",
        "\n",
        "def laplacian_pyramid(img, levels):\n",
        "    \"\"\"Construct Laplacian pyramid, ensuring dimension alignment.\"\"\"\n",
        "    g_pyr = gaussian_pyramid(img, levels)\n",
        "    l_pyr = []\n",
        "    for i in range(len(g_pyr) - 1):\n",
        "        target_h, target_w = g_pyr[i].shape[:2]\n",
        "        up = cv2.pyrUp(g_pyr[i + 1])\n",
        "        up = cv2.resize(up, (target_w, target_h), interpolation=cv2.INTER_LINEAR)\n",
        "        if up.shape != g_pyr[i].shape:\n",
        "            raise ValueError(f\"Shape mismatch at level {i}: g_pyr[{i}]={g_pyr[i].shape}, up={up.shape}\")\n",
        "        lap = g_pyr[i] - up\n",
        "        l_pyr.append(lap)\n",
        "    l_pyr.append(g_pyr[-1])\n",
        "    return l_pyr\n",
        "\n",
        "def reconstruct_laplacian_pyramid(pyr):\n",
        "    \"\"\"Reconstruct image from Laplacian pyramid.\"\"\"\n",
        "    img = pyr[-1]\n",
        "    for i in range(len(pyr) - 2, -1, -1):\n",
        "        target_w, target_h = pyr[i].shape[1], pyr[i].shape[0]\n",
        "        img = cv2.pyrUp(img)\n",
        "        img = cv2.resize(img, (target_w, target_h), interpolation=cv2.INTER_LINEAR)\n",
        "        if img.shape != pyr[i].shape:\n",
        "            raise ValueError(f\"Shape mismatch at level {i}: pyr[{i}]={pyr[i].shape}, img={img.shape}\")\n",
        "        img = img + pyr[i]\n",
        "    return img\n",
        "\n",
        "def fusion_pyramid(imgs, weights, lev):\n",
        "    \"\"\"Fuse images using pyramid decomposition.\"\"\"\n",
        "    H, W, C, N = imgs.shape\n",
        "    weights = weights + 1e-12\n",
        "    weights = weights / np.sum(weights, axis=2, keepdims=True)\n",
        "\n",
        "    pyr = []\n",
        "    for i in range(lev):\n",
        "        h = max(1, H // (2 ** i))\n",
        "        w = max(1, W // (2 ** i))\n",
        "        pyr.append(np.zeros((h, w, C)))\n",
        "\n",
        "    for n in range(N):\n",
        "        pyrW = gaussian_pyramid(weights[:, :, n], lev)\n",
        "        pyrI = laplacian_pyramid(imgs[:, :, :, n], lev)\n",
        "        for l in range(min(len(pyr), len(pyrW), len(pyrI))):\n",
        "            target_h, target_w = pyr[l].shape[:2]\n",
        "            w = cv2.resize(pyrW[l], (target_w, target_h), interpolation=cv2.INTER_LINEAR)\n",
        "            if len(w.shape) == 1:\n",
        "                w = w.reshape((target_h, target_w))\n",
        "            elif len(w.shape) == 3 and w.shape[-1] == 1:\n",
        "                w = w.squeeze(-1)\n",
        "            w = np.repeat(w[:, :, np.newaxis], C, axis=2)\n",
        "            if w.shape != pyrI[l].shape:\n",
        "                pyrI_l = cv2.resize(pyrI[l], (target_w, target_h), interpolation=cv2.INTER_LINEAR)\n",
        "            else:\n",
        "                pyrI_l = pyrI[l]\n",
        "            pyr[l] = pyr[l] + w * pyrI_l\n",
        "\n",
        "    result = reconstruct_laplacian_pyramid(pyr)\n",
        "    return np.clip(result, 0, 1)\n",
        "\n",
        "# Cell 18: Define Denoising Function\n",
        "def denoise_image(fused_img):\n",
        "    \"\"\"Denoise the fused image using bilateral filter.\"\"\"\n",
        "    # Convert to uint8 for OpenCV (scale from [0,1] to [0,255])\n",
        "    img_uint8 = (fused_img * 255).astype(np.uint8)\n",
        "    # Apply bilateral filter (preserves edges while smoothing)\n",
        "    denoised = cv2.bilateralFilter(img_uint8, d=9, sigmaColor=75, sigmaSpace=75)\n",
        "    # Convert back to float [0,1]\n",
        "    denoised = denoised.astype(np.float32) / 255.0\n",
        "    return np.clip(denoised, 0, 1)\n",
        "\n",
        "# Cell 19: Process Images with LDINet Decomposition and Fusion\n",
        "def process_with_ldinet(image_path):\n",
        "    \"\"\"Process an image using LDINet decomposition and fusion technique.\"\"\"\n",
        "    # Load and convert image\n",
        "    original = cv2.imread(image_path)\n",
        "    if original is None:\n",
        "        print(f\"Error: Could not load image {image_path}\")\n",
        "        return None, None, None\n",
        "\n",
        "    original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB) / 255.0\n",
        "\n",
        "    # Resize for processing if needed\n",
        "    if max(original.shape[:2]) > 800:\n",
        "        scale = 800 / max(original.shape[:2])\n",
        "        new_size = (int(original.shape[1] * scale), int(original.shape[0] * scale))\n",
        "        original = cv2.resize(original, new_size)\n",
        "\n",
        "    # Add noise for testing\n",
        "    noisy = original + np.random.normal(0, 0.05, original.shape)\n",
        "    noisy = np.clip(noisy, 0, 1)\n",
        "\n",
        "    # Convert to grayscale for LDINet\n",
        "    gray_noisy = cv2.cvtColor(noisy, cv2.COLOR_RGB2GRAY)\n",
        "    gray_noisy_tensor = torch.from_numpy(gray_noisy).float().unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    # Apply LDINet for decomposition\n",
        "    with torch.no_grad():\n",
        "        texture, structure = ldinet(gray_noisy_tensor)\n",
        "\n",
        "    texture_np = texture.squeeze().cpu().numpy()\n",
        "    structure_np = structure.squeeze().cpu().numpy()\n",
        "\n",
        "    # Normalize texture from Tanh output range\n",
        "    texture_np = (texture_np + 1) / 2\n",
        "    texture_np = np.clip(texture_np, 0, 1)\n",
        "\n",
        "    # Create multi-exposure versions using the decomposition\n",
        "    imgs_rgb = generate_exosured_imgs(noisy)\n",
        "\n",
        "    # Calculate weights\n",
        "    w1 = weight_saliency(imgs_rgb)\n",
        "    w1 = normalize_weights(w1)\n",
        "    w1 = refine_weight(w1)\n",
        "\n",
        "    w2 = weight_contrast(imgs_rgb)\n",
        "    w2 = normalize_weights(w2)\n",
        "    w2 = refine_weight(w2)\n",
        "\n",
        "    w3 = weight_saturation(imgs_rgb)\n",
        "    w3 = normalize_weights(w3)\n",
        "    w3 = refine_weight(w3)\n",
        "\n",
        "    w4 = weight_luminance(imgs_rgb)\n",
        "    w4 = normalize_weights(w4)\n",
        "    w4 = refine_weight(w4)\n",
        "\n",
        "    # Combine weights (emphasize structure from LDINet)\n",
        "    w = w1 * w2 * w3 * w4 * 2  # Increase weight for structure\n",
        "\n",
        "    # Fuse images\n",
        "    fused = fusion_pyramid(imgs_rgb, w, 5)\n",
        "\n",
        "    # Apply denoising\n",
        "    denoised = denoise_image(fused)\n",
        "\n",
        "    return noisy, fused, denoised\n",
        "\n",
        "# Cell 20: Main Function to Test on Sample Images\n",
        "def main():\n",
        "    \"\"\"Process images from the BSR dataset, apply LDINet and fusion-based denoising.\"\"\"\n",
        "    plt.figure(figsize=(15, 12))\n",
        "\n",
        "    # Get some sample images from the dataset\n",
        "    sample_images = sorted(glob.glob(os.path.join(bsr_train_path, '*.jpg')))[:4]\n",
        "\n",
        "    for i, img_path in enumerate(sample_images):\n",
        "        noisy, fused, denoised = process_with_ldinet(img_path)\n",
        "\n",
        "        if noisy is None:\n",
        "            continue\n",
        "\n",
        "        plt.subplot(4, 3, i*3 + 1)\n",
        "        plt.imshow(noisy)\n",
        "        plt.title(f'Noisy Image {i+1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(4, 3, i*3 + 2)\n",
        "        plt.imshow(fused)\n",
        "        plt.title(f'Fused Image {i+1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(4, 3, i*3 + 3)\n",
        "        plt.imshow(denoised)\n",
        "        plt.title(f'Denoised Image {i+1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results_comparison.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate and display metrics for the last processed image\n",
        "    if noisy is not None:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "iCqQqYGSNzlP",
        "outputId": "af2ffea2-4a21-4d4d-ba85-3d867c550c8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-1-4094b1021c77>, line 566)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4094b1021c77>\"\u001b[0;36m, line \u001b[0;32m566\u001b[0m\n\u001b[0;31m    if noisy is not None:\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BKkU5tjIN0XO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}