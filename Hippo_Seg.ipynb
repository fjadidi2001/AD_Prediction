{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwi/NRlp2FFPqMemhW2F4E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/Hippo_Seg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries\n"
      ],
      "metadata": {
        "id": "tsVSgzEDyrXx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eMLXEIKKkYJk"
      },
      "outputs": [],
      "source": [
        "# Purpose: Import necessary libraries for data processing, model building, and visualization.\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras import backend as K\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "seed = 2019\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive Setup\n"
      ],
      "metadata": {
        "id": "rGN3IDO0zD-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Purpose: Mount Google Drive, set paths for dataset and models, and copy dataset if not already present.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDoOUfVCziGX",
        "outputId": "6ab7324f-c9a3-4a62-8def-723aa11aba55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Drive paths\n",
        "drive_dataset_path = '/content/drive/MyDrive/Hippocampus_Dataset'\n",
        "drive_model_path = '/content/drive/MyDrive/Hippocampus_Models'\n",
        "local_dataset_path = '/content/hippocampus_dataset'"
      ],
      "metadata": {
        "id": "BxdxYst26NQG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directories if they don't exist\n",
        "os.makedirs(drive_dataset_path, exist_ok=True)\n",
        "os.makedirs(drive_model_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "hGapwYXk6UK-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if dataset exists in Drive\n",
        "if not os.path.exists(os.path.join(drive_dataset_path, 'aug')):\n",
        "    print(\"Copying dataset to Google Drive...\")\n",
        "    shutil.copy('/content/hippocampus segmentation dataset.zip', drive_dataset_path)\n",
        "    !unzip -q \"{os.path.join(drive_dataset_path, 'hippocampus segmentation dataset.zip')}\" -d \"{local_dataset_path}\"\n",
        "    shutil.copytree(local_dataset_path, os.path.join(drive_dataset_path, 'hippocampus_dataset'))\n",
        "else:\n",
        "    print(\"Loading dataset from Google Drive...\")\n",
        "    shutil.copytree(os.path.join(drive_dataset_path, 'hippocampus_dataset'), local_dataset_path)\n",
        "\n",
        "# Debug: Check dataset contents\n",
        "print(\"Dataset contents:\")\n",
        "!ls {local_dataset_path}\n",
        "print(\"Images folder:\")\n",
        "!ls {os.path.join(local_dataset_path, 'aug/images')}\n",
        "print(\"Left masks folder:\")\n",
        "!ls {os.path.join(local_dataset_path, 'aug/masks/left')}\n",
        "print(\"Right masks folder:\")\n",
        "!ls {os.path.join(local_dataset_path, 'aug/masks/right')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ERfyMrG-yyic",
        "outputId": "08ee4072-6dac-4c9e-f291-e73a8a492781"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying dataset to Google Drive...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/hippocampus segmentation dataset.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e291d4106e53>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aug'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Copying dataset to Google Drive...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/hippocampus segmentation dataset.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrive_dataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip -q \"{os.path.join(drive_dataset_path, \\'hippocampus segmentation dataset.zip\\')}\" -d \"{local_dataset_path}\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hippocampus_dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/hippocampus segmentation dataset.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing\n"
      ],
      "metadata": {
        "id": "09C32gQO8SJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Purpose: Load images and masks, match files, preprocess data, and prepare X_train, Y_train.\n",
        "# Constants\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "# Define dataset paths\n",
        "data = os.path.join(local_dataset_path, 'aug/images')\n",
        "data_left = os.path.join(local_dataset_path, 'aug/masks/left')\n",
        "data_right = os.path.join(local_dataset_path, 'aug/masks/right')\n",
        "\n",
        "# Load file paths\n",
        "train_data = [os.path.join(dirName, f) for dirName, _, fileList in sorted(os.walk(data)) for f in fileList if '.jpg' in f.lower()]\n",
        "mask_left = [os.path.join(dirName, f) for dirName, _, fileList in sorted(os.walk(data_left)) for f in fileList if '.jpg' in f.lower()]\n",
        "mask_right = [os.path.join(dirName, f) for dirName, _, fileList in sorted(os.walk(data_right)) for f in fileList if '.jpg' in f.lower()]\n",
        "print(f\"Found {len(train_data)} image files, {len(mask_left)} left mask files, {len(mask_right)} right mask files.\")\n",
        "\n",
        "# Match files\n",
        "def extract_id(filename, prefix):\n",
        "    base = os.path.splitext(os.path.basename(filename))[0]\n",
        "    return base.replace(prefix, '')\n",
        "\n",
        "image_ids = [extract_id(f, 'img_') for f in train_data]\n",
        "left_mask_ids = [extract_id(f, 'maskleft_') for f in mask_left]\n",
        "right_mask_ids = [extract_id(f, 'maskright_') for f in mask_right]\n",
        "print(\"Image IDs:\", image_ids)\n",
        "print(\"Left mask IDs:\", left_mask_ids)\n",
        "print(\"Right mask IDs:\", right_mask_ids)\n",
        "\n",
        "common_ids = sorted(list(set(image_ids) & set(left_mask_ids) & set(right_mask_ids)))\n",
        "print(f\"Found {len(common_ids)} complete image-mask pairs.\")\n",
        "\n",
        "train_data = [f for f in train_data if extract_id(f, 'img_') in common_ids]\n",
        "mask_left = [f for f in mask_left if extract_id(f, 'maskleft_') in common_ids]\n",
        "mask_right = [f for f in mask_right if extract_id(f, 'maskright_') in common_ids]\n",
        "\n",
        "train_data.sort(key=lambda x: extract_id(x, 'img_'))\n",
        "mask_left.sort(key=lambda x: extract_id(x, 'maskleft_'))\n",
        "mask_right.sort(key=lambda x: extract_id(x, 'maskright_'))\n",
        "\n",
        "# Verify alignment\n",
        "for img, ml, mr in zip(train_data, mask_left, mask_right):\n",
        "    img_id = extract_id(img, 'img_')\n",
        "    ml_id = extract_id(ml, 'maskleft_')\n",
        "    mr_id = extract_id(mr, 'maskright_')\n",
        "    if img_id != ml_id or img_id != mr_id:\n",
        "        print(f\"Warning: Mismatch - Image: {img_id}, Left: {ml_id}, Right: {mr_id}\")\n",
        "\n",
        "if not train_data or not mask_left or not mask_right:\n",
        "    raise ValueError(\"No images or masks found after matching.\")\n",
        "\n",
        "# Initialize arrays\n",
        "X_train = np.zeros((len(train_data), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
        "Y_train = np.zeros((len(train_data), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
        "\n",
        "# Load and preprocess\n",
        "for i in tqdm(range(len(train_data)), desc=\"Loading images\"):\n",
        "    img = imread(train_data[i])\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), mode='constant', preserve_range=True)\n",
        "    img = img / 255.0\n",
        "    X_train[i] = img\n",
        "\n",
        "for i in tqdm(range(len(train_data)), desc=\"Loading masks\"):\n",
        "    maskl = imread(mask_left[i], as_gray=True)\n",
        "    maskr = imread(mask_right[i], as_gray=True)\n",
        "    mask = np.maximum(maskl, maskr)\n",
        "    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH, 1), mode='constant', preserve_range=True)\n",
        "    mask = (mask > 0.5).astype(np.float32)\n",
        "    Y_train[i] = mask\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n",
        "\n",
        "# Visualize sample\n",
        "if X_train.shape[0] > 0:\n",
        "    id = random.randint(0, X_train.shape[0] - 1)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    imshow(X_train[id])\n",
        "    plt.title(f\"Sample Image (ID: {extract_id(train_data[id], 'img_')})\")\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    imshow(Y_train[id][:, :, 0], cmap='gray')\n",
        "    plt.title(\"Sample Mask\")\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "83ZAbKlSzL9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Functions\n"
      ],
      "metadata": {
        "id": "rUkDIagtB5fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Purpose: Define montage function and metrics for evaluation.\n",
        "def custom_montage(images, n_rows=5, n_cols=5, cmap='gray'):\n",
        "    if images.shape[0] == 0:\n",
        "        print(\"No images to display in montage.\")\n",
        "        return None\n",
        "    n_images = min(images.shape[0], n_rows * n_cols)\n",
        "    images = images[:n_images]\n",
        "    if images.ndim == 4:\n",
        "        images = images[..., 0]\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    fig, ax = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2, n_rows * 2))\n",
        "    ax = ax.ravel()\n",
        "    for i in range(n_images):\n",
        "        ax[i].imshow(images[i], cmap=cmap)\n",
        "        ax[i].axis('off')\n",
        "    for i in range(n_images, len(ax)):\n",
        "        ax[i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "smooth = 1.\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "def compute_metrics(y_true, y_pred, threshold=0.5):\n",
        "    y_pred_bin = (y_pred > threshold).astype(np.float32)\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred_bin.flatten()\n",
        "    intersection = np.sum(y_true_f * y_pred_f)\n",
        "    dice = (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
        "    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection\n",
        "    iou_score = (intersection + smooth) / (union + smooth)\n",
        "    true_pos = intersection\n",
        "    false_pos = np.sum(y_pred_f) - intersection\n",
        "    false_neg = np.sum(y_true_f) - intersection\n",
        "    precision = true_pos / (true_pos + false_pos + smooth)\n",
        "    recall = true_pos / (true_pos + false_neg + smooth)\n",
        "    return dice, iou_score, precision, recall"
      ],
      "metadata": {
        "id": "kXrY8blVBuUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResUNet Model\n"
      ],
      "metadata": {
        "id": "ZiZ39yG-CWtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Purpose: Define and compile the ResUNet model for segmentation.\n",
        "def bn_act(x, act=True):\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    if act:\n",
        "        x = keras.layers.Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = bn_act(x)\n",
        "    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
        "    return conv\n",
        "\n",
        "def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    shortcut = keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    output = keras.layers.Add()([conv, shortcut])\n",
        "    return output\n",
        "\n",
        "def residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
        "    shortcut = keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    output = keras.layers.Add()([shortcut, res])\n",
        "    return output\n",
        "\n",
        "def upsample_concat_block(x, xskip):\n",
        "    u = keras.layers.UpSampling2D((2, 2))(x)\n",
        "    c = keras.layers.Concatenate()([u, xskip])\n",
        "    return c\n",
        "\n",
        "def ResUNet():\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "\n",
        "    # Encoder\n",
        "    e0 = inputs\n",
        "    e1 = stem(e0, f[0])\n",
        "    e2 = residual_block(e1, f[1], strides=2)\n",
        "    e3 = residual_block(e2, f[2], strides=2)\n",
        "    e4 = residual_block(e3, f[3], strides=2)\n",
        "    e5 = residual_block(e4, f[4], strides=2)\n",
        "\n",
        "    # Bridge\n",
        "    b0 = conv_block(e5, f[4], strides=1)\n",
        "    b1 = conv_block(b0, f[4], strides=1)\n",
        "\n",
        "    # Decoder\n",
        "    u1 = upsample_concat_block(b1, e4)\n",
        "    d1 = residual_block(u1, f[4])\n",
        "    u2 = upsample_concat_block(d1, e3)\n",
        "    d2 = residual_block(u2, f[3])\n",
        "    u3 = upsample_concat_block(d2, e2)\n",
        "    d3 = residual_block(u3, f[2])\n",
        "    u4 = upsample_concat_block(d3, e1)\n",
        "    d4 = residual_block(u4, f[1])\n",
        "\n",
        "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "    model = keras.models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "resunet_model = ResUNet()\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "resunet_model.compile(optimizer=optimizer, loss=dice_coef_loss, metrics=[dice_coef, iou])\n",
        "resunet_model.summary()"
      ],
      "metadata": {
        "id": "RBiaGuRVCOTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diffusion Model\n"
      ],
      "metadata": {
        "id": "z_dFXODJDKzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Diffusion Model\n",
        "# Purpose: Implement a simplified diffusion model for hippocampus segmentation, inspired by Stable Diffusion.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class DiffusionModel(keras.Model):\n",
        "    def __init__(self, timesteps=100, img_size=(128, 128)):\n",
        "        super(DiffusionModel, self).__init__()\n",
        "        self.timesteps = timesteps\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # U-Net for noise prediction\n",
        "        self.unet = self.build_unet()\n",
        "\n",
        "        # Beta schedule\n",
        "        self.betas = tf.linspace(1e-4, 0.02, timesteps)\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alpha_bars = tf.math.cumprod(self.alphas)\n",
        "\n",
        "    def build_unet(self):\n",
        "        # Inputs\n",
        "        mask_input = layers.Input(shape=(*self.img_size, 1))  # Noisy mask: (None, 128, 128, 1)\n",
        "        image_input = layers.Input(shape=(*self.img_size, 3))  # MRI image: (None, 128, 128, 3)\n",
        "        time_input = layers.Input(shape=(1,))  # Timestep: (None, 1)\n",
        "\n",
        "        # Time embedding\n",
        "        t_emb = layers.Dense(128, activation='relu')(time_input)  # (None, 128)\n",
        "        t_emb = layers.Dense(256, activation='relu')(t_emb)  # (None, 256)\n",
        "        t_emb = layers.Reshape((1, 1, 256))(t_emb)  # (None, 1, 1, 256)\n",
        "        t_emb = layers.UpSampling2D(size=(128, 128))(t_emb)  # (None, 128, 128, 256)\n",
        "\n",
        "        # Image preprocessing\n",
        "        img = layers.Conv2D(64, 3, padding='same', activation='relu')(image_input)  # (None, 128, 128, 64)\n",
        "\n",
        "        # Encoder\n",
        "        x = layers.Concatenate()([mask_input, img])  # (None, 128, 128, 65)\n",
        "        x1 = layers.Conv2D(64, 3, padding='same', activation='relu')(x)  # (None, 128, 128, 64)\n",
        "        x = layers.MaxPooling2D()(x1)  # (None, 64, 64, 64)\n",
        "        x2 = layers.Conv2D(128, 3, padding='same', activation='relu')(x)  # (None, 64, 64, 128)\n",
        "        x = layers.MaxPooling2D()(x2)  # (None, 32, 32, 128)\n",
        "        x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)  # (None, 32, 32, 256)\n",
        "\n",
        "        # Middle\n",
        "        x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)  # (None, 32, 32, 256)\n",
        "        x = layers.Add()([x, layers.Conv2D(256, 1, padding='same')(t_emb[:, :32, :32, :])])  # (None, 32, 32, 256)\n",
        "\n",
        "        # Decoder\n",
        "        x = layers.UpSampling2D()(x)  # (None, 64, 64, 256)\n",
        "        x = layers.Concatenate()([x, x2])  # (None, 64, 64, 384)\n",
        "        x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)  # (None, 64, 64, 128)\n",
        "        x = layers.UpSampling2D()(x)  # (None, 128, 128, 128)\n",
        "        x = layers.Concatenate()([x, x1])  # (None, 128, 128, 192)\n",
        "        x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)  # (None, 128, 128, 64)\n",
        "\n",
        "        # Output: predicted noise\n",
        "        outputs = layers.Conv2D(1, 3, padding='same', activation='linear')(x)  # (None, 128, 128, 1)\n",
        "        return keras.models.Model([mask_input, image_input, time_input], outputs)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        mask, image, t = inputs\n",
        "        return self.unet([mask, image, t], training=training)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data  # x: images (None, 128, 128, 3), y: masks (None, 128, 128, 1)\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        t = tf.random.uniform([batch_size], 0, self.timesteps, dtype=tf.int32)\n",
        "\n",
        "        # Add noise\n",
        "        sqrt_alpha_bar = tf.sqrt(tf.gather(self.alpha_bars, t))[:, None, None, None]\n",
        "        sqrt_one_minus_alpha_bar = tf.sqrt(1.0 - tf.gather(self.alpha_bars, t))[:, None, None, None]\n",
        "        noise = tf.random.normal(tf.shape(y))\n",
        "        y_noisy = sqrt_alpha_bar * y + sqrt_one_minus_alpha_bar * noise\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predicted_noise = self([y_noisy, x, tf.cast(t, tf.float32) / self.timesteps], training=True)\n",
        "            loss = tf.reduce_mean(tf.square(noise - predicted_noise))\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        return {'loss': loss}\n",
        "\n",
        "    def generate(self, images, steps=50):\n",
        "        x_t = tf.random.normal([images.shape[0], *self.img_size, 1])\n",
        "        for t in range(steps - 1, -1, -1):\n",
        "            t_tensor = tf.ones([images.shape[0]], dtype=tf.float32) * t\n",
        "            predicted_noise = self([x_t, images, t_tensor / self.timesteps], training=False)\n",
        "            alpha = tf.gather(self.alphas, t)\n",
        "            alpha_bar = tf.gather(self.alpha_bars, t)\n",
        "            x_t = (x_t - ((1 - alpha) / tf.sqrt(1 - alpha_bar)) * predicted_noise) / tf.sqrt(alpha)\n",
        "        return tf.clip_by_value(x_t, 0, 1)\n",
        "\n",
        "# Instantiate and compile\n",
        "diffusion_model = DiffusionModel(timesteps=100)\n",
        "diffusion_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4))"
      ],
      "metadata": {
        "id": "OxQKUL6ycmpo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}