{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/AD%D9%80Ad1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2CrhuvPr1zD",
        "outputId": "72e46c97-53d2-4ca7-b43c-017b68552bc8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/db_al/Q1 Dataset.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55wRkH9doGE6",
        "outputId": "f2a0130e-e07c-403f-af14-28edae01d8a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/db_al/Q1 Dataset.zip, /content/drive/MyDrive/db_al/Q1 Dataset.zip.zip or /content/drive/MyDrive/db_al/Q1 Dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "D-VP96CgiLGQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "FcNURN7eWsrD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/Alzheimer_s_Disease_Neuroimaging_ADNI_Dataset'\n",
        "\n",
        "# Load data\n",
        "def load_data(data_dir):\n",
        "    images, labels = [], []\n",
        "    for label in os.listdir(data_dir):\n",
        "        label_dir = os.path.join(data_dir, label)\n",
        "        for image_file in os.listdir(label_dir):\n",
        "            image_path = os.path.join(label_dir, image_file)\n",
        "            image = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))\n",
        "            image = tf.image.resize(image, (64,64))\n",
        "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return images, labels\n",
        "\n",
        "images, labels = load_data(data_dir)\n",
        "labels = np.where(labels == 'AD', 1, 0)\n",
        "one_hot = np.zeros((labels.shape[0], 2))\n",
        "one_hot[np.arange(labels.shape[0]), labels] = 1\n",
        "labels = one_hot"
      ],
      "metadata": {
        "id": "C_QoEhvmiSBl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "54bd45be-bf26-4f76-af8d-fa22cd53fc8a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7898435c10af>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-7898435c10af>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mlabel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-validation-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.05, random_state=42, stratify=labels)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train)"
      ],
      "metadata": {
        "id": "CclVxwDkid0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display class distribution before augmentation\n",
        "sns.countplot(x=np.argmax(y_train, 1))\n",
        "plt.title('Class Distribution Before Augmentation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dFYPU7Sxdws9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n",
        "test_generator = test_datagen.flow(X_test, y_test, batch_size=1)\n",
        "\n",
        "# Display class distribution after augmentation\n",
        "augmented_images, _ = next(train_generator)\n",
        "\n",
        "augmented_labels = []\n",
        "for _ in range((len(y_train)*5 // batch_size)+1):\n",
        "    _, batch_labels = next(train_generator)\n",
        "    augmented_labels.extend(batch_labels)\n",
        "sns.countplot(x=np.argmax(augmented_labels,1))\n",
        "plt.title('Class Distribution After Augmentation')\n",
        "plt.show()\n",
        "\n",
        "# Display 5 random augmented images\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
        "for i in range(5):\n",
        "    random_index = np.random.randint(0, len(augmented_images))\n",
        "    ax = axes[i]\n",
        "    ax.imshow(augmented_images[random_index])\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dd4LqrL7d7-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Definition\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform()),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "testing_model_1 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "testing_model_2 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "jFqLdVGtiuLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = 'best_model.h5'\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_path,\n",
        "    save_best_only = True,\n",
        "    monitor = 'val_loss',\n",
        "    mode = 'min',\n",
        "    verbose = 1\n",
        ")"
      ],
      "metadata": {
        "id": "70Mlv8RbojAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Compilation\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model Training\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=500,\n",
        "                    validation_data=val_generator,\n",
        "                    callbacks=[checkpoint_callback])\n",
        "\n",
        "# Model Evaluation\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Test accuracy: {test_acc}\", f\"Test loss: {test_loss}\")\n",
        "\n",
        "# Save Model\n",
        "model.save('alzheimer_cnn_model.h5')"
      ],
      "metadata": {
        "id": "M7sm9wnwhpNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "    # Plot loss and accuracy history\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    # Plot loss\n",
        "    axs[0].plot(history.history['loss'], label='Train Loss')\n",
        "    axs[0].plot(history.history['val_loss'], label='Validation Loss')\n",
        "    axs[0].set_title('Loss')\n",
        "    axs[0].set_xlabel('Epochs')\n",
        "    axs[0].set_ylabel('Loss')\n",
        "    axs[0].legend()\n",
        "    # Plot accuracy\n",
        "    axs[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    axs[1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    axs[1].set_title('Accuracy')\n",
        "    axs[1].set_xlabel('Epochs')\n",
        "    axs[1].set_ylabel('Accuracy')\n",
        "    axs[1].legend()\n",
        "    plt.show()\n",
        "plot_history(history)\n"
      ],
      "metadata": {
        "id": "c1YD0_bTNtiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get true labels\n",
        "Y_true = []\n",
        "for _ in range(len(y_test)):\n",
        "    _, batch_labels = next(test_generator)\n",
        "    Y_true.extend(batch_labels)\n",
        "Y_true = np.argmax(Y_true, 1)"
      ],
      "metadata": {
        "id": "xbJpPUIXNNP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "test_generator.reset()\n",
        "Y_pred = model.predict(test_generator)\n",
        "Y_pred_classes = np.argmax(Y_pred, 1)\n",
        "\n",
        "# Plot ROCcurve\n",
        "fpr, tpr, _ = roc_curve(Y_true, Y_pred[:,1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9uQ7AnVoOgbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "conf_matrix = confusion_matrix(Y_true, Y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(2)\n",
        "plt.xticks(tick_marks, ['Class 0', 'Class 1'], rotation=45)\n",
        "plt.yticks(tick_marks, ['Class 0', 'Class 1'])\n",
        "thresh = conf_matrix.max() / 2.\n",
        "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
        "    plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
        "         horizontalalignment=\"center\",\n",
        "         color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bT9YYUa6fqSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(Y_true, Y_pred_classes)\n",
        "precision = precision_score(Y_true, Y_pred_classes)\n",
        "recall = recall_score(Y_true, Y_pred_classes)\n",
        "f1 = f1_score(Y_true, Y_pred_classes)\n",
        "print(f'Accuracy: {accuracy*100:.2f}')\n",
        "print(f'Precision: {precision*100:.2f}')\n",
        "print(f'Recall: {recall*100:.2f}')\n",
        "print(f'F1 Score: {f1:.3f}')\n",
        "print(f'AUC: {roc_auc:.3f}')\n",
        "print(f\"Loss: {test_loss:.3f}\")"
      ],
      "metadata": {
        "id": "09Dd--lkpd5-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}