{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/MRtoCT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wDMEndHw6FSu",
    "outputId": "fc858852-9347-47bd-ad0e-0ecb1ccd6c37"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cizhYdBE8QyZ"
   },
   "source": [
    "> The Falah/Alzheimer_MRI Disease Classification dataset is a valuable resource for researchers and health medicine applications. This dataset focuses on the classification of Alzheimer's disease based on MRI scans. The dataset consists of brain MRI images labeled into four categories:\n",
    "\n",
    "- '0': Mild_Demented\n",
    "- '1': Moderate_Demented\n",
    "- '2': Non_Demented\n",
    "- '3': Very_Mild_Demented\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423,
     "referenced_widgets": [
      "ab52ab785cf84736b557c6fa18968f20",
      "09b96bd9b01a4259a0aa3357303986cd",
      "3992485ff5294b34ac25c0264a523e4d",
      "b3d602d79b364954b3058768e33e4180",
      "00f024df9e60476b85404268435d2f99",
      "d2690c2e58d7468ea5f71dc6f914bdd4",
      "00bc2a5474b145c6b0ee4d58f7a32976",
      "ee34b195abd4484f879d3697a16116bc",
      "1a2af5ad2f564018832046d07f5bb3be",
      "adc61eb718ba44fd8e41561c37bdfa78",
      "b7a7fa01532b427dbf81ffbb90cd0ea2",
      "2f2817277d1f47a9ab50e0e5e26ffea7",
      "3aff9a687883420b85d3e85c7e8e7e9b",
      "42378d017b0c491b91264f94cb33ca2c",
      "d89cd8d5295d44719becc917b1eb9fe8",
      "d4b06aae0cc54ad3a8e32b3ab55d0410",
      "e87e9faa593a4c759c10486249be6d6b",
      "5ec0515dbc0444cd818eafcba3e77cda",
      "aac46f45d73048728041381dbbe3b8fb",
      "d15318cf4df04a2e852a1f6cdce36a99",
      "ba7a9f043aaa4537bf063074a61ec304",
      "127b58bc61f841d9adb7bd83afa3bee7",
      "c0abf96b2d744448b7f95f58773d094d",
      "94b2a8798a5b4077bf2f858ba7179a85",
      "afe6e8ed24a2406991d0109c4ee850b1",
      "257cf9c4ffaa4b719f4a793d4ddee26e",
      "52f2bb50ebaf469eabc1442935daa727",
      "1ce6ed35845a44acb9ea43eaf7a5582f",
      "4819ef8591e34977858c14a1f1c92801",
      "14eaa963c1834e8dacd85acb15a96e4a",
      "d280d087b7bd42b9827c448085f4da55",
      "4c524c9b33534c40b8d2a23a721e458c",
      "6ed28e301a8f4494b61abadbb472ba1f",
      "b5ad0357e16b4ff8a192cedcd6ab28b1",
      "eccdbea4f8944bb18999c6c74e737506",
      "50493df346054b5caefb7aa1b4932c9f",
      "d2f4159b830149df84f1f3d6cbfe8176",
      "df9645aa3174432b900ba67a914fe837",
      "bc177975558a41938b3a7bc3c8625351",
      "dba3ee72e8424e51a6ff394e055074f1",
      "c180f96e9d4e4e4fabe0efc003902436",
      "1d4cca25a1a143d19bff6bd22c459b62",
      "15279f14ac394cc2a023c3afef3589c4",
      "356893b5ecec40a3adc4cff92954a322",
      "85e2ecac1da640b69293d5ab6590ab1b",
      "05029f9cad6e4ef99d4e5f9cfef5297b",
      "28c190c3a58d46e285800e781224ea17",
      "91924b58cb1b49cc901296e70a77c7e4",
      "db0e59a78e264c39813f949e818bbb0e",
      "3882dc6a720c4b83a102ad5cd70cedb6",
      "7658dd3383a544a8bdccfe55ceb1d1ca",
      "0f2164817bb2473b8b5a3b4ab2450a41",
      "c0373b06126241848e44b7335c6b6a36",
      "15bb7d5c8d724630bbe5151d0ba1396e",
      "782ca16b5b7045919f2b23c80abf2606"
     ]
    },
    "id": "DG3WAtOb57oX",
    "outputId": "6ab01b5a-942a-45dc-db43-e755c80a6675"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Falah/Alzheimer_MRI dataset\n",
    "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
    "\n",
    "# Print the number of examples\n",
    "print(\"Number of examples:\", len(dataset))\n",
    "\n",
    "# Print the structure of the first example\n",
    "print(\"Structure of the first example:\")\n",
    "print(dataset[0])\n",
    "\n",
    "# Print the keys of the first example (if it's a dictionary)\n",
    "if isinstance(dataset[0], dict):\n",
    "    print(\"Keys in the first example:\", dataset[0].keys())\n",
    "\n",
    "# Print the first few samples\n",
    "print(\"Sample data:\")\n",
    "for example in dataset[:5]:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "zzLHbZoe7-dA",
    "outputId": "09b2ed8b-a6ac-4dbb-871b-2e7f344132ff"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the image is stored under the key 'image' in the dataset\n",
    "image = dataset[0]['image']\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide the axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "id": "MhuehP6pD7qN",
    "outputId": "cce7f751-aa0b-42ec-8f22-06ea4b894215"
   },
   "outputs": [],
   "source": [
    "# Display 25 images with their labels\n",
    "plt.figure(figsize=(15, 10))  # Set the figure size\n",
    "for i in range(25):\n",
    "    # Get the image and label\n",
    "    image = dataset[i]['image']\n",
    "    label = dataset[i]['label']\n",
    "\n",
    "    # Plot the image\n",
    "    plt.subplot(5, 5, i + 1)  # Arrange images in a grid (2 rows, 5 columns)\n",
    "    plt.imshow(image)  # Display the image\n",
    "    plt.title(f\"Label: {label}\")  # Set the title as the label\n",
    "    plt.axis('off')  # Hide the axes\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to avoid overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "X1F0g8toD_Pk",
    "outputId": "f954a138-432f-47f5-e642-f482920fc89e"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Load the Falah/Alzheimer_MRI dataset\n",
    "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
    "\n",
    "# Extract labels (assuming the key is 'label')\n",
    "labels = [int(example['label']) for example in dataset]  # Convert labels to integers\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "# Print the label distribution\n",
    "print(\"Label distribution:\", label_counts)\n",
    "\n",
    "# Set a better color palette\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(label_counts.keys()), y=list(label_counts.values()), palette=\"viridis\",hue=list(label_counts.keys()))\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Labels', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.title('Distribution of Labels in the Train Dataset before augmentation', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Add grid lines for better readability\n",
    "plt.grid(True, axis='y', linestyle='-', alpha=0.7)\n",
    "\n",
    "# Customize x-axis to show only integer labels\n",
    "plt.xticks(list(label_counts.keys()), fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "JcFMT_sXHMu9",
    "outputId": "eb655307-0eb4-4fdf-e42a-e74a46e20347"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Load the Falah/Alzheimer_MRI dataset\n",
    "dataset = load_dataset('Falah/Alzheimer_MRI', split='test')\n",
    "\n",
    "# Extract labels (assuming the key is 'label')\n",
    "labels = [int(example['label']) for example in dataset]  # Convert labels to integers\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "# Print the label distribution\n",
    "print(\"Label distribution:\", label_counts)\n",
    "\n",
    "# Set a better color palette\n",
    "sns.set_palette(\"pastel\")  # You can choose other palettes like \"deep\", \"muted\", \"bright\", etc.\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(label_counts.keys()), y=list(label_counts.values()), palette=\"viridis\",hue=list(label_counts.keys()))\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Labels', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.title('Distribution of Labels in the Test Dataset before augmentation', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Add grid lines for better readability\n",
    "plt.grid(True, axis='y', linestyle='-', alpha=0.7)\n",
    "\n",
    "# Customize x-axis to show only integer labels\n",
    "plt.xticks(list(label_counts.keys()), fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65Q32KeHIPHR"
   },
   "source": [
    "> Data augmentation is a powerful technique to increase the diversity of your training dataset by applying random transformations such as rotations, flips, zooms, and more. This helps improve the generalization of your model, especially when the dataset is small or imbalanced.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oalIYPPuNFxk",
    "outputId": "d7c759c2-09ea-4a5e-dc36-db70ee5680ca"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Falah/Alzheimer_MRI dataset\n",
    "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
    "\n",
    "# Define augmentation transformations\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,       # Randomly rotate by up to 15 degrees\n",
    "    width_shift_range=0.1,   # Randomly shift width by up to 10%\n",
    "    height_shift_range=0.1,  # Randomly shift height by up to 10%\n",
    "    horizontal_flip=True,    # Randomly flip horizontally\n",
    "    brightness_range=[0.8, 1.2],  # Randomly adjust brightness\n",
    "    zoom_range=0.2,          # Randomly zoom by up to 20%\n",
    ")\n",
    "\n",
    "# Function to apply augmentation to an image\n",
    "def augment_image(image):\n",
    "    # Convert PIL image to NumPy array if necessary\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        image = np.array(image)  # Convert PIL image to NumPy array\n",
    "\n",
    "    # Ensure the image has 3 channels (RGB)\n",
    "    if len(image.shape) == 2:  # If grayscale, convert to RGB\n",
    "        image = np.stack((image,) * 3, axis=-1)  # Shape: (height, width, 3)\n",
    "    elif len(image.shape) == 3 and image.shape[-1] == 4:  # If RGBA, convert to RGB\n",
    "        image = image[:, :, :3]  # Keep only the first 3 channels\n",
    "\n",
    "    # Print the shape of the image before augmentation\n",
    "    print(f\"Shape before augmentation: {image.shape}\")\n",
    "\n",
    "    # Add batch dimension: (1, height, width, channels)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Apply augmentation\n",
    "    augmented_image = next(datagen.flow(image, batch_size=1))[0]  # Use next() to get the augmented image\n",
    "\n",
    "    # Print the shape of the image after augmentation\n",
    "    print(f\"Shape after augmentation: {augmented_image.shape}\")\n",
    "\n",
    "    return augmented_image\n",
    "\n",
    "# Display original and augmented images with labels\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(5):  # Show 5 examples\n",
    "    # Original image\n",
    "    original_image = dataset[i]['image']  # Replace 'image' with the correct key\n",
    "    label = dataset[i]['label']  # Replace 'label' with the correct key\n",
    "\n",
    "    # Check the type of the image\n",
    "    print(f\"Image type: {type(original_image)}\")\n",
    "\n",
    "    # Display original image\n",
    "    plt.subplot(5, 2, 2 * i + 1)\n",
    "    plt.imshow(original_image)\n",
    "    plt.title(f\"Original {i+1} - Label: {label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Augmented image\n",
    "    augmented_image = augment_image(original_image)\n",
    "    plt.subplot(5, 2, 2 * i + 2)\n",
    "    plt.imshow(augmented_image.astype(np.uint8))  # Ensure the image is in the correct format for display\n",
    "    plt.title(f\"Augmented {i+1} - Label: {label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CGaYwnn9NoZX",
    "outputId": "fc919925-cc26-4ba3-db5c-ab54a19ea701"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageOps\n",
    "\n",
    "# Load the Falah/Alzheimer_MRI dataset\n",
    "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
    "\n",
    "# Define augmentation transformations for grayscale images\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,       # Randomly rotate by up to 15 degrees\n",
    "    width_shift_range=0.1,   # Randomly shift width by up to 10%\n",
    "    height_shift_range=0.1,  # Randomly shift height by up to 10%\n",
    "    horizontal_flip=True,    # Randomly flip horizontally\n",
    "    brightness_range=[0.8, 1.2],  # Randomly adjust brightness\n",
    "    zoom_range=0.2,          # Randomly zoom by up to 20%\n",
    ")\n",
    "\n",
    "# Function to convert image to grayscale\n",
    "def to_grayscale(image):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:  # If RGB, convert to grayscale\n",
    "            image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)\n",
    "    else:  # If PIL image, convert to grayscale\n",
    "        image = ImageOps.grayscale(image)\n",
    "    return image\n",
    "\n",
    "# Function to apply augmentation to a grayscale image\n",
    "def augment_image(image):\n",
    "    # Convert image to NumPy array if necessary\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        image = np.array(image)  # Convert PIL image to NumPy array\n",
    "\n",
    "    # Ensure the image has a single channel (grayscale)\n",
    "    if len(image.shape) == 2:  # If grayscale, add a channel dimension\n",
    "        image = np.expand_dims(image, axis=-1)  # Shape: (height, width, 1)\n",
    "\n",
    "    # Add batch dimension: (1, height, width, 1)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Apply augmentation\n",
    "    augmented_image = next(datagen.flow(image, batch_size=1))[0]  # Use next() to get the augmented image\n",
    "    return augmented_image\n",
    "\n",
    "# Display original and augmented grayscale images with labels\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(5):  # Show 5 examples\n",
    "    # Original image\n",
    "    original_image = dataset[i]['image']  # Replace 'image' with the correct key\n",
    "    label = dataset[i]['label']  # Replace 'label' with the correct key\n",
    "\n",
    "    # Convert original image to grayscale\n",
    "    original_grayscale = to_grayscale(original_image)\n",
    "\n",
    "    # Display original grayscale image\n",
    "    plt.subplot(5, 2, 2 * i + 1)\n",
    "    plt.imshow(original_grayscale, cmap='gray')\n",
    "    plt.title(f\"Original {i+1} - Label: {label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Augmented grayscale image\n",
    "    augmented_image = augment_image(original_grayscale)\n",
    "    plt.subplot(5, 2, 2 * i + 2)\n",
    "    plt.imshow(augmented_image.squeeze(), cmap='gray')  # Remove extra dimensions and display\n",
    "    plt.title(f\"Augmented {i+1} - Label: {label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "Rme0Y8LqOWjq",
    "outputId": "8aa9ac9b-c0f4-41da-f988-cb5a5b79cdec"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from PIL import ImageOps\n",
    "\n",
    "# Load the Falah/Alzheimer_MRI dataset\n",
    "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
    "\n",
    "# Define augmentation transformations for grayscale images\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,       # Randomly rotate by up to 15 degrees\n",
    "    width_shift_range=0.1,   # Randomly shift width by up to 10%\n",
    "    height_shift_range=0.1,  # Randomly shift height by up to 10%\n",
    "    horizontal_flip=True,    # Randomly flip horizontally\n",
    "    brightness_range=[0.8, 1.2],  # Randomly adjust brightness\n",
    "    zoom_range=0.2,          # Randomly zoom by up to 20%\n",
    ")\n",
    "\n",
    "# Function to convert image to grayscale\n",
    "def to_grayscale(image):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:  # If RGB, convert to grayscale\n",
    "            image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)\n",
    "    else:  # If PIL image, convert to grayscale\n",
    "        image = ImageOps.grayscale(image)\n",
    "    return image\n",
    "\n",
    "# Function to apply augmentation to a grayscale image\n",
    "def augment_image(image):\n",
    "    # Convert image to NumPy array if necessary\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        image = np.array(image)  # Convert PIL image to NumPy array\n",
    "\n",
    "    # Ensure the image has a single channel (grayscale)\n",
    "    if len(image.shape) == 2:  # If grayscale, add a channel dimension\n",
    "        image = np.expand_dims(image, axis=-1)  # Shape: (height, width, 1)\n",
    "\n",
    "    # Add batch dimension: (1, height, width, 1)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Apply augmentation\n",
    "    augmented_image = next(datagen.flow(image, batch_size=1))[0]  # Use next() to get the augmented image\n",
    "    return augmented_image\n",
    "\n",
    "# Augment the dataset and collect labels\n",
    "augmented_labels = []\n",
    "for example in dataset:\n",
    "    original_image = example['image']  # Replace 'image' with the correct key\n",
    "    label = example['label']  # Replace 'label' with the correct key\n",
    "\n",
    "    # Convert original image to grayscale\n",
    "    original_grayscale = to_grayscale(original_image)\n",
    "\n",
    "    # Augment the grayscale image\n",
    "    augmented_image = augment_image(original_grayscale)\n",
    "\n",
    "    # Append the label to the augmented_labels list\n",
    "    augmented_labels.append(label)\n",
    "\n",
    "# Count the occurrences of each label in the augmented dataset\n",
    "augmented_label_counts = Counter(augmented_labels)\n",
    "\n",
    "# Print the label distribution\n",
    "print(\"Augmented label distribution:\", augmented_label_counts)\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(augmented_label_counts.keys(), augmented_label_counts.values(), color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Labels', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.title('Distribution of Labels After Augmentation', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Customize x-axis to show only integer labels\n",
    "plt.xticks(list(augmented_label_counts.keys()), fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bFJxzPSO2ol"
   },
   "source": [
    "> The augmentation process is not modifying the dataset or the labels. This happens because:\n",
    "\n",
    "1. The augmentation is applied to the images, but the labels remain unchanged.\n",
    "\n",
    "2. The augmented images are not being saved or used to update the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiDqEDg0PTJg"
   },
   "source": [
    "### Steps:\n",
    "- Define Augmentation Ratios:\n",
    "\n",
    "For each class, specify how many augmented images to generate per original image.\n",
    "\n",
    "- Apply Augmentation:\n",
    "\n",
    "For each image in the dataset, generate the specified number of augmented images based on its class.\n",
    "\n",
    "- Collect Augmented Images and Labels:\n",
    "\n",
    "Store the augmented images and their corresponding labels.\n",
    "\n",
    "- Visualize the Distribution:\n",
    "\n",
    "Plot the distribution of labels in the augmented dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "5-cBopVzRcjM",
    "outputId": "c7cdff21-a89d-4887-e463-c934dbe0b52c"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from PIL import ImageOps\n",
    "\n",
    "# Load the Falah/Alzheimer_MRI dataset\n",
    "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
    "\n",
    "# Define augmentation transformations for grayscale images\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,       # Randomly rotate by up to 15 degrees\n",
    "    width_shift_range=0.1,   # Randomly shift width by up to 10%\n",
    "    height_shift_range=0.1,  # Randomly shift height by up to 10%\n",
    "    horizontal_flip=True,    # Randomly flip horizontally\n",
    "    brightness_range=[0.8, 1.2],  # Randomly adjust brightness\n",
    "    zoom_range=0.2,          # Randomly zoom by up to 20%\n",
    ")\n",
    "\n",
    "# Function to convert image to grayscale\n",
    "def to_grayscale(image):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        if len(image.shape) == 3 and image.shape[-1] == 3:  # If RGB, convert to grayscale\n",
    "            image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)\n",
    "    else:  # If PIL image, convert to grayscale\n",
    "        image = ImageOps.grayscale(image)\n",
    "    return image\n",
    "\n",
    "# Function to apply augmentation to a grayscale image\n",
    "def augment_image(image):\n",
    "    # Convert image to NumPy array if necessary\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        image = np.array(image)  # Convert PIL image to NumPy array\n",
    "\n",
    "    # Ensure the image has a single channel (grayscale)\n",
    "    if len(image.shape) == 2:  # If grayscale, add a channel dimension\n",
    "        image = np.expand_dims(image, axis=-1)  # Shape: (height, width, 1)\n",
    "\n",
    "    # Add batch dimension: (1, height, width, 1)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Apply augmentation\n",
    "    augmented_image = next(datagen.flow(image, batch_size=1))[0]  # Use next() to get the augmented image\n",
    "    return augmented_image\n",
    "\n",
    "# Define the number of augmented images to generate per class\n",
    "augmentation_ratios = {\n",
    "    0: 7,  # For class 0, generate 7 augmented images per original image\n",
    "    1: 102,  # For class 1, generate 102 augmented images per original image\n",
    "    2: 2,  # For class 2, generate 1 augmented image per original image\n",
    "    3: 3,  # For class 3, generate 3 augmented images per original image\n",
    "}\n",
    "\n",
    "# Augment the dataset and collect labels\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "for example in dataset:\n",
    "    original_image = example['image']  # Replace 'image' with the correct key\n",
    "    label = example['label']  # Replace 'label' with the correct key\n",
    "\n",
    "    # Convert original image to grayscale\n",
    "    original_grayscale = to_grayscale(original_image)\n",
    "\n",
    "    # Generate augmented images based on the class\n",
    "    num_augmented = augmentation_ratios.get(label, 1)  # Default to 1 if label not in augmentation_ratios\n",
    "    for _ in range(num_augmented):\n",
    "        augmented_image = augment_image(original_grayscale)\n",
    "        augmented_images.append(augmented_image)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "# Count the occurrences of each label in the augmented dataset\n",
    "augmented_label_counts = Counter(augmented_labels)\n",
    "\n",
    "# Print the label distribution\n",
    "print(\"Augmented label distribution:\", augmented_label_counts)\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(augmented_label_counts.keys(), augmented_label_counts.values(), color='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Labels', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.title('Distribution of Labels After Augmentation', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Customize x-axis to show only integer labels\n",
    "plt.xticks(list(augmented_label_counts.keys()), fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "id": "IorQ_2v8SnG7",
    "outputId": "b27b3ce5-ab07-4d3c-f690-9ff07b7574f6"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Combine original and augmented data\n",
    "all_images = list(dataset['image']) + augmented_images\n",
    "all_labels = list(dataset['label']) + augmented_labels\n",
    "\n",
    "# Separate images by class\n",
    "class_images = defaultdict(list)\n",
    "for image, label in zip(all_images, all_labels):\n",
    "    class_images[label].append(image)\n",
    "\n",
    "# Randomly sample 10 images from each class\n",
    "sampled_images = {}\n",
    "for label, images in class_images.items():\n",
    "    sampled_images[label] = random.sample(images, min(10, len(images)))  # Sample 10 images or all if less than 10\n",
    "\n",
    "# Display sampled images\n",
    "plt.figure(figsize=(20, 20))\n",
    "for label, images in sampled_images.items():\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(4, 10, label * 10 + i + 1)  # Arrange in a grid (4 classes x 10 images)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(f\"Class {label}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SqPK1jEd0WG"
   },
   "source": [
    "# Apr4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Whwgh8QBd_qL"
   },
   "source": [
    "## Step 1: Load and Preprocess the MRI Dataset\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
