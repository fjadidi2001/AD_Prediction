{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/MRtoCT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDMEndHw6FSu",
        "outputId": "487a2079-2632-4662-a75b-a76c0f5ed5a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cizhYdBE8QyZ"
      },
      "source": [
        "> The Falah/Alzheimer_MRI Disease Classification dataset is a valuable resource for researchers and health medicine applications. This dataset focuses on the classification of Alzheimer's disease based on MRI scans. The dataset consists of brain MRI images labeled into four categories:\n",
        "\n",
        "- '0': Mild_Demented\n",
        "- '1': Moderate_Demented\n",
        "- '2': Non_Demented\n",
        "- '3': Very_Mild_Demented\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG3WAtOb57oX"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the Falah/Alzheimer_MRI dataset\n",
        "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
        "\n",
        "# Print the number of examples\n",
        "print(\"Number of examples:\", len(dataset))\n",
        "\n",
        "# Print the structure of the first example\n",
        "print(\"Structure of the first example:\")\n",
        "print(dataset[0])\n",
        "\n",
        "# Print the keys of the first example (if it's a dictionary)\n",
        "if isinstance(dataset[0], dict):\n",
        "    print(\"Keys in the first example:\", dataset[0].keys())\n",
        "\n",
        "# Print the first few samples\n",
        "print(\"Sample data:\")\n",
        "for example in dataset[:5]:\n",
        "    print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzLHbZoe7-dA"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming the image is stored under the key 'image' in the dataset\n",
        "image = dataset[0]['image']\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # Hide the axes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhuehP6pD7qN"
      },
      "outputs": [],
      "source": [
        "# Display 25 images with their labels\n",
        "plt.figure(figsize=(15, 10))  # Set the figure size\n",
        "for i in range(25):\n",
        "    # Get the image and label\n",
        "    image = dataset[i]['image']\n",
        "    label = dataset[i]['label']\n",
        "\n",
        "    # Plot the image\n",
        "    plt.subplot(5, 5, i + 1)  # Arrange images in a grid (2 rows, 5 columns)\n",
        "    plt.imshow(image)  # Display the image\n",
        "    plt.title(f\"Label: {label}\")  # Set the title as the label\n",
        "    plt.axis('off')  # Hide the axes\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to avoid overlapping\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1F0g8toD_Pk"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# Load the Falah/Alzheimer_MRI dataset\n",
        "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
        "\n",
        "# Extract labels (assuming the key is 'label')\n",
        "labels = [int(example['label']) for example in dataset]  # Convert labels to integers\n",
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = Counter(labels)\n",
        "\n",
        "# Print the label distribution\n",
        "print(\"Label distribution:\", label_counts)\n",
        "\n",
        "# Set a better color palette\n",
        "sns.set_palette(\"muted\")\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=list(label_counts.keys()), y=list(label_counts.values()), palette=\"viridis\",hue=list(label_counts.keys()))\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Labels', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.title('Distribution of Labels in the Train Dataset before augmentation', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Add grid lines for better readability\n",
        "plt.grid(True, axis='y', linestyle='-', alpha=0.7)\n",
        "\n",
        "# Customize x-axis to show only integer labels\n",
        "plt.xticks(list(label_counts.keys()), fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcFMT_sXHMu9"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# Load the Falah/Alzheimer_MRI dataset\n",
        "dataset = load_dataset('Falah/Alzheimer_MRI', split='test')\n",
        "\n",
        "# Extract labels (assuming the key is 'label')\n",
        "labels = [int(example['label']) for example in dataset]  # Convert labels to integers\n",
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = Counter(labels)\n",
        "\n",
        "# Print the label distribution\n",
        "print(\"Label distribution:\", label_counts)\n",
        "\n",
        "# Set a better color palette\n",
        "sns.set_palette(\"pastel\")  # You can choose other palettes like \"deep\", \"muted\", \"bright\", etc.\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=list(label_counts.keys()), y=list(label_counts.values()), palette=\"viridis\",hue=list(label_counts.keys()))\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Labels', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.title('Distribution of Labels in the Test Dataset before augmentation', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Add grid lines for better readability\n",
        "plt.grid(True, axis='y', linestyle='-', alpha=0.7)\n",
        "\n",
        "# Customize x-axis to show only integer labels\n",
        "plt.xticks(list(label_counts.keys()), fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Q32KeHIPHR"
      },
      "source": [
        "> Data augmentation is a powerful technique to increase the diversity of your training dataset by applying random transformations such as rotations, flips, zooms, and more. This helps improve the generalization of your model, especially when the dataset is small or imbalanced.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oalIYPPuNFxk"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Falah/Alzheimer_MRI dataset\n",
        "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
        "\n",
        "# Define augmentation transformations\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,       # Randomly rotate by up to 15 degrees\n",
        "    width_shift_range=0.1,   # Randomly shift width by up to 10%\n",
        "    height_shift_range=0.1,  # Randomly shift height by up to 10%\n",
        "    horizontal_flip=True,    # Randomly flip horizontally\n",
        "    brightness_range=[0.8, 1.2],  # Randomly adjust brightness\n",
        "    zoom_range=0.2,          # Randomly zoom by up to 20%\n",
        ")\n",
        "\n",
        "# Function to apply augmentation to an image\n",
        "def augment_image(image):\n",
        "    # Convert PIL image to NumPy array if necessary\n",
        "    if not isinstance(image, np.ndarray):\n",
        "        image = np.array(image)  # Convert PIL image to NumPy array\n",
        "\n",
        "    # Ensure the image has 3 channels (RGB)\n",
        "    if len(image.shape) == 2:  # If grayscale, convert to RGB\n",
        "        image = np.stack((image,) * 3, axis=-1)  # Shape: (height, width, 3)\n",
        "    elif len(image.shape) == 3 and image.shape[-1] == 4:  # If RGBA, convert to RGB\n",
        "        image = image[:, :, :3]  # Keep only the first 3 channels\n",
        "\n",
        "    # Print the shape of the image before augmentation\n",
        "    print(f\"Shape before augmentation: {image.shape}\")\n",
        "\n",
        "    # Add batch dimension: (1, height, width, channels)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Apply augmentation\n",
        "    augmented_image = next(datagen.flow(image, batch_size=1))[0]  # Use next() to get the augmented image\n",
        "\n",
        "    # Print the shape of the image after augmentation\n",
        "    print(f\"Shape after augmentation: {augmented_image.shape}\")\n",
        "\n",
        "    return augmented_image\n",
        "\n",
        "# Display original and augmented images with labels\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(5):  # Show 5 examples\n",
        "    # Original image\n",
        "    original_image = dataset[i]['image']  # Replace 'image' with the correct key\n",
        "    label = dataset[i]['label']  # Replace 'label' with the correct key\n",
        "\n",
        "    # Check the type of the image\n",
        "    print(f\"Image type: {type(original_image)}\")\n",
        "\n",
        "    # Display original image\n",
        "    plt.subplot(5, 2, 2 * i + 1)\n",
        "    plt.imshow(original_image)\n",
        "    plt.title(f\"Original {i+1} - Label: {label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Augmented image\n",
        "    augmented_image = augment_image(original_image)\n",
        "    plt.subplot(5, 2, 2 * i + 2)\n",
        "    plt.imshow(augmented_image.astype(np.uint8))  # Ensure the image is in the correct format for display\n",
        "    plt.title(f\"Augmented {i+1} - Label: {label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGaYwnn9NoZX"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import ImageOps\n",
        "\n",
        "# Load the Falah/Alzheimer_MRI dataset\n",
        "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
        "\n",
        "# Define augmentation transformations for grayscale images\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,       # Randomly rotate by up to 15 degrees\n",
        "    width_shift_range=0.1,   # Randomly shift width by up to 10%\n",
        "    height_shift_range=0.1,  # Randomly shift height by up to 10%\n",
        "    horizontal_flip=True,    # Randomly flip horizontally\n",
        "    brightness_range=[0.8, 1.2],  # Randomly adjust brightness\n",
        "    zoom_range=0.2,          # Randomly zoom by up to 20%\n",
        ")\n",
        "\n",
        "# Function to convert image to grayscale\n",
        "def to_grayscale(image):\n",
        "    if isinstance(image, np.ndarray):\n",
        "        if len(image.shape) == 3 and image.shape[-1] == 3:  # If RGB, convert to grayscale\n",
        "            image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)\n",
        "    else:  # If PIL image, convert to grayscale\n",
        "        image = ImageOps.grayscale(image)\n",
        "    return image\n",
        "\n",
        "# Function to apply augmentation to a grayscale image\n",
        "def augment_image(image):\n",
        "    # Convert image to NumPy array if necessary\n",
        "    if not isinstance(image, np.ndarray):\n",
        "        image = np.array(image)  # Convert PIL image to NumPy array\n",
        "\n",
        "    # Ensure the image has a single channel (grayscale)\n",
        "    if len(image.shape) == 2:  # If grayscale, add a channel dimension\n",
        "        image = np.expand_dims(image, axis=-1)  # Shape: (height, width, 1)\n",
        "\n",
        "    # Add batch dimension: (1, height, width, 1)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Apply augmentation\n",
        "    augmented_image = next(datagen.flow(image, batch_size=1))[0]  # Use next() to get the augmented image\n",
        "    return augmented_image\n",
        "\n",
        "# Display original and augmented grayscale images with labels\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(5):  # Show 5 examples\n",
        "    # Original image\n",
        "    original_image = dataset[i]['image']  # Replace 'image' with the correct key\n",
        "    label = dataset[i]['label']  # Replace 'label' with the correct key\n",
        "\n",
        "    # Convert original image to grayscale\n",
        "    original_grayscale = to_grayscale(original_image)\n",
        "\n",
        "    # Display original grayscale image\n",
        "    plt.subplot(5, 2, 2 * i + 1)\n",
        "    plt.imshow(original_grayscale, cmap='gray')\n",
        "    plt.title(f\"Original {i+1} - Label: {label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Augmented grayscale image\n",
        "    augmented_image = augment_image(original_grayscale)\n",
        "    plt.subplot(5, 2, 2 * i + 2)\n",
        "    plt.imshow(augmented_image.squeeze(), cmap='gray')  # Remove extra dimensions and display\n",
        "    plt.title(f\"Augmented {i+1} - Label: {label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rme0Y8LqOWjq"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from PIL import ImageOps\n",
        "\n",
        "# Load the Falah/Alzheimer_MRI dataset\n",
        "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
        "\n",
        "# Define augmentation transformations for grayscale images\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,       # Randomly rotate by up to 15 degrees\n",
        "    width_shift_range=0.1,   # Randomly shift width by up to 10%\n",
        "    height_shift_range=0.1,  # Randomly shift height by up to 10%\n",
        "    horizontal_flip=True,    # Randomly flip horizontally\n",
        "    brightness_range=[0.8, 1.2],  # Randomly adjust brightness\n",
        "    zoom_range=0.2,          # Randomly zoom by up to 20%\n",
        ")\n",
        "\n",
        "# Function to convert image to grayscale\n",
        "def to_grayscale(image):\n",
        "    if isinstance(image, np.ndarray):\n",
        "        if len(image.shape) == 3 and image.shape[-1] == 3:  # If RGB, convert to grayscale\n",
        "            image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)\n",
        "    else:  # If PIL image, convert to grayscale\n",
        "        image = ImageOps.grayscale(image)\n",
        "    return image\n",
        "\n",
        "# Function to apply augmentation to a grayscale image\n",
        "def augment_image(image):\n",
        "    # Convert image to NumPy array if necessary\n",
        "    if not isinstance(image, np.ndarray):\n",
        "        image = np.array(image)  # Convert PIL image to NumPy array\n",
        "\n",
        "    # Ensure the image has a single channel (grayscale)\n",
        "    if len(image.shape) == 2:  # If grayscale, add a channel dimension\n",
        "        image = np.expand_dims(image, axis=-1)  # Shape: (height, width, 1)\n",
        "\n",
        "    # Add batch dimension: (1, height, width, 1)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Apply augmentation\n",
        "    augmented_image = next(datagen.flow(image, batch_size=1))[0]  # Use next() to get the augmented image\n",
        "    return augmented_image\n",
        "\n",
        "# Augment the dataset and collect labels\n",
        "augmented_labels = []\n",
        "for example in dataset:\n",
        "    original_image = example['image']  # Replace 'image' with the correct key\n",
        "    label = example['label']  # Replace 'label' with the correct key\n",
        "\n",
        "    # Convert original image to grayscale\n",
        "    original_grayscale = to_grayscale(original_image)\n",
        "\n",
        "    # Augment the grayscale image\n",
        "    augmented_image = augment_image(original_grayscale)\n",
        "\n",
        "    # Append the label to the augmented_labels list\n",
        "    augmented_labels.append(label)\n",
        "\n",
        "# Count the occurrences of each label in the augmented dataset\n",
        "augmented_label_counts = Counter(augmented_labels)\n",
        "\n",
        "# Print the label distribution\n",
        "print(\"Augmented label distribution:\", augmented_label_counts)\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(augmented_label_counts.keys(), augmented_label_counts.values(), color='skyblue')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Labels', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.title('Distribution of Labels After Augmentation', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Customize x-axis to show only integer labels\n",
        "plt.xticks(list(augmented_label_counts.keys()), fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bFJxzPSO2ol"
      },
      "source": [
        "> The augmentation process is not modifying the dataset or the labels. This happens because:\n",
        "\n",
        "1. The augmentation is applied to the images, but the labels remain unchanged.\n",
        "\n",
        "2. The augmented images are not being saved or used to update the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiDqEDg0PTJg"
      },
      "source": [
        "### Steps:\n",
        "- Define Augmentation Ratios:\n",
        "\n",
        "For each class, specify how many augmented images to generate per original image.\n",
        "\n",
        "- Apply Augmentation:\n",
        "\n",
        "For each image in the dataset, generate the specified number of augmented images based on its class.\n",
        "\n",
        "- Collect Augmented Images and Labels:\n",
        "\n",
        "Store the augmented images and their corresponding labels.\n",
        "\n",
        "- Visualize the Distribution:\n",
        "\n",
        "Plot the distribution of labels in the augmented dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-cBopVzRcjM"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from PIL import ImageOps\n",
        "\n",
        "# Load the Falah/Alzheimer_MRI dataset\n",
        "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
        "\n",
        "# Define augmentation transformations for grayscale images\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,       # Randomly rotate by up to 15 degrees\n",
        "    width_shift_range=0.1,   # Randomly shift width by up to 10%\n",
        "    height_shift_range=0.1,  # Randomly shift height by up to 10%\n",
        "    horizontal_flip=True,    # Randomly flip horizontally\n",
        "    brightness_range=[0.8, 1.2],  # Randomly adjust brightness\n",
        "    zoom_range=0.2,          # Randomly zoom by up to 20%\n",
        ")\n",
        "\n",
        "# Function to convert image to grayscale\n",
        "def to_grayscale(image):\n",
        "    if isinstance(image, np.ndarray):\n",
        "        if len(image.shape) == 3 and image.shape[-1] == 3:  # If RGB, convert to grayscale\n",
        "            image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)\n",
        "    else:  # If PIL image, convert to grayscale\n",
        "        image = ImageOps.grayscale(image)\n",
        "    return image\n",
        "\n",
        "# Function to apply augmentation to a grayscale image\n",
        "def augment_image(image):\n",
        "    # Convert image to NumPy array if necessary\n",
        "    if not isinstance(image, np.ndarray):\n",
        "        image = np.array(image)  # Convert PIL image to NumPy array\n",
        "\n",
        "    # Ensure the image has a single channel (grayscale)\n",
        "    if len(image.shape) == 2:  # If grayscale, add a channel dimension\n",
        "        image = np.expand_dims(image, axis=-1)  # Shape: (height, width, 1)\n",
        "\n",
        "    # Add batch dimension: (1, height, width, 1)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Apply augmentation\n",
        "    augmented_image = next(datagen.flow(image, batch_size=1))[0]  # Use next() to get the augmented image\n",
        "    return augmented_image\n",
        "\n",
        "# Define the number of augmented images to generate per class\n",
        "augmentation_ratios = {\n",
        "    0: 7,  # For class 0, generate 7 augmented images per original image\n",
        "    1: 102,  # For class 1, generate 102 augmented images per original image\n",
        "    2: 2,  # For class 2, generate 1 augmented image per original image\n",
        "    3: 3,  # For class 3, generate 3 augmented images per original image\n",
        "}\n",
        "\n",
        "# Augment the dataset and collect labels\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "\n",
        "for example in dataset:\n",
        "    original_image = example['image']  # Replace 'image' with the correct key\n",
        "    label = example['label']  # Replace 'label' with the correct key\n",
        "\n",
        "    # Convert original image to grayscale\n",
        "    original_grayscale = to_grayscale(original_image)\n",
        "\n",
        "    # Generate augmented images based on the class\n",
        "    num_augmented = augmentation_ratios.get(label, 1)  # Default to 1 if label not in augmentation_ratios\n",
        "    for _ in range(num_augmented):\n",
        "        augmented_image = augment_image(original_grayscale)\n",
        "        augmented_images.append(augmented_image)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "# Count the occurrences of each label in the augmented dataset\n",
        "augmented_label_counts = Counter(augmented_labels)\n",
        "\n",
        "# Print the label distribution\n",
        "print(\"Augmented label distribution:\", augmented_label_counts)\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(augmented_label_counts.keys(), augmented_label_counts.values(), color='black')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Labels', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.title('Distribution of Labels After Augmentation', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Customize x-axis to show only integer labels\n",
        "plt.xticks(list(augmented_label_counts.keys()), fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IorQ_2v8SnG7"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "# Combine original and augmented data\n",
        "all_images = list(dataset['image']) + augmented_images\n",
        "all_labels = list(dataset['label']) + augmented_labels\n",
        "\n",
        "# Separate images by class\n",
        "class_images = defaultdict(list)\n",
        "for image, label in zip(all_images, all_labels):\n",
        "    class_images[label].append(image)\n",
        "\n",
        "# Randomly sample 10 images from each class\n",
        "sampled_images = {}\n",
        "for label, images in class_images.items():\n",
        "    sampled_images[label] = random.sample(images, min(10, len(images)))  # Sample 10 images or all if less than 10\n",
        "\n",
        "# Display sampled images\n",
        "plt.figure(figsize=(20, 20))\n",
        "for label, images in sampled_images.items():\n",
        "    for i, image in enumerate(images):\n",
        "        plt.subplot(4, 10, label * 10 + i + 1)  # Arrange in a grid (4 classes x 10 images)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(f\"Class {label}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SqPK1jEd0WG"
      },
      "source": [
        "# Apr 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whwgh8QBd_qL"
      },
      "source": [
        "## Step 1: Load and Preprocess the MRI Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "\n",
        "# Load the Falah/Alzheimer_MRI dataset\n",
        "dataset = load_dataset('Falah/Alzheimer_MRI', split='train')\n",
        "\n",
        "# Print dataset info\n",
        "print(\"Number of examples:\", len(dataset))\n",
        "print(\"Structure of the first example:\", dataset[0])\n",
        "if isinstance(dataset[0], dict):\n",
        "    print(\"Keys in the first example:\", dataset[0].keys())\n",
        "\n",
        "# Visualize label distribution\n",
        "labels = [int(example['label']) for example in dataset]\n",
        "label_counts = Counter(labels)\n",
        "print(\"Label distribution:\", label_counts)\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.set_palette(\"muted\")\n",
        "sns.barplot(x=list(label_counts.keys()), y=list(label_counts.values()), palette=\"viridis\", hue=list(label_counts.keys()))\n",
        "plt.xlabel('Labels', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.title('Distribution of Labels in the Train Dataset', fontsize=16, fontweight='bold')\n",
        "plt.grid(True, axis='y', linestyle='-', alpha=0.7)\n",
        "plt.xticks(list(label_counts.keys()), fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Define preprocessing transformations\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Resize to 256x256 as per the diagram\n",
        "    transforms.ToTensor(),  # Convert to tensor (values between 0 and 1)\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1] for GAN training\n",
        "])\n",
        "\n",
        "# Apply preprocessing to the dataset\n",
        "def preprocess_image(example):\n",
        "    image = example['image']\n",
        "    if isinstance(image, np.ndarray):\n",
        "        image = Image.fromarray(image)\n",
        "    if image.mode != 'L':  # Convert to grayscale if not already\n",
        "        image = image.convert('L')\n",
        "    image = preprocess(image)\n",
        "    return {'image': image, 'label': example['label']}\n",
        "\n",
        "# Map the preprocessing function to the dataset\n",
        "processed_dataset = dataset.map(preprocess_image)\n",
        "\n",
        "# Visualize the first preprocessed image\n",
        "image = processed_dataset[0]['image']\n",
        "image = image * 0.5 + 0.5  # Denormalize for visualization\n",
        "plt.imshow(image.squeeze(), cmap='gray')  # Display as grayscale\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "OaF22wp5g4rx",
        "outputId": "c2bf9e6b-4477-488b-90dd-3f77c42bec51"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-76418f0f2d25>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}