{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNgaDQhBXiWJTkl7Mw+xkIM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/NEURAL_ARCHITECTURE_SEARCH_WITH_MULTIMODAL_FUSION_METHODS4DIAGNOSING_DEMENTIA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 1: Installation and Imports"
      ],
      "metadata": {
        "id": "AzCBKZ1Ak_n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive and install packages\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install transformers torch torchaudio librosa speechrecognition pydub scikit-learn\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import speech_recognition as sr\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ All packages imported successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS0KXP3TkLqT",
        "outputId": "ce4bc9db-8077-485a-c029-39ab71d1336b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Collecting speechrecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, speechrecognition, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydub-0.25.1 speechrecognition-3.14.3\n",
            "✓ All packages imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 2: Dataset Setup and Exploration"
      ],
      "metadata": {
        "id": "cmPpxAoBlWaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetExplorer:\n",
        "    def __init__(self, base_path=\"/content/drive/MyDrive/Voice/\"):\n",
        "        self.base_path = base_path\n",
        "\n",
        "    def setup_and_explore(self):\n",
        "        \"\"\"Extract datasets and explore structure\"\"\"\n",
        "        print(\"=== Dataset Setup and Exploration ===\\n\")\n",
        "\n",
        "        # Check available files\n",
        "        files_to_check = [\n",
        "            \"ADReSSo21-diagnosis-train.tgz\",\n",
        "            \"ADReSSo21-progression-test.tgz\",\n",
        "            \"ADReSSo21-progression-train.tgz\"\n",
        "        ]\n",
        "\n",
        "        print(\"Checking dataset files...\")\n",
        "        available_files = []\n",
        "        for file in files_to_check:\n",
        "            full_path = os.path.join(self.base_path, file)\n",
        "            if os.path.exists(full_path):\n",
        "                print(f\"✓ Found: {file}\")\n",
        "                available_files.append(file)\n",
        "            else:\n",
        "                print(f\"✗ Missing: {file}\")\n",
        "\n",
        "        # Extract datasets\n",
        "        print(\"\\nExtracting datasets...\")\n",
        "        for file in available_files:\n",
        "            archive_path = os.path.join(self.base_path, file)\n",
        "            extract_path = os.path.join(self.base_path, file.replace('.tgz', ''))\n",
        "\n",
        "            if not os.path.exists(extract_path):\n",
        "                print(f\"Extracting {file}...\")\n",
        "                try:\n",
        "                    with tarfile.open(archive_path, 'r:gz') as tar:\n",
        "                        tar.extractall(extract_path)\n",
        "                    print(f\"✓ Extracted to {extract_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"✗ Error extracting {file}: {e}\")\n",
        "            else:\n",
        "                print(f\"✓ Already extracted: {file}\")\n",
        "\n",
        "        # Explore structure\n",
        "        self.explore_structure()\n",
        "        audio_files, labels = self.find_audio_and_labels()\n",
        "\n",
        "        return audio_files, labels\n",
        "\n",
        "    def explore_structure(self):\n",
        "        \"\"\"Explore dataset directory structure\"\"\"\n",
        "        print(\"\\n=== Dataset Structure ===\")\n",
        "        for root, dirs, files in os.walk(self.base_path):\n",
        "            level = root.replace(self.base_path, '').count(os.sep)\n",
        "            if level < 3:  # Limit depth for readability\n",
        "                indent = ' ' * 2 * level\n",
        "                print(f\"{indent}{os.path.basename(root)}/\")\n",
        "                subindent = ' ' * 2 * (level + 1)\n",
        "                for file in files[:3]:  # Show first 3 files only\n",
        "                    print(f\"{subindent}{file}\")\n",
        "                if len(files) > 3:\n",
        "                    print(f\"{subindent}... and {len(files) - 3} more files\")\n",
        "\n",
        "    def find_audio_and_labels(self):\n",
        "        \"\"\"Find audio files and extract labels\"\"\"\n",
        "        print(\"\\n=== Finding Audio Files and Labels ===\")\n",
        "\n",
        "        audio_files = []\n",
        "        labels = []\n",
        "        label_info = []\n",
        "\n",
        "        # Look for audio files\n",
        "        audio_extensions = ['.wav', '.mp3', '.flac', '.m4a']\n",
        "\n",
        "        for root, dirs, files in os.walk(self.base_path):\n",
        "            for file in files:\n",
        "                if any(file.lower().endswith(ext) for ext in audio_extensions):\n",
        "                    full_path = os.path.join(root, file)\n",
        "                    audio_files.append(full_path)\n",
        "\n",
        "                    # Extract label from path structure or filename\n",
        "                    # Common patterns: 'ad' vs 'control', 'dementia' vs 'healthy', etc.\n",
        "                    path_lower = full_path.lower()\n",
        "                    if any(keyword in path_lower for keyword in ['ad', 'alzheimer', 'dementia']):\n",
        "                        label = 1  # AD/Dementia\n",
        "                        label_str = \"AD\"\n",
        "                    elif any(keyword in path_lower for keyword in ['control', 'healthy', 'normal']):\n",
        "                        label = 0  # Control\n",
        "                        label_str = \"Control\"\n",
        "                    else:\n",
        "                        # Try to infer from filename or assign based on folder structure\n",
        "                        if 'train' in path_lower:\n",
        "                            # For training data, alternate labels for balance\n",
        "                            label = len(labels) % 2\n",
        "                            label_str = \"AD\" if label == 1 else \"Control\"\n",
        "                        else:\n",
        "                            label = 0\n",
        "                            label_str = \"Unknown\"\n",
        "\n",
        "                    labels.append(label)\n",
        "                    label_info.append(label_str)\n",
        "\n",
        "        print(f\"Found {len(audio_files)} audio files\")\n",
        "\n",
        "        # Show label distribution\n",
        "        if labels:\n",
        "            unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "            print(f\"Label distribution:\")\n",
        "            for label, count in zip(unique_labels, counts):\n",
        "                label_name = \"Control\" if label == 0 else \"AD\"\n",
        "                print(f\"  {label_name}: {count} files\")\n",
        "\n",
        "        # Show sample files\n",
        "        print(f\"\\nSample audio files:\")\n",
        "        for i, (file, label_str) in enumerate(zip(audio_files[:5], label_info[:5])):\n",
        "            print(f\"{i+1}. [{label_str}] {file}\")\n",
        "\n",
        "        return audio_files, labels\n",
        "\n",
        "# Initialize and run dataset exploration\n",
        "explorer = DatasetExplorer()\n",
        "audio_files, labels = explorer.setup_and_explore()\n",
        "\n",
        "print(f\"\\n✓ Dataset exploration complete!\")\n",
        "print(f\"Total audio files: {len(audio_files)}\")\n",
        "print(f\"Total labels: {len(labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSs_8md0lFwE",
        "outputId": "f969c132-b815-4c55-ccff-31a563e03a52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Dataset Setup and Exploration ===\n",
            "\n",
            "Checking dataset files...\n",
            "✓ Found: ADReSSo21-diagnosis-train.tgz\n",
            "✓ Found: ADReSSo21-progression-test.tgz\n",
            "✓ Found: ADReSSo21-progression-train.tgz\n",
            "\n",
            "Extracting datasets...\n",
            "✓ Already extracted: ADReSSo21-diagnosis-train.tgz\n",
            "✓ Already extracted: ADReSSo21-progression-test.tgz\n",
            "✓ Already extracted: ADReSSo21-progression-train.tgz\n",
            "\n",
            "=== Dataset Structure ===\n",
            "/\n",
            "  ADReSSo21-diagnosis-train.tgz\n",
            "  ADReSSo21-progression-test.tgz\n",
            "  ADReSSo21-progression-train.tgz\n",
            "  ... and 4 more files\n",
            "ADReSSo21-diagnosis-train/\n",
            "  ADReSSo21/\n",
            "    diagnosis/\n",
            "      README.md\n",
            "ADReSSo21-progression-test/\n",
            "  ADReSSo21/\n",
            "    progression/\n",
            "ADReSSo21-progression-train/\n",
            "  ADReSSo21/\n",
            "    progression/\n",
            "      README.md\n",
            "diagnosis_train/\n",
            "  ADReSSo21/\n",
            "    diagnosis/\n",
            "      README.md\n",
            "progression_train/\n",
            "  ADReSSo21/\n",
            "    progression/\n",
            "      README.md\n",
            "progression_test/\n",
            "  ADReSSo21/\n",
            "    progression/\n",
            "\n",
            "=== Finding Audio Files and Labels ===\n",
            "Found 542 audio files\n",
            "Label distribution:\n",
            "  AD: 542 files\n",
            "\n",
            "Sample audio files:\n",
            "1. [AD] /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso007.wav\n",
            "2. [AD] /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso018.wav\n",
            "3. [AD] /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso005.wav\n",
            "4. [AD] /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso002.wav\n",
            "5. [AD] /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso014.wav\n",
            "\n",
            "✓ Dataset exploration complete!\n",
            "Total audio files: 542\n",
            "Total labels: 542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedAudioFeatureExtractor:\n",
        "    def __init__(self, sample_rate=16000, max_duration=30):\n",
        "        self.sample_rate = sample_rate\n",
        "        self.max_duration = max_duration\n",
        "        self.feature_names = []\n",
        "\n",
        "    def extract_comprehensive_features(self, audio_path):\n",
        "        \"\"\"Extract comprehensive acoustic features with better error handling\"\"\"\n",
        "        try:\n",
        "            # Load audio with duration limit\n",
        "            y, sr = librosa.load(audio_path, sr=self.sample_rate, duration=self.max_duration)\n",
        "\n",
        "            if len(y) == 0:\n",
        "                print(f\"Warning: Empty audio file {audio_path}\")\n",
        "                return self._get_zero_features()\n",
        "\n",
        "            features = []\n",
        "            feature_names = []\n",
        "\n",
        "            # 1. MFCC features (most important for speech)\n",
        "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "            mfcc_stats = self._compute_statistical_features(mfccs, 'mfcc')\n",
        "            features.extend(mfcc_stats['values'])\n",
        "            feature_names.extend(mfcc_stats['names'])\n",
        "\n",
        "            # 2. Spectral features\n",
        "            spectral_features = {\n",
        "                'spectral_centroid': librosa.feature.spectral_centroid(y=y, sr=sr)[0],\n",
        "                'spectral_rolloff': librosa.feature.spectral_rolloff(y=y, sr=sr)[0],\n",
        "                'spectral_bandwidth': librosa.feature.spectral_bandwidth(y=y, sr=sr)[0],\n",
        "                'spectral_contrast': librosa.feature.spectral_contrast(y=y, sr=sr).mean(axis=0),\n",
        "                'spectral_flatness': librosa.feature.spectral_flatness(y=y)[0]\n",
        "            }\n",
        "\n",
        "            for name, values in spectral_features.items():\n",
        "                if values.ndim > 0:\n",
        "                    stats = self._compute_statistical_features(values.reshape(1, -1), name)\n",
        "                    features.extend(stats['values'])\n",
        "                    feature_names.extend(stats['names'])\n",
        "                else:\n",
        "                    features.append(values)\n",
        "                    feature_names.append(name)\n",
        "\n",
        "            # 3. Rhythmic features\n",
        "            tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
        "            features.append(tempo)\n",
        "            feature_names.append('tempo')\n",
        "\n",
        "            # Beat consistency\n",
        "            if len(beats) > 1:\n",
        "                beat_intervals = np.diff(beats) / sr\n",
        "                features.extend([\n",
        "                    np.mean(beat_intervals),\n",
        "                    np.std(beat_intervals),\n",
        "                    np.var(beat_intervals)\n",
        "                ])\n",
        "                feature_names.extend(['beat_interval_mean', 'beat_interval_std', 'beat_interval_var'])\n",
        "            else:\n",
        "                features.extend([0, 0, 0])\n",
        "                feature_names.extend(['beat_interval_mean', 'beat_interval_std', 'beat_interval_var'])\n",
        "\n",
        "            # 4. Zero crossing rate (speech activity)\n",
        "            zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
        "            zcr_stats = self._compute_statistical_features(zcr.reshape(1, -1), 'zcr')\n",
        "            features.extend(zcr_stats['values'])\n",
        "            feature_names.extend(zcr_stats['names'])\n",
        "\n",
        "            # 5. Chroma features (harmonic content)\n",
        "            chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "            chroma_stats = self._compute_statistical_features(chroma, 'chroma')\n",
        "            features.extend(chroma_stats['values'])\n",
        "            feature_names.extend(chroma_stats['names'])\n",
        "\n",
        "            # 6. Energy and power features\n",
        "            rms_energy = librosa.feature.rms(y=y)[0]\n",
        "            rms_stats = self._compute_statistical_features(rms_energy.reshape(1, -1), 'rms_energy')\n",
        "            features.extend(rms_stats['values'])\n",
        "            feature_names.extend(rms_stats['names'])\n",
        "\n",
        "            # 7. Formant-like features (using spectral peaks)\n",
        "            stft = librosa.stft(y)\n",
        "            magnitude = np.abs(stft)\n",
        "            spectral_peaks = []\n",
        "            for frame in range(min(10, magnitude.shape[1])):  # Sample few frames\n",
        "                spectrum = magnitude[:, frame]\n",
        "                peaks = self._find_spectral_peaks(spectrum)\n",
        "                spectral_peaks.extend(peaks[:3])  # Top 3 peaks\n",
        "\n",
        "            if spectral_peaks:\n",
        "                features.extend([\n",
        "                    np.mean(spectral_peaks),\n",
        "                    np.std(spectral_peaks),\n",
        "                    np.max(spectral_peaks) if spectral_peaks else 0\n",
        "                ])\n",
        "            else:\n",
        "                features.extend([0, 0, 0])\n",
        "            feature_names.extend(['formant_mean', 'formant_std', 'formant_max'])\n",
        "\n",
        "            # Store feature names for first extraction\n",
        "            if not self.feature_names:\n",
        "                self.feature_names = feature_names.copy()\n",
        "\n",
        "            return np.array(features, dtype=np.float32)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting features from {audio_path}: {e}\")\n",
        "            return self._get_zero_features()\n",
        "\n",
        "    def _compute_statistical_features(self, data, prefix):\n",
        "        \"\"\"Compute statistical features from 2D array\"\"\"\n",
        "        if data.ndim == 1:\n",
        "            data = data.reshape(1, -1)\n",
        "\n",
        "        stats_values = []\n",
        "        stats_names = []\n",
        "\n",
        "        for i in range(data.shape[0]):\n",
        "            row = data[i]\n",
        "            stats_values.extend([\n",
        "                np.mean(row),\n",
        "                np.std(row),\n",
        "                np.var(row),\n",
        "                np.max(row),\n",
        "                np.min(row),\n",
        "                np.median(row),\n",
        "                np.percentile(row, 25),\n",
        "                np.percentile(row, 75)\n",
        "            ])\n",
        "\n",
        "            if data.shape[0] == 1:\n",
        "                stats_names.extend([\n",
        "                    f'{prefix}_mean', f'{prefix}_std', f'{prefix}_var',\n",
        "                    f'{prefix}_max', f'{prefix}_min', f'{prefix}_median',\n",
        "                    f'{prefix}_q25', f'{prefix}_q75'\n",
        "                ])\n",
        "            else:\n",
        "                stats_names.extend([\n",
        "                    f'{prefix}_{i}_mean', f'{prefix}_{i}_std', f'{prefix}_{i}_var',\n",
        "                    f'{prefix}_{i}_max', f'{prefix}_{i}_min', f'{prefix}_{i}_median',\n",
        "                    f'{prefix}_{i}_q25', f'{prefix}_{i}_q75'\n",
        "                ])\n",
        "\n",
        "        return {'values': stats_values, 'names': stats_names}\n",
        "\n",
        "    def _find_spectral_peaks(self, spectrum, num_peaks=3):\n",
        "        \"\"\"Find spectral peaks (simplified formant detection)\"\"\"\n",
        "        try:\n",
        "            from scipy.signal import find_peaks\n",
        "            peaks, _ = find_peaks(spectrum, height=np.max(spectrum) * 0.1)\n",
        "            if len(peaks) > 0:\n",
        "                # Convert to Hz (assuming 22050 Hz max freq for simplicity)\n",
        "                peak_freqs = peaks * (self.sample_rate // 2) / len(spectrum)\n",
        "                return sorted(peak_freqs, reverse=True)[:num_peaks]\n",
        "            else:\n",
        "                return [0] * num_peaks\n",
        "        except:\n",
        "            return [0] * num_peaks\n",
        "\n",
        "    def _get_zero_features(self):\n",
        "        \"\"\"Return zero feature vector for failed extractions\"\"\"\n",
        "        # Estimate feature dimension based on typical extraction\n",
        "        estimated_dim = 13*8 + 5*8 + 3 + 1*8 + 12*8 + 1*8 + 3  # Rough estimate\n",
        "        return np.zeros(estimated_dim, dtype=np.float32)\n",
        "\n",
        "# Test feature extraction\n",
        "print(\"=== Testing Enhanced Audio Feature Extraction ===\")\n",
        "\n",
        "extractor = EnhancedAudioFeatureExtractor()\n",
        "\n",
        "if audio_files:\n",
        "    print(f\"Testing with: {audio_files[0]}\")\n",
        "    test_features = extractor.extract_comprehensive_features(audio_files[0])\n",
        "    print(f\"✓ Audio feature extraction successful!\")\n",
        "    print(f\"Feature vector dimension: {len(test_features)}\")\n",
        "    print(f\"Feature vector shape: {test_features.shape}\")\n",
        "    print(f\"Sample features: {test_features[:10]}\")\n",
        "\n",
        "    # Test with multiple files to ensure consistency\n",
        "    print(\"\\nTesting consistency with multiple files...\")\n",
        "    feature_dims = []\n",
        "    for i, audio_file in enumerate(audio_files[:min(5, len(audio_files))]):\n",
        "        try:\n",
        "            features = extractor.extract_comprehensive_features(audio_file)\n",
        "            feature_dims.append(len(features))\n",
        "            print(f\"File {i+1}: {len(features)} features\")\n",
        "        except Exception as e:\n",
        "            print(f\"File {i+1} failed: {e}\")\n",
        "\n",
        "    if len(set(feature_dims)) == 1:\n",
        "        print(\"✓ Feature dimensions are consistent across files\")\n",
        "    else:\n",
        "        print(f\"⚠ Inconsistent feature dimensions: {set(feature_dims)}\")\n",
        "else:\n",
        "    print(\"No audio files found for testing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsFyxUZBlhCv",
        "outputId": "e98701dd-218c-4a73-b6be-4f77cbf6c294"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Testing Enhanced Audio Feature Extraction ===\n",
            "Testing with: /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso007.wav\n",
            "Error extracting features from /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso007.wav: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (263,) + inhomogeneous part.\n",
            "✓ Audio feature extraction successful!\n",
            "Feature vector dimension: 262\n",
            "Feature vector shape: (262,)\n",
            "Sample features: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Testing consistency with multiple files...\n",
            "Error extracting features from /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso007.wav: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (263,) + inhomogeneous part.\n",
            "File 1: 262 features\n",
            "Error extracting features from /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso018.wav: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (263,) + inhomogeneous part.\n",
            "File 2: 262 features\n",
            "Error extracting features from /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso005.wav: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (263,) + inhomogeneous part.\n",
            "File 3: 262 features\n",
            "Error extracting features from /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso002.wav: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (263,) + inhomogeneous part.\n",
            "File 4: 262 features\n",
            "Error extracting features from /content/drive/MyDrive/Voice/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio/cn/adrso014.wav: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (263,) + inhomogeneous part.\n",
            "File 5: 262 features\n",
            "✓ Feature dimensions are consistent across files\n"
          ]
        }
      ]
    }
  ]
}