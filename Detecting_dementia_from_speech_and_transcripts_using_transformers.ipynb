{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM7tYteSke46l+SSj8jwjgS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/Detecting_dementia_from_speech_and_transcripts_using_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# Workflow for Detecting Dementia from Speech and Transcripts Using Transformers\n",
        "\n",
        "## 1. Data Preparation\n",
        "\n",
        "* **Dataset**: Utilize the **ADReSS Challenge Dataset**, consisting of 78 AD and 78 non-AD patients. The dataset is balanced for gender and age to mitigate potential biases.\n",
        "\n",
        "* **Speech Data**:\n",
        "  Convert audio files into images with three channels:\n",
        "\n",
        "  * Log-Mel spectrograms (or Mel-frequency cepstral coefficients - **MFCCs**)\n",
        "  * **Delta** features\n",
        "  * **Delta-delta** features\n",
        "    These dynamic features incorporate temporal information into the static cepstral features.\n",
        "\n",
        "* **Transcript Data**:\n",
        "  Obtain corresponding **textual transcripts** of the audio files for linguistic analysis.\n",
        "\n",
        "* **Data Splitting**:\n",
        "  Divide the dataset as follows:\n",
        "\n",
        "  * **Training Set**: 65%\n",
        "  * **Validation Set**: 35%\n",
        "    A separate **test set** is provided by the ADReSS Challenge.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Feature Extraction\n",
        "\n",
        "### Acoustic Features\n",
        "\n",
        "* Convert audio files into log-Mel spectrograms or MFCCs with delta and delta-delta components.\n",
        "* Stack these into **three-channel image representations**.\n",
        "* Feed the images into a **Vision Transformer (ViT)**.\n",
        "  ViT is selected as the best-performing model after evaluating alternatives like AlexNet, VGG16, DenseNet, and EfficientNet.\n",
        "\n",
        "### Textual Features\n",
        "\n",
        "* Process transcripts using **BERT (base, uncased)** to extract **contextualized text embeddings**.\n",
        "\n",
        "> **Rationale**:\n",
        ">\n",
        "> * Delta and delta-delta features enrich speech dynamics.\n",
        "> * Transformer architectures (ViT and BERT) provide robust feature representations for images and text, respectively.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Model Architecture\n",
        "\n",
        "### Unimodal Models\n",
        "\n",
        "* **Speech-Only**:\n",
        "  Evaluate pretrained models (AlexNet, VGG16, DenseNet, EfficientNet, ViT) using the three-channel images.\n",
        "  **ViT** is the top performer.\n",
        "\n",
        "* **Text-Only**:\n",
        "  Train a **BERT model** on transcripts to establish a baseline for AD detection from text.\n",
        "\n",
        "### Multimodal Models\n",
        "\n",
        "* **BERT + ViT**:\n",
        "  Concatenate the features from BERT and ViT for a baseline multimodal model.\n",
        "\n",
        "* **BERT + ViT + Gated Multimodal Unit (GMU)**:\n",
        "  Introduce a **GMU** to assign dynamic weights to each modality, suppressing irrelevant information.\n",
        "  Inspired by gating mechanisms in GRU/LSTM.\n",
        "\n",
        "* **BERT + ViT + Crossmodal Attention**:\n",
        "  Use **crossmodal attention mechanisms** to model interactions between speech and text:\n",
        "\n",
        "  * **Text-to-Image Attention**\n",
        "  * **Image-to-Text Attention**\n",
        "\n",
        "  Concatenate attention outputs, apply global average pooling, and feed into a final dense layer for **binary classification** (AD vs. non-AD).\n",
        "\n",
        "> **Rationale**:\n",
        ">\n",
        "> * GMU enables adaptive modality fusion.\n",
        "> * Crossmodal attention outperforms both early and late fusion by capturing fine-grained intermodal relationships.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Model Training\n",
        "\n",
        "* **Environment**:\n",
        "  Tesla P100-PCIE-16GB GPU, using **PyTorch**.\n",
        "\n",
        "* **Optimization**:\n",
        "\n",
        "  * **Optimizer**: Adam (learning rate: `1e-5`)\n",
        "  * **Learning Rate Scheduler**: ReduceLROnPlateau (factor: `0.1`, patience: `3 epochs`)\n",
        "  * **EarlyStopping**: Triggered if validation loss doesn't improve for `6 epochs`\n",
        "  * **Loss Function**: Cross-entropy loss\n",
        "\n",
        "* **Training Protocol**:\n",
        "\n",
        "  * Each model is trained **five times**.\n",
        "  * Average the results to reduce variability.\n",
        "  * Use the validation set for monitoring and the ADReSS **test set** for final evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Evaluation\n",
        "\n",
        "* **Metrics**:\n",
        "\n",
        "  * Accuracy\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1-Score\n",
        "  * Specificity\n",
        "    *(With dementia class as the **positive class**)*\n",
        "\n",
        "* **Comparison**:\n",
        "\n",
        "  * **Unimodal**: Compare ViT and BERT with other SOTA approaches.\n",
        "  * **Multimodal**: Compare baseline (BERT+ViT), GMU, and Crossmodal Attention models with traditional fusion strategies.\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "* **ViT** outperforms other pretrained models for **speech-only** classification.\n",
        "* **BERT + ViT + Crossmodal Attention** achieves the **highest performance**:\n",
        "\n",
        "  * **Accuracy**:\n",
        "\n",
        "    * 88.33% with log-Mel spectrograms\n",
        "    * 87.92% with MFCCs\n",
        "  * **F1-Score**:\n",
        "\n",
        "    * 88.69% with log-Mel spectrograms\n",
        "    * 87.99% with MFCCs\n",
        "* Crossmodal attention exceeds GMU and concatenation by:\n",
        "\n",
        "  * **Accuracy** improvement: +3.13% to +15.41%\n",
        "  * **F1-Score** improvement: +3.29% to +18.93%\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Analysis and Discussion\n",
        "\n",
        "### Limitations\n",
        "\n",
        "* The ADReSS dataset is **relatively small** (156 samples).\n",
        "* **Concatenation-based fusion** treats modalities equally, which is suboptimal.\n",
        "* GMU controls information flow but lacks the capability to model **crossmodal interactions** effectively.\n",
        "\n",
        "### Advantages\n",
        "\n",
        "* **ViT for speech**: A novel use of transformer-based models for acoustic features.\n",
        "* **Crossmodal attention**: Dynamically models inter-modal interactions, overcoming early/late fusion drawbacks.\n",
        "\n",
        "### Future Work\n",
        "\n",
        "* Explore **optimal transport** methods for modality fusion.\n",
        "* Investigate **wav2vec 2.0** for creating speech image representations.\n",
        "* Expand dataset size for greater **model robustness**.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Conclusion\n",
        "\n",
        "This workflow demonstrates an effective approach for **Alzheimer’s Disease (AD)** detection using **transformer-based multimodal architectures**. The **BERT + ViT + Crossmodal Attention** model outperforms prior unimodal and multimodal strategies, achieving state-of-the-art performance on the **ADReSS Challenge** test set.\n",
        "\n",
        "> This work advances AD detection by improving feature extraction, modality fusion, and intermodal interaction modeling—key steps toward more accurate and interpretable dementia prediction systems.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "uGrY4i1XgmGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install Dependencies\n",
        "!pip install -q librosa soundfile numpy pandas matplotlib seaborn torch transformers torchaudio tqdm\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import tarfile\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import soundfile as sf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import BertTokenizer, BertModel, ViTModel, ViTFeatureExtractor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Visualization: Display installed package versions\n",
        "import pkg_resources\n",
        "packages = ['librosa', 'soundfile', 'numpy', 'pandas', 'matplotlib', 'seaborn', 'torch', 'transformers', 'torchaudio']\n",
        "table_data = [[pkg, pkg_resources.get_distribution(pkg).version] for pkg in packages]\n",
        "table_df = pd.DataFrame(table_data, columns=['Package', 'Version'])\n",
        "print(\"\\nInstalled Package Versions:\")\n",
        "display(table_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "eUudKWhziqrf",
        "outputId": "65cf818d-3ee9-4039-e352-3e11105ac7a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Installed Package Versions:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Package      Version\n",
              "0       librosa       0.11.0\n",
              "1     soundfile       0.13.1\n",
              "2         numpy        2.0.2\n",
              "3        pandas        2.2.2\n",
              "4    matplotlib       3.10.0\n",
              "5       seaborn       0.13.2\n",
              "6         torch  2.6.0+cu124\n",
              "7  transformers       4.51.3\n",
              "8    torchaudio  2.6.0+cu124"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f536667c-6a91-4a21-9b34-bc3b60ca311b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Package</th>\n",
              "      <th>Version</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>librosa</td>\n",
              "      <td>0.11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>soundfile</td>\n",
              "      <td>0.13.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>numpy</td>\n",
              "      <td>2.0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pandas</td>\n",
              "      <td>2.2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>matplotlib</td>\n",
              "      <td>3.10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>seaborn</td>\n",
              "      <td>0.13.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>torch</td>\n",
              "      <td>2.6.0+cu124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>transformers</td>\n",
              "      <td>4.51.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>torchaudio</td>\n",
              "      <td>2.6.0+cu124</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f536667c-6a91-4a21-9b34-bc3b60ca311b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f536667c-6a91-4a21-9b34-bc3b60ca311b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f536667c-6a91-4a21-9b34-bc3b60ca311b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-15971821-dbf1-4f5b-86d5-1534fc6f4e6a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15971821-dbf1-4f5b-86d5-1534fc6f4e6a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-15971821-dbf1-4f5b-86d5-1534fc6f4e6a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5dd1cd93-3496-49ef-92b0-b9b92a561e49\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('table_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5dd1cd93-3496-49ef-92b0-b9b92a561e49 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('table_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "table_df",
              "summary": "{\n  \"name\": \"table_df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Package\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"transformers\",\n          \"soundfile\",\n          \"seaborn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Version\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"0.13.1\",\n          \"0.13.2\",\n          \"0.11.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}