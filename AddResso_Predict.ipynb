{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcfWAx6SSvL5GYgf/U/ryq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/AddResso_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa soundfile opensmile speechbrain transformers torch openai-whisper\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCdl17FwbSna",
        "outputId": "780579e5-732b-48d6-c2ab-225ba8273e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Collecting opensmile\n",
            "  Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
            "Collecting speechbrain\n",
            "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Collecting audobject>=0.6.1 (from opensmile)\n",
            "  Downloading audobject-0.7.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting audinterface>=0.7.0 (from opensmile)\n",
            "  Downloading audinterface-1.3.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.33.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Collecting audeer>=2.1.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audeer-2.2.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audformat-1.3.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting audiofile>=1.3.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audiofile-1.5.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting audmath>=1.4.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audmath-1.4.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audresample-1.3.4-py3-none-manylinux_2_17_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting asttokens>=2.0.0 (from audobject>=0.6.1->opensmile)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from audobject>=0.6.1->opensmile) (8.7.0)\n",
            "Collecting oyaml (from audobject>=0.6.1->opensmile)\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain) (1.1.5)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting iso639-lang (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso639_lang-2.6.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (18.1.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.23.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.17.0)\n",
            "Downloading opensmile-2.5.1-py3-none-manylinux_2_17_x86_64.whl (996 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.0/996.0 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audinterface-1.3.1-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audobject-0.7.12-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading audeer-2.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audformat-1.3.2-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audiofile-1.5.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audmath-1.4.2-py3-none-any.whl (23 kB)\n",
            "Downloading audresample-1.3.4-py3-none-manylinux_2_17_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading iso639_lang-2.6.1-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.9/324.9 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=deb690400acd3c40a2f152ea83ffa09d058b8235c0453b80e6c45cd153794a34\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/d2/9a/801b5cc5b2a1af2e280089b71c326711a682fc1d50ea29d0ed\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: ruamel.yaml.clib, oyaml, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, iso639-lang, iso3166, audresample, audmath, audeer, asttokens, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, audobject, nvidia-cusolver-cu12, hyperpyyaml, audiofile, audformat, openai-whisper, audinterface, speechbrain, opensmile\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "9zpduMHiZ-97",
        "outputId": "23c94eaf-25dd-424c-e1da-94feb8f7b0b8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'whisper'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3800223198.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopensmile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWav2Vec2Processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWav2Vec2Model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'whisper'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Any, Optional\n",
        "import librosa\n",
        "import torch\n",
        "import whisper\n",
        "import opensmile\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2Model, BertTokenizer, BertModel\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class ADReSSoAnalyzer:\n",
        "    def __init__(self, base_path=\"/content/drive/MyDrive/Voice/extracted/ADReSSo21\"):\n",
        "        self.base_path = base_path\n",
        "        self.output_path = \"/content\"\n",
        "        self.checkpoint_path = \"/content/checkpoints\"\n",
        "\n",
        "        # Initialize models\n",
        "        self._initialize_models()\n",
        "\n",
        "        # Create output directories\n",
        "        os.makedirs(f\"{self.output_path}/transcripts\", exist_ok=True)\n",
        "        os.makedirs(f\"{self.output_path}/features\", exist_ok=True)\n",
        "        os.makedirs(self.checkpoint_path, exist_ok=True)\n",
        "\n",
        "    def _initialize_models(self):\n",
        "        \"\"\"Initialize all required models\"\"\"\n",
        "        print(\"Initializing models...\")\n",
        "\n",
        "        # OpenSMILE for eGeMAPS features\n",
        "        self.smile = opensmile.Smile(\n",
        "            feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "            feature_level=opensmile.FeatureLevel.Functionals,\n",
        "        )\n",
        "\n",
        "        # Whisper for transcription\n",
        "        self.whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "        # Wav2Vec2 for deep acoustic features\n",
        "        self.wav2vec_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "        self.wav2vec_model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "        # BERT for linguistic features\n",
        "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        print(\"Models initialized successfully!\")\n",
        "\n",
        "    def get_audio_files(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"Get all audio files from the dataset\"\"\"\n",
        "        audio_files = {\n",
        "            'diagnosis_ad': [],\n",
        "            'diagnosis_cn': [],\n",
        "            'progression_decline': [],\n",
        "            'progression_no_decline': [],\n",
        "            'progression_test': []\n",
        "        }\n",
        "\n",
        "        # Define paths\n",
        "        paths = {\n",
        "            'diagnosis_ad': f\"{self.base_path}/diagnosis/train/audio/ad\",\n",
        "            'diagnosis_cn': f\"{self.base_path}/diagnosis/train/audio/cn\",\n",
        "            'progression_decline': f\"{self.base_path}/progression/train/audio/decline\",\n",
        "            'progression_no_decline': f\"{self.base_path}/progression/train/audio/no_decline\",\n",
        "            'progression_test': f\"{self.base_path}/progression/test-dist/audio\"\n",
        "        }\n",
        "\n",
        "        # Collect audio files\n",
        "        for category, path in paths.items():\n",
        "            if os.path.exists(path):\n",
        "                audio_files[category] = [\n",
        "                    f\"{path}/{f}\" for f in os.listdir(path)\n",
        "                    if f.endswith('.wav')\n",
        "                ]\n",
        "\n",
        "        return audio_files\n",
        "\n",
        "    def extract_acoustic_features(self, audio_path: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Extract comprehensive acoustic features from audio file\"\"\"\n",
        "        try:\n",
        "            # Load audio at 16kHz\n",
        "            y, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "            if len(y) == 0:\n",
        "                print(f\"Warning: Empty audio file {os.path.basename(audio_path)}\")\n",
        "                return None\n",
        "\n",
        "            features = {}\n",
        "\n",
        "            # 1. eGeMAPS features\n",
        "            try:\n",
        "                features['egemaps'] = self.smile.process_file(audio_path).values.flatten()\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: eGeMAPS failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['egemaps'] = np.zeros(88)\n",
        "\n",
        "            # 2. MFCC features\n",
        "            try:\n",
        "                mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "                features['mfccs'] = {\n",
        "                    'mean': np.mean(mfccs, axis=1),\n",
        "                    'std': np.std(mfccs, axis=1),\n",
        "                    'delta': np.mean(librosa.feature.delta(mfccs), axis=1),\n",
        "                    'delta2': np.mean(librosa.feature.delta(mfccs, order=2), axis=1)\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: MFCC failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['mfccs'] = {\n",
        "                    'mean': np.zeros(13), 'std': np.zeros(13),\n",
        "                    'delta': np.zeros(13), 'delta2': np.zeros(13)\n",
        "                }\n",
        "\n",
        "            # 3. Log-mel spectrogram features\n",
        "            try:\n",
        "                mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80)\n",
        "                log_mel = librosa.power_to_db(mel_spec)\n",
        "                features['log_mel'] = {\n",
        "                    'mean': np.mean(log_mel, axis=1),\n",
        "                    'std': np.std(log_mel, axis=1)\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Log-mel failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['log_mel'] = {'mean': np.zeros(80), 'std': np.zeros(80)}\n",
        "\n",
        "            # 4. Wav2Vec2 features\n",
        "            try:\n",
        "                input_values = self.wav2vec_processor(\n",
        "                    y, sampling_rate=16000, return_tensors=\"pt\"\n",
        "                ).input_values\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    wav2vec_features = self.wav2vec_model(input_values).last_hidden_state\n",
        "                features['wav2vec2'] = torch.mean(wav2vec_features, dim=1).squeeze().numpy()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Wav2Vec2 failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['wav2vec2'] = np.zeros(768)\n",
        "\n",
        "            # 5. Prosodic features\n",
        "            try:\n",
        "                f0 = librosa.yin(y, fmin=50, fmax=300, sr=sr)\n",
        "                f0_clean = f0[f0 > 0]\n",
        "\n",
        "                features['prosodic'] = {\n",
        "                    'f0_mean': np.mean(f0_clean) if len(f0_clean) > 0 else 0.0,\n",
        "                    'f0_std': np.std(f0_clean) if len(f0_clean) > 0 else 0.0,\n",
        "                    'energy_mean': np.mean(librosa.feature.rms(y=y)),\n",
        "                    'energy_std': np.std(librosa.feature.rms(y=y)),\n",
        "                    'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(y)),\n",
        "                    'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
        "                    'spectral_rolloff': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),\n",
        "                    'duration': len(y) / sr\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Prosodic features failed for {os.path.basename(audio_path)}: {str(e)}\")\n",
        "                features['prosodic'] = {\n",
        "                    'f0_mean': 0.0, 'f0_std': 0.0, 'energy_mean': 0.0, 'energy_std': 0.0,\n",
        "                    'zero_crossing_rate': 0.0, 'spectral_centroid': 0.0, 'spectral_rolloff': 0.0,\n",
        "                    'duration': 0.0\n",
        "                }\n",
        "\n",
        "            return features\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {audio_path}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def extract_acoustic_features_with_checkpoint(self, audio_files: Dict[str, List[str]]) -> Dict[str, Dict[str, Any]]:\n",
        "        \"\"\"Extract acoustic features with checkpoint support\"\"\"\n",
        "        checkpoint_file = f\"{self.checkpoint_path}/acoustic_features.pkl\"\n",
        "\n",
        "        # Try to load existing checkpoint\n",
        "        if os.path.exists(checkpoint_file):\n",
        "            print(\"Loading existing acoustic features checkpoint...\")\n",
        "            with open(checkpoint_file, 'rb') as f:\n",
        "                acoustic_features = pickle.load(f)\n",
        "            print(f\"Loaded {len(acoustic_features)} existing features\")\n",
        "        else:\n",
        "            acoustic_features = {}\n",
        "\n",
        "        # Count total files and processed files\n",
        "        total_files = sum(len(files) for files in audio_files.values())\n",
        "        processed_files = len(acoustic_features)\n",
        "\n",
        "        print(f\"Extracting acoustic features: {processed_files}/{total_files} completed\")\n",
        "\n",
        "        # Process remaining files\n",
        "        with tqdm(total=total_files, initial=processed_files, desc=\"Extracting acoustic features\") as pbar:\n",
        "            for category, files in audio_files.items():\n",
        "                for file_path in files:\n",
        "                    filename = os.path.basename(file_path)\n",
        "                    key = f\"{category}_{filename}\"\n",
        "\n",
        "                    # Skip if already processed\n",
        "                    if key in acoustic_features:\n",
        "                        pbar.update(1)\n",
        "                        continue\n",
        "\n",
        "                    # Extract features\n",
        "                    features = self.extract_acoustic_features(file_path)\n",
        "\n",
        "                    if features is not None:\n",
        "                        acoustic_features[key] = {\n",
        "                            'file_path': file_path,\n",
        "                            'category': category,\n",
        "                            'filename': filename,\n",
        "                            'features': features\n",
        "                        }\n",
        "                    else:\n",
        "                        print(f\"Failed to extract features for {filename}\")\n",
        "\n",
        "                    pbar.update(1)\n",
        "\n",
        "                    # Save checkpoint every 10 files\n",
        "                    if len(acoustic_features) % 10 == 0:\n",
        "                        with open(checkpoint_file, 'wb') as f:\n",
        "                            pickle.dump(acoustic_features, f)\n",
        "\n",
        "        # Final save\n",
        "        with open(checkpoint_file, 'wb') as f:\n",
        "            pickle.dump(acoustic_features, f)\n",
        "\n",
        "        print(f\"Acoustic features extraction completed: {len(acoustic_features)} files processed\")\n",
        "        return acoustic_features\n",
        "\n",
        "    def extract_transcripts_with_checkpoint(self, audio_files: Dict[str, List[str]]) -> Dict[str, Dict[str, Any]]:\n",
        "        \"\"\"Extract transcripts with checkpoint support\"\"\"\n",
        "        checkpoint_file = f\"{self.checkpoint_path}/transcripts.pkl\"\n",
        "\n",
        "        # Try to load existing checkpoint\n",
        "        if os.path.exists(checkpoint_file):\n",
        "            print(\"Loading existing transcripts checkpoint...\")\n",
        "            with open(checkpoint_file, 'rb') as f:\n",
        "                transcripts = pickle.load(f)\n",
        "            print(f\"Loaded {len(transcripts)} existing transcripts\")\n",
        "        else:\n",
        "            transcripts = {}\n",
        "\n",
        "        # Count total files and processed files\n",
        "        total_files = sum(len(files) for files in audio_files.values())\n",
        "        processed_files = len(transcripts)\n",
        "\n",
        "        print(f\"Extracting transcripts: {processed_files}/{total_files} completed\")\n",
        "\n",
        "        # Process remaining files\n",
        "        with tqdm(total=total_files, initial=processed_files, desc=\"Extracting transcripts\") as pbar:\n",
        "            for category, files in audio_files.items():\n",
        "                for file_path in files:\n",
        "                    filename = os.path.basename(file_path)\n",
        "                    key = f\"{category}_{filename}\"\n",
        "\n",
        "                    # Skip if already processed\n",
        "                    if key in transcripts:\n",
        "                        pbar.update(1)\n",
        "                        continue\n",
        "\n",
        "                    try:\n",
        "                        result = self.whisper_model.transcribe(file_path)\n",
        "                        transcripts[key] = {\n",
        "                            'file_path': file_path,\n",
        "                            'category': category,\n",
        "                            'filename': filename,\n",
        "                            'transcript': result[\"text\"].strip(),\n",
        "                            'language': result.get('language', 'en'),\n",
        "                            'segments': len(result.get('segments', []))\n",
        "                        }\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error transcribing {filename}: {str(e)}\")\n",
        "                        transcripts[key] = {\n",
        "                            'file_path': file_path,\n",
        "                            'category': category,\n",
        "                            'filename': filename,\n",
        "                            'transcript': \"\",\n",
        "                            'error': str(e)\n",
        "                        }\n",
        "\n",
        "                    pbar.update(1)\n",
        "\n",
        "                    # Save checkpoint every 5 files (transcription is slower)\n",
        "                    if len(transcripts) % 5 == 0:\n",
        "                        with open(checkpoint_file, 'wb') as f:\n",
        "                            pickle.dump(transcripts, f)\n",
        "\n",
        "        # Final save\n",
        "        with open(checkpoint_file, 'wb') as f:\n",
        "            pickle.dump(transcripts, f)\n",
        "\n",
        "        print(f\"Transcript extraction completed: {len(transcripts)} files processed\")\n",
        "        return transcripts\n",
        "\n",
        "    def extract_linguistic_features(self, transcripts: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
        "        \"\"\"Extract linguistic features from transcripts\"\"\"\n",
        "        linguistic_features = {}\n",
        "\n",
        "        print(\"Extracting linguistic features...\")\n",
        "\n",
        "        for key, data in tqdm(transcripts.items(), desc=\"Processing transcripts\"):\n",
        "            transcript = data['transcript']\n",
        "\n",
        "            if not transcript:\n",
        "                linguistic_features[key] = {\n",
        "                    'raw_text': '',\n",
        "                    'word_count': 0,\n",
        "                    'sentence_count': 0,\n",
        "                    'avg_word_length': 0,\n",
        "                    'unique_words': 0,\n",
        "                    'lexical_diversity': 0,\n",
        "                    'bert_input_ids': [],\n",
        "                    'bert_attention_mask': []\n",
        "                }\n",
        "                continue\n",
        "\n",
        "            # Basic linguistic features\n",
        "            words = transcript.split()\n",
        "            sentences = [s.strip() for s in transcript.split('.') if s.strip()]\n",
        "\n",
        "            # BERT tokenization\n",
        "            bert_encoding = self.bert_tokenizer(\n",
        "                transcript,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=512,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            linguistic_features[key] = {\n",
        "                'raw_text': transcript,\n",
        "                'word_count': len(words),\n",
        "                'sentence_count': len(sentences),\n",
        "                'avg_word_length': np.mean([len(word) for word in words]) if words else 0,\n",
        "                'unique_words': len(set(words)),\n",
        "                'lexical_diversity': len(set(words)) / len(words) if words else 0,\n",
        "                'bert_input_ids': bert_encoding['input_ids'].squeeze().tolist(),\n",
        "                'bert_attention_mask': bert_encoding['attention_mask'].squeeze().tolist()\n",
        "            }\n",
        "\n",
        "        # Save linguistic features\n",
        "        with open(f\"{self.output_path}/features/linguistic_features.pkl\", 'wb') as f:\n",
        "            pickle.dump(linguistic_features, f)\n",
        "\n",
        "        return linguistic_features\n",
        "\n",
        "    def save_results(self, acoustic_features: Dict, transcripts: Dict, linguistic_features: Dict):\n",
        "        \"\"\"Save all results to files\"\"\"\n",
        "        print(\"Saving results...\")\n",
        "\n",
        "        # Save acoustic features\n",
        "        with open(f\"{self.output_path}/features/acoustic_features.pkl\", 'wb') as f:\n",
        "            pickle.dump(acoustic_features, f)\n",
        "\n",
        "        # Save transcripts\n",
        "        with open(f\"{self.output_path}/transcripts/transcripts.pkl\", 'wb') as f:\n",
        "            pickle.dump(transcripts, f)\n",
        "\n",
        "        # Save transcripts as JSON\n",
        "        with open(f\"{self.output_path}/transcripts/transcripts.json\", 'w', encoding='utf-8') as f:\n",
        "            json.dump(transcripts, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        # Create summary DataFrame\n",
        "        summary_data = []\n",
        "        for key in acoustic_features.keys():\n",
        "            transcript_data = transcripts.get(key, {})\n",
        "            linguistic_data = linguistic_features.get(key, {})\n",
        "\n",
        "            summary_data.append({\n",
        "                'File_ID': key,\n",
        "                'Category': acoustic_features[key]['category'],\n",
        "                'Filename': acoustic_features[key]['filename'],\n",
        "                'Has_Acoustic_Features': 'features' in acoustic_features[key],\n",
        "                'Has_Transcript': bool(transcript_data.get('transcript', '')),\n",
        "                'Word_Count': linguistic_data.get('word_count', 0),\n",
        "                'Transcript_Length': len(transcript_data.get('transcript', '')),\n",
        "                'Language': transcript_data.get('language', 'N/A'),\n",
        "                'Has_Error': 'error' in transcript_data\n",
        "            })\n",
        "\n",
        "        summary_df = pd.DataFrame(summary_data)\n",
        "        summary_df.to_csv(f\"{self.output_path}/processing_summary.csv\", index=False)\n",
        "\n",
        "        print(f\"Results saved to {self.output_path}\")\n",
        "\n",
        "    def run_complete_pipeline(self):\n",
        "        \"\"\"Run the complete analysis pipeline with checkpointing\"\"\"\n",
        "        print(\"=== ADReSSo21 Speech Analysis Pipeline ===\\n\")\n",
        "\n",
        "        # Step 1: Get audio files\n",
        "        print(\"Step 1: Getting audio files...\")\n",
        "        audio_files = self.get_audio_files()\n",
        "\n",
        "        total_files = sum(len(files) for files in audio_files.values())\n",
        "        print(f\"Found {total_files} audio files\")\n",
        "\n",
        "        for category, files in audio_files.items():\n",
        "            print(f\"  {category}: {len(files)} files\")\n",
        "\n",
        "        if total_files == 0:\n",
        "            print(\"No audio files found. Please check the dataset path.\")\n",
        "            return\n",
        "\n",
        "        # Step 2: Extract acoustic features with checkpoint\n",
        "        print(\"\\nStep 2: Extracting acoustic features...\")\n",
        "        acoustic_features = self.extract_acoustic_features_with_checkpoint(audio_files)\n",
        "\n",
        "        # Step 3: Extract transcripts with checkpoint\n",
        "        print(\"\\nStep 3: Extracting transcripts...\")\n",
        "        transcripts = self.extract_transcripts_with_checkpoint(audio_files)\n",
        "\n",
        "        # Step 4: Extract linguistic features\n",
        "        print(\"\\nStep 4: Extracting linguistic features...\")\n",
        "        linguistic_features = self.extract_linguistic_features(transcripts)\n",
        "\n",
        "        # Step 5: Save all results\n",
        "        print(\"\\nStep 5: Saving results...\")\n",
        "        self.save_results(acoustic_features, transcripts, linguistic_features)\n",
        "\n",
        "        print(\"\\n=== Pipeline completed successfully! ===\")\n",
        "        print(f\"Processed {len(acoustic_features)} files\")\n",
        "        print(f\"Results saved to: {self.output_path}\")\n",
        "        print(f\"Checkpoints saved to: {self.checkpoint_path}\")\n",
        "\n",
        "        return {\n",
        "            'audio_files': audio_files,\n",
        "            'acoustic_features': acoustic_features,\n",
        "            'transcripts': transcripts,\n",
        "            'linguistic_features': linguistic_features\n",
        "        }\n",
        "\n",
        "# Usage example:\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize analyzer\n",
        "    analyzer = ADReSSoAnalyzer()\n",
        "\n",
        "    # Run complete pipeline\n",
        "    results = analyzer.run_complete_pipeline()"
      ]
    }
  ]
}