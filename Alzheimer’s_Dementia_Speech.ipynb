{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJiyI4TUfmv909Gb+HI4j0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/AD_Prediction/blob/main/Alzheimer%E2%80%99s_Dementia_Speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLPPAR6MyWfH",
        "outputId": "61de0110-7164-4634-a491-6bc7f4f2d70a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.io import wavfile\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import soundfile as sf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import uuid\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "J9_mpqWeL2Ck"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load Dataset from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths to the .tgz files\n",
        "data_path = '/content/drive/MyDrive/Voice/ADRESS021/'\n",
        "train_prog_tgz = os.path.join(data_path, 'ADRESS021-progression-train.tgz')\n",
        "test_prog_tgz = os.path.join(data_path, 'ADRESS021-progression-test.tgz')\n",
        "train_diag_tgz = os.path.join(data_path, 'ADRESS021-diagnosis-train.tgz')\n",
        "\n",
        "# Extract .tgz files\n",
        "extracted_path = '/content/adress021_data/'\n",
        "os.makedirs(extracted_path, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5meKbIPly7Vc",
        "outputId": "073d5aad-86d2-43b9-c95f-29f0dd226fa2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Define file paths (update these to match your actual file locations)\n",
        "train_prog_tgz = '/content/drive/MyDrive/Voice/ADRESS021/ADRESS021-progression-train.tgz'\n",
        "test_prog_tgz = '/content/drive/MyDrive/Voice/ADRESS021/ADRESS021-progression-test.tgz'\n",
        "train_diag_tgz = '/content/drive/MyDrive/Voice/ADRESS021/ADRESS021-diagnostic-train.tgz'\n",
        "extracted_path = '/content/extracted_audio'  # Directory to extract files to\n",
        "\n",
        "# Ensure extracted_path exists\n",
        "os.makedirs(extracted_path, exist_ok=True)\n",
        "\n",
        "# Function to extract .tgz files\n",
        "def extract_tgz(tgz_path, extract_to):\n",
        "    try:\n",
        "        with tarfile.open(tgz_path, 'r:gz') as tar:\n",
        "            tar.extractall(path=extract_to)\n",
        "        print(f\"Successfully extracted {tgz_path} to {extract_to}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File {tgz_path} not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting {tgz_path}: {str(e)}\")\n",
        "\n",
        "# Extract each .tgz file\n",
        "for tgz in [train_prog_tgz, test_prog_tgz, train_diag_tgz]:\n",
        "    if os.path.exists(tgz):\n",
        "        extract_tgz(tgz, extracted_path)\n",
        "    else:\n",
        "        print(f\"Skipping {tgz}: File does not exist.\")\n",
        "\n",
        "# Find all WAV files\n",
        "audio_files = glob.glob(os.path.join(extracted_path, '**/*.wav'), recursive=True)\n",
        "print(f\"Found {len(audio_files)} audio files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqtU-txczugd",
        "outputId": "909a4fba-475b-4e9c-a836-e293ab7b8b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping /content/drive/MyDrive/Voice/ADRESS021/ADRESS021-progression-train.tgz: File does not exist.\n",
            "Skipping /content/drive/MyDrive/Voice/ADRESS021/ADRESS021-progression-test.tgz: File does not exist.\n",
            "Skipping /content/drive/MyDrive/Voice/ADRESS021/ADRESS021-diagnostic-train.tgz: File does not exist.\n",
            "Found 0 audio files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load metadata (assuming there's a CSV or text file with labels)\n",
        "# Modify this based on actual metadata structure\n",
        "metadata_path = glob.glob(os.path.join(extracted_path, '**/*.csv'), recursive=True)\n",
        "if metadata_path:\n",
        "    metadata = pd.read_csv(metadata_path[0])\n",
        "    print(\"Metadata loaded:\")\n",
        "    print(metadata.head())\n",
        "else:\n",
        "    metadata = pd.DataFrame({'file': audio_files, 'label': 'unknown'})\n",
        "    print(\"No metadata CSV found. Using file paths only.\")"
      ],
      "metadata": {
        "id": "4Ureo4cpL8Au",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "680f4521-8d91-41f9-d62e-06e7ead916dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Voice/ADRESS021/ADRESS021-progression-train.tgz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-186eef6809c9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtgz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_prog_tgz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_prog_tgz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_diag_tgz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mextract_tgz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextracted_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Find all WAV files (assuming audio files are in WAV format)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-186eef6809c9>\u001b[0m in \u001b[0;36mextract_tgz\u001b[0;34m(tgz_path, extract_to)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_tgz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgz_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgz_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r:gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtgz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_prog_tgz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_prog_tgz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_diag_tgz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1852\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown compression type %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1854\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"|\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1901\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Voice/ADRESS021/ADRESS021-progression-train.tgz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Visualize and Explore Dataset\n",
        "# Select a few sample audio files\n",
        "sample_files = audio_files[:3]\n",
        "\n",
        "# Visualize waveforms\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, audio_file in enumerate(sample_files):\n",
        "    y, sr = librosa.load(audio_file, sr=None)\n",
        "    plt.subplot(len(sample_files), 1, i+1)\n",
        "    librosa.display.waveshow(y, sr=sr)\n",
        "    plt.title(f\"Waveform: {os.path.basename(audio_file)}\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/waveforms.png')\n",
        "plt.show()\n",
        "\n",
        "# Show sample metadata\n",
        "print(\"\\nSample Metadata:\")\n",
        "print(metadata.head())\n",
        "\n",
        "# Plot spectrogram for one sample\n",
        "y, sr = librosa.load(sample_files[0], sr=None)\n",
        "D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "plt.figure(figsize=(10, 6))\n",
        "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title(f\"Spectrogram: {os.path.basename(sample_files[0])}\")\n",
        "plt.savefig('/content/spectrogram.png')\n",
        "plt.show()\n",
        "\n",
        "# Show label distribution (assuming metadata has a 'label' column)\n",
        "if 'label' in metadata.columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.countplot(data=metadata, x='label')\n",
        "    plt.title('Label Distribution')\n",
        "    plt.savefig('/content/label_distribution.png')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No label column found in metadata.\")"
      ],
      "metadata": {
        "id": "VEzAzNABMAwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Preprocess Dataset\n",
        "processed_features = []\n",
        "output_dir = '/content/processed_features/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for audio_file in audio_files:\n",
        "    # Load audio\n",
        "    y, sr = librosa.load(audio_file, sr=16000, mono=True)  # Standardize to 16kHz, mono\n",
        "\n",
        "    # Noise Removal (simple spectral gating)\n",
        "    y_denoised = librosa.decompose.nn_filter(y, aggregate=np.median, metric='cosine')\n",
        "\n",
        "    # Silence Trimming\n",
        "    y_trimmed, _ = librosa.effects.trim(y_denoised, top_db=20)\n",
        "\n",
        "    # Segmentation (Optional)\n",
        "    audio = AudioSegment.from_wav(audio_file)\n",
        "    chunks = split_on_silence(audio, min_silence_len=500, silence_thresh=-40)\n",
        "    segments = []\n",
        "    for chunk in chunks:\n",
        "        chunk.export(f\"/content/temp_{uuid.uuid4()}.wav\", format=\"wav\")\n",
        "        seg_y, seg_sr = librosa.load(f\"/content/temp_{uuid.uuid4()}.wav\", sr=16000)\n",
        "        segments.append(seg_y)\n",
        "    if not segments:\n",
        "        segments = [y_trimmed]  # Use trimmed audio if no segments\n",
        "\n",
        "    # Feature Extraction\n",
        "    for seg_y in segments:\n",
        "        # Acoustic Features (MFCCs)\n",
        "        mfccs = librosa.feature.mfcc(y=seg_y, sr=16000, n_mfcc=13)\n",
        "        mfccs_mean = np.mean(mfccs, axis=1)\n",
        "\n",
        "        # Prosodic Features (Pitch, Energy)\n",
        "        pitches, magnitudes = librosa.piptrack(y=seg_y, sr=16000)\n",
        "        pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0\n",
        "        energy = np.mean(librosa.feature.rms(y=seg_y))\n",
        "\n",
        "        # Linguistic Features (Placeholder: requires transcription)\n",
        "        # Example: word count, pause frequency (needs external ASR)\n",
        "        linguistic_features = np.array([0, 0])  # Placeholder\n",
        "\n",
        "        # Combine features\n",
        "        features = np.concatenate([mfccs_mean, [pitch_mean, energy], linguistic_features])\n",
        "        processed_features.append(features)\n",
        "\n",
        "    # Save processed audio (optional)\n",
        "    sf.write(os.path.join(output_dir, os.path.basename(audio_file)), y_trimmed, 16000)\n",
        "\n",
        "# Feature Normalization\n",
        "scaler = StandardScaler()\n",
        "processed_features = np.array(processed_features)\n",
        "normalized_features = scaler.fit_transform(processed_features)\n",
        "\n",
        "# Data Augmentation (e.g., add noise)\n",
        "augmented_features = []\n",
        "for features in normalized_features:\n",
        "    noise = np.random.normal(0, 0.01, features.shape)\n",
        "    augmented_features.append(features + noise)\n",
        "augmented_features = np.array(augmented_features)\n",
        "\n",
        "# Export Processed Features\n",
        "np.save(os.path.join(output_dir, 'normalized_features.npy'), normalized_features)\n",
        "np.save(os.path.join(output_dir, 'augmented_features.npy'), augmented_features)\n",
        "print(f\"Processed features saved to {output_dir}\")\n",
        "\n",
        "# Clean up temporary files\n",
        "for temp_file in glob.glob('/content/temp_*.wav'):\n",
        "    os.remove(temp_file)"
      ],
      "metadata": {
        "id": "wCpaMqopL0Zq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}